{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study2_autoencoder_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
      },
      "source": [
        "# Autoencoder: Generate Corresponding Embedding"
      ],
      "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
      },
      "source": [
        "### Imports"
      ],
      "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK38cfNTYVw5",
        "outputId": "64788004-0fb4-4e08-ba8b-1a8588c1a706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ],
      "id": "PK38cfNTYVw5"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from scipy import spatial\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from plotnine import ggplot, geom_line, aes, ggsave, labs, theme, element_text, guides, guide_legend"
      ],
      "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_fc5dDySK5",
        "outputId": "79c69051-2b92-48c1-a72a-b48a8a5ca893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQTEV8ZsQtXD"
      },
      "outputs": [],
      "source": [
        "import osfclient.cli"
      ],
      "id": "WQTEV8ZsQtXD"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cxigtskT2dda"
      },
      "outputs": [],
      "source": [
        "from osfclient.api import OSF\n",
        "from osfclient.models import Project, Storage\n",
        "from io import BytesIO"
      ],
      "id": "cxigtskT2dda"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
      },
      "source": [
        "## Data"
      ],
      "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFnWt4JYqWi"
      },
      "source": [
        "#### [Import] Grab data from OSF"
      ],
      "id": "vIFnWt4JYqWi"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxpT2Q9yYpzD",
        "outputId": "82b75cb2-a7ec-4452-f7be-9a48907bbc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 152M/152M [00:01<00:00, 109Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/corpora.zip"
      ],
      "id": "UxpT2Q9yYpzD"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KuvkPngZtcz",
        "outputId": "2aabc0c5-aaea-49fc-bc55-5c09e892cd1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 53.0M/53.0M [00:00<00:00, 85.2Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/embeddings_dump.zip"
      ],
      "id": "8KuvkPngZtcz"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz8qXrcYZh3e",
        "outputId": "035daf3a-557e-402c-d83b-b9dfcc7166c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['corpora', '__MACOSX']\n"
          ]
        }
      ],
      "source": [
        "corpora_file_path = '/content/corpora.zip'\n",
        "output_folder_path = '/content/corpora'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(corpora_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "id": "fz8qXrcYZh3e"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUrn5AETZwpv",
        "outputId": "45849fa2-2b9f-4c5b-9a3c-d82c3b8ca703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['economy', 'global_embeddings.pkl']\n"
          ]
        }
      ],
      "source": [
        "embeddings_dump_file_path = '/content/embeddings_dump.zip'\n",
        "output_folder_path = '/content/current_data_dump/embeddings_dump'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(embeddings_dump_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "id": "XUrn5AETZwpv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUmuCm4MYuzG"
      },
      "source": [
        "#### Functions for preparing training data"
      ],
      "id": "NUmuCm4MYuzG"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1c418d64-8e44-4bb4-a85c-050f9197756f"
      },
      "outputs": [],
      "source": [
        "def prepare_training_df(data: pd.DataFrame):\n",
        "  \"\"\"Drop rows that do not follow 'point' -> 'counter' pattern\"\"\"\n",
        "  point_indices = data[data['type'] == 'point'].index\n",
        "  counter_indices = data[data['type'] == 'counter'].index\n",
        "  drop_indices = []\n",
        "  for idx in point_indices:\n",
        "    if (idx == len(data)-1) or (idx + 1 < len(data) and data.loc[idx + 1, 'type'] != 'counter'):\n",
        "      drop_indices.append(idx)\n",
        "  for idx in counter_indices:\n",
        "    if idx > 0 and data.loc[idx - 1, 'type'] != 'point':\n",
        "      drop_indices.append(idx)\n",
        "  data = data.drop(drop_indices)\n",
        "  data = data.select_dtypes(include=[np.number])\n",
        "  data = data.reset_index(drop=True)\n",
        "  return data"
      ],
      "id": "1c418d64-8e44-4bb4-a85c-050f9197756f"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f1b3452b-e0ce-4050-9a06-f392505474d0"
      },
      "outputs": [],
      "source": [
        "def prepare_training_df_shuffled(data: pd.DataFrame):\n",
        "  \"\"\"Drop rows that do not follow 'point' -> 'counter' pattern\"\"\"\n",
        "  point_indices = data[data['type'] == 'point'].index\n",
        "  counter_indices = data[data['type'] == 'counter'].index\n",
        "  drop_indices = []\n",
        "  for idx in point_indices:\n",
        "    if (idx == len(data)-1) or (idx + 1 < len(data) and data.loc[idx + 1, 'type'] != 'counter'):\n",
        "      drop_indices.append(idx)\n",
        "  for idx in counter_indices:\n",
        "    if idx > 0 and data.loc[idx - 1, 'type'] != 'point':\n",
        "      drop_indices.append(idx)\n",
        "  data = data.drop(drop_indices)\n",
        "  data = data.reset_index(drop=True)\n",
        "  return data"
      ],
      "id": "f1b3452b-e0ce-4050-9a06-f392505474d0"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8f4dffbb-31cf-4236-a7a7-ed53b2ec98b8"
      },
      "outputs": [],
      "source": [
        "def make_x_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Make training and testing datasets\"\"\"\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  train_rows_df = data.iloc[:cutoff, :]\n",
        "  x_train = train_rows_df[train_rows_df.index % 2 == 0].reset_index(drop=True)\n",
        "  return x_train\n",
        "\n",
        "def make_y_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  train_rows_df = data.iloc[:cutoff, :]\n",
        "  y_train = train_rows_df[train_rows_df.index % 2 != 0].reset_index(drop=True)\n",
        "  return y_train\n",
        "\n",
        "def make_x_test(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  test_rows_df = data.iloc[cutoff:, :]\n",
        "  x_test = test_rows_df[test_rows_df.index % 2 == 0].reset_index(drop=True)\n",
        "  return x_test\n",
        "\n",
        "def make_y_test(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  test_rows_df = data.iloc[cutoff:, :]\n",
        "  y_test = test_rows_df[test_rows_df.index % 2 != 0].reset_index(drop=True)\n",
        "  return y_test"
      ],
      "id": "8f4dffbb-31cf-4236-a7a7-ed53b2ec98b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0beb081-2126-4a1a-bc5e-5fc775407314"
      },
      "source": [
        "#### Global data"
      ],
      "id": "e0beb081-2126-4a1a-bc5e-5fc775407314"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "189ca924-572d-4b56-9288-5dd0a03b6782"
      },
      "outputs": [],
      "source": [
        "global_embeddings_data = pd.read_pickle(\"current_data_dump/embeddings_dump/global_embeddings.pkl\")"
      ],
      "id": "189ca924-572d-4b56-9288-5dd0a03b6782"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "32fbc58f-b070-40c3-a1b9-820a9f8616f6"
      },
      "outputs": [],
      "source": [
        "global_training_df = prepare_training_df(global_embeddings_data)"
      ],
      "id": "32fbc58f-b070-40c3-a1b9-820a9f8616f6"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ba13fea2-4018-471a-929d-a7dffb83af42"
      },
      "outputs": [],
      "source": [
        "global_x_train = make_x_train(global_training_df)"
      ],
      "id": "ba13fea2-4018-471a-929d-a7dffb83af42"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6ddf9949-701d-4722-88c8-eee4d2e39828"
      },
      "outputs": [],
      "source": [
        "global_y_train = make_y_train(global_training_df)"
      ],
      "id": "6ddf9949-701d-4722-88c8-eee4d2e39828"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ea9a7137-fc4e-4b3a-9696-90c8ad10f795"
      },
      "outputs": [],
      "source": [
        "global_x_test = make_x_test(global_training_df)"
      ],
      "id": "ea9a7137-fc4e-4b3a-9696-90c8ad10f795"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9834f07d-9e2c-4046-86d2-29db8cb2ae5d"
      },
      "outputs": [],
      "source": [
        "global_y_test = make_y_test(global_training_df)"
      ],
      "id": "9834f07d-9e2c-4046-86d2-29db8cb2ae5d"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5d54a04a-d779-45af-a297-3356e8c6adf3"
      },
      "outputs": [],
      "source": [
        "global_y_train_test = pd.concat([global_y_train, global_y_test], axis=0)"
      ],
      "id": "5d54a04a-d779-45af-a297-3356e8c6adf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
      },
      "source": [
        "#### Global data shuffled"
      ],
      "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
      },
      "outputs": [],
      "source": [
        "global_training_df_shuffled = prepare_training_df_shuffled(global_embeddings_data)"
      ],
      "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9e08cd74-7f3e-4be7-8d19-f5b43cecca2e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "global_y_train_shuffled = make_y_train(global_training_df_shuffled)"
      ],
      "id": "9e08cd74-7f3e-4be7-8d19-f5b43cecca2e"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "45961bd5-55e4-4e29-b785-4f03007f9f73",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "global_y_train_shuffled = global_y_train_shuffled.groupby(['topic'], sort=False)\n",
        "global_y_train_shuffled = global_y_train_shuffled.sample(frac=1).reset_index(drop=True)\n",
        "global_y_train_shuffled = global_y_train_shuffled.select_dtypes(include=[np.number])"
      ],
      "id": "45961bd5-55e4-4e29-b785-4f03007f9f73"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
      },
      "source": [
        "## Model"
      ],
      "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdhQDH3Hdf2d"
      },
      "source": [
        "### Architecture"
      ],
      "id": "wdhQDH3Hdf2d"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "92def071-b058-49c3-9573-6ee31d041244"
      },
      "outputs": [],
      "source": [
        "# Layers\n",
        "input_layer = tf.keras.layers.Input(shape=(1536, ), name=\"Input\")\n",
        "hidden_layer = tf.keras.layers.Dense(units=1536, activation=\"relu\", name=\"Hidden\")(input_layer)\n",
        "output_layer = tf.keras.layers.Dense(units=1536, activation=\"linear\", name=\"Output\")(hidden_layer)"
      ],
      "id": "92def071-b058-49c3-9573-6ee31d041244"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00",
        "outputId": "98a26578-bee2-4f1c-e523-5e34774d5203",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 1536)]            0         \n",
            "                                                                 \n",
            " Hidden (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4721664 (18.01 MB)\n",
            "Trainable params: 4721664 (18.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "autoencoder_model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder_model.summary()"
      ],
      "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYS3gnudicT"
      },
      "source": [
        "### Metric"
      ],
      "id": "bfYS3gnudicT"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  \"\"\"global_metric\"\"\"\n",
        "  global_training_df_32 = tf.cast(global_training_df, dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
      },
      "source": [
        "### Global Training"
      ],
      "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "global_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")"
      ],
      "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2",
        "scrolled": true,
        "outputId": "a241c08b-eaef-46e2-aa40-e496fa9a3d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.8853 - metric_choose_argument_global_y_train: 0.0538\n",
            "Epoch 1: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 44s 8ms/step - loss: -0.8853 - metric_choose_argument_global_y_train: 0.0538 - val_loss: -0.8982 - val_metric_choose_argument_global_y_train: 0.1033\n",
            "Epoch 2/20\n",
            "3243/3252 [============================>.] - ETA: 0s - loss: -0.9115 - metric_choose_argument_global_y_train: 0.1344\n",
            "Epoch 2: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9115 - metric_choose_argument_global_y_train: 0.1344 - val_loss: -0.9056 - val_metric_choose_argument_global_y_train: 0.1205\n",
            "Epoch 3/20\n",
            "3247/3252 [============================>.] - ETA: 0s - loss: -0.9210 - metric_choose_argument_global_y_train: 0.2153\n",
            "Epoch 3: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9210 - metric_choose_argument_global_y_train: 0.2153 - val_loss: -0.9111 - val_metric_choose_argument_global_y_train: 0.2005\n",
            "Epoch 4/20\n",
            "3247/3252 [============================>.] - ETA: 0s - loss: -0.9278 - metric_choose_argument_global_y_train: 0.3221\n",
            "Epoch 4: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9278 - metric_choose_argument_global_y_train: 0.3223 - val_loss: -0.9144 - val_metric_choose_argument_global_y_train: 0.2226\n",
            "Epoch 5/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9332 - metric_choose_argument_global_y_train: 0.4346\n",
            "Epoch 5: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9332 - metric_choose_argument_global_y_train: 0.4345 - val_loss: -0.9152 - val_metric_choose_argument_global_y_train: 0.2718\n",
            "Epoch 6/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9375 - metric_choose_argument_global_y_train: 0.5449\n",
            "Epoch 6: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9375 - metric_choose_argument_global_y_train: 0.5449 - val_loss: -0.9161 - val_metric_choose_argument_global_y_train: 0.2989\n",
            "Epoch 7/20\n",
            "3243/3252 [============================>.] - ETA: 0s - loss: -0.9411 - metric_choose_argument_global_y_train: 0.6457\n",
            "Epoch 7: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9411 - metric_choose_argument_global_y_train: 0.6445 - val_loss: -0.9164 - val_metric_choose_argument_global_y_train: 0.3235\n",
            "Epoch 8/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9441 - metric_choose_argument_global_y_train: 0.7077\n",
            "Epoch 8: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.9441 - metric_choose_argument_global_y_train: 0.7079 - val_loss: -0.9165 - val_metric_choose_argument_global_y_train: 0.3506\n",
            "Epoch 9/20\n",
            "3243/3252 [============================>.] - ETA: 0s - loss: -0.9465 - metric_choose_argument_global_y_train: 0.7724\n",
            "Epoch 9: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9465 - metric_choose_argument_global_y_train: 0.7718 - val_loss: -0.9168 - val_metric_choose_argument_global_y_train: 0.3665\n",
            "Epoch 10/20\n",
            "3247/3252 [============================>.] - ETA: 0s - loss: -0.9486 - metric_choose_argument_global_y_train: 0.8115\n",
            "Epoch 10: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9486 - metric_choose_argument_global_y_train: 0.8115 - val_loss: -0.9168 - val_metric_choose_argument_global_y_train: 0.3825\n",
            "Epoch 11/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9504 - metric_choose_argument_global_y_train: 0.8484\n",
            "Epoch 11: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9504 - metric_choose_argument_global_y_train: 0.8484 - val_loss: -0.9171 - val_metric_choose_argument_global_y_train: 0.3875\n",
            "Epoch 12/20\n",
            "3244/3252 [============================>.] - ETA: 0s - loss: -0.9520 - metric_choose_argument_global_y_train: 0.8773\n",
            "Epoch 12: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9520 - metric_choose_argument_global_y_train: 0.8770 - val_loss: -0.9176 - val_metric_choose_argument_global_y_train: 0.3936\n",
            "Epoch 13/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9533 - metric_choose_argument_global_y_train: 0.8988\n",
            "Epoch 13: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9533 - metric_choose_argument_global_y_train: 0.8985 - val_loss: -0.9163 - val_metric_choose_argument_global_y_train: 0.3998\n",
            "Epoch 14/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9545 - metric_choose_argument_global_y_train: 0.9173\n",
            "Epoch 14: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 24s 8ms/step - loss: -0.9545 - metric_choose_argument_global_y_train: 0.9173 - val_loss: -0.9163 - val_metric_choose_argument_global_y_train: 0.4022\n",
            "Epoch 15/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9556 - metric_choose_argument_global_y_train: 0.9262\n",
            "Epoch 15: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 22s 7ms/step - loss: -0.9556 - metric_choose_argument_global_y_train: 0.9262 - val_loss: -0.9166 - val_metric_choose_argument_global_y_train: 0.4133\n",
            "Epoch 16/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9566 - metric_choose_argument_global_y_train: 0.9336\n",
            "Epoch 16: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 20s 6ms/step - loss: -0.9566 - metric_choose_argument_global_y_train: 0.9336 - val_loss: -0.9165 - val_metric_choose_argument_global_y_train: 0.4010\n",
            "Epoch 17/20\n",
            "3243/3252 [============================>.] - ETA: 0s - loss: -0.9574 - metric_choose_argument_global_y_train: 0.9399\n",
            "Epoch 17: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 23s 7ms/step - loss: -0.9574 - metric_choose_argument_global_y_train: 0.9400 - val_loss: -0.9167 - val_metric_choose_argument_global_y_train: 0.4084\n",
            "Epoch 18/20\n",
            "3244/3252 [============================>.] - ETA: 0s - loss: -0.9582 - metric_choose_argument_global_y_train: 0.9498\n",
            "Epoch 18: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9583 - metric_choose_argument_global_y_train: 0.9496 - val_loss: -0.9155 - val_metric_choose_argument_global_y_train: 0.4071\n",
            "Epoch 19/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9590 - metric_choose_argument_global_y_train: 0.9563\n",
            "Epoch 19: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9590 - metric_choose_argument_global_y_train: 0.9560 - val_loss: -0.9157 - val_metric_choose_argument_global_y_train: 0.4121\n",
            "Epoch 20/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9596 - metric_choose_argument_global_y_train: 0.9551\n",
            "Epoch 20: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 22s 7ms/step - loss: -0.9596 - metric_choose_argument_global_y_train: 0.9551 - val_loss: -0.9155 - val_metric_choose_argument_global_y_train: 0.4207\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath='global_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
        "csv_logger_callback = CSVLogger(filename='global_training_log.csv', separator=',', append=True)\n",
        "global_history = global_autoencoder_model.fit(\n",
        "  x=global_x_train,\n",
        "  y=global_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (global_x_test, global_y_test),\n",
        "  callbacks=[checkpoint_callback, csv_logger_callback]\n",
        ")"
      ],
      "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
      },
      "outputs": [],
      "source": [
        "global_history_df = pd.DataFrame(global_history.history)"
      ],
      "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current_data_dump/ada_autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_history_df.to_csv(f'{output_folder_path}global_training_log.csv')"
      ],
      "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current_data_dump/ada_autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_autoencoder_model.save(f'{output_folder_path}global_autoencoder_model.keras')"
      ],
      "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
      },
      "source": [
        "#### Global Shuffled Training"
      ],
      "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "9887abb8-c075-46b4-9eee-b28922a61575",
        "outputId": "1c187c26-bf1b-49eb-ccc5-f35e85b7b36b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3252/3252 [==============================] - 37s 9ms/step - loss: -0.8765 - metric_choose_argument_global_y_train: 0.0138 - val_loss: -0.8918 - val_metric_choose_argument_global_y_train: 0.0418\n",
            "Epoch 2/20\n",
            "3252/3252 [==============================] - 21s 6ms/step - loss: -0.8990 - metric_choose_argument_global_y_train: 0.0351 - val_loss: -0.8988 - val_metric_choose_argument_global_y_train: 0.0529\n",
            "Epoch 3/20\n",
            "3252/3252 [==============================] - 23s 7ms/step - loss: -0.9074 - metric_choose_argument_global_y_train: 0.0581 - val_loss: -0.9024 - val_metric_choose_argument_global_y_train: 0.0677\n",
            "Epoch 4/20\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9135 - metric_choose_argument_global_y_train: 0.0919 - val_loss: -0.9034 - val_metric_choose_argument_global_y_train: 0.0836\n",
            "Epoch 5/20\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9180 - metric_choose_argument_global_y_train: 0.1169 - val_loss: -0.9040 - val_metric_choose_argument_global_y_train: 0.0824\n",
            "Epoch 6/20\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9219 - metric_choose_argument_global_y_train: 0.1605 - val_loss: -0.9039 - val_metric_choose_argument_global_y_train: 0.0861\n",
            "Epoch 7/20\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9251 - metric_choose_argument_global_y_train: 0.2196 - val_loss: -0.9028 - val_metric_choose_argument_global_y_train: 0.0836\n",
            "Epoch 8/20\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9279 - metric_choose_argument_global_y_train: 0.2881 - val_loss: -0.9018 - val_metric_choose_argument_global_y_train: 0.0664\n",
            "Epoch 9/20\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9303 - metric_choose_argument_global_y_train: 0.3524 - val_loss: -0.9003 - val_metric_choose_argument_global_y_train: 0.0615\n",
            "Epoch 10/20\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9324 - metric_choose_argument_global_y_train: 0.4194 - val_loss: -0.8992 - val_metric_choose_argument_global_y_train: 0.0664\n",
            "Epoch 11/20\n",
            "3252/3252 [==============================] - 23s 7ms/step - loss: -0.9343 - metric_choose_argument_global_y_train: 0.4754 - val_loss: -0.8975 - val_metric_choose_argument_global_y_train: 0.0627\n",
            "Epoch 12/20\n",
            "3252/3252 [==============================] - 22s 7ms/step - loss: -0.9359 - metric_choose_argument_global_y_train: 0.5200 - val_loss: -0.8968 - val_metric_choose_argument_global_y_train: 0.0652\n",
            "Epoch 13/20\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9372 - metric_choose_argument_global_y_train: 0.5563 - val_loss: -0.8954 - val_metric_choose_argument_global_y_train: 0.0566\n",
            "Epoch 14/20\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9385 - metric_choose_argument_global_y_train: 0.6049 - val_loss: -0.8947 - val_metric_choose_argument_global_y_train: 0.0541\n",
            "Epoch 15/20\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9396 - metric_choose_argument_global_y_train: 0.6239 - val_loss: -0.8933 - val_metric_choose_argument_global_y_train: 0.0640\n",
            "Epoch 16/20\n",
            "3252/3252 [==============================] - 21s 6ms/step - loss: -0.9405 - metric_choose_argument_global_y_train: 0.6384 - val_loss: -0.8924 - val_metric_choose_argument_global_y_train: 0.0640\n",
            "Epoch 17/20\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9414 - metric_choose_argument_global_y_train: 0.6611 - val_loss: -0.8911 - val_metric_choose_argument_global_y_train: 0.0541\n",
            "Epoch 18/20\n",
            "3252/3252 [==============================] - 23s 7ms/step - loss: -0.9423 - metric_choose_argument_global_y_train: 0.6787 - val_loss: -0.8908 - val_metric_choose_argument_global_y_train: 0.0566\n",
            "Epoch 19/20\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9430 - metric_choose_argument_global_y_train: 0.6928 - val_loss: -0.8901 - val_metric_choose_argument_global_y_train: 0.0541\n",
            "Epoch 20/20\n",
            "3252/3252 [==============================] - 19s 6ms/step - loss: -0.9437 - metric_choose_argument_global_y_train: 0.6971 - val_loss: -0.8894 - val_metric_choose_argument_global_y_train: 0.0578\n"
          ]
        }
      ],
      "source": [
        "# Global Shuffled Model\n",
        "global_shuffled_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_shuffled_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")\n",
        "\n",
        "global_shuffled_history = global_shuffled_autoencoder_model.fit(\n",
        "  x=global_x_train,\n",
        "  y=global_y_train_shuffled,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (global_x_test, global_y_test)\n",
        ")"
      ],
      "id": "9887abb8-c075-46b4-9eee-b28922a61575"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5i5lFFqIbNzh"
      },
      "outputs": [],
      "source": [
        "global_shuffled_history_df = pd.DataFrame(global_shuffled_history.history)"
      ],
      "id": "5i5lFFqIbNzh"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KOtX9nyBbNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current_data_dump/ada_autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_history_df.to_csv(f'{output_folder_path}global_shuffled_training_log.csv')"
      ],
      "id": "KOtX9nyBbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KrmhWBS2bNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current_data_dump/ada_autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_autoencoder_model.save(f'{output_folder_path}global_shuffled_autoencoder_model.keras')"
      ],
      "id": "KrmhWBS2bNzk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export data"
      ],
      "metadata": {
        "id": "o4WdvaTBDg0Q"
      },
      "id": "o4WdvaTBDg0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "def export_ada_autoencoder():\n",
        "  \"\"\"Export ada_autoencoder directory\"\"\"\n",
        "  ada_autoencoder_file_path = '/content/current_data_dump/ada_autoencoder'\n",
        "  ada_autoencoder_file_path_zip = '/content/current_data_dump/ada_autoencoder'\n",
        "  shutil.make_archive(ada_autoencoder_file_path_zip, 'zip', ada_autoencoder_file_path)\n",
        "  print(f\"Zip file created at: {ada_autoencoder_file_path_zip}\")\n",
        "  result = subprocess.run([f\"osf -p sakjg upload --force {ada_autoencoder_file_path_zip}.zip ada_autoencoder.zip\"], shell=True, capture_output=True, text=True)\n",
        "  print(result.stderr)\n",
        "  print(f\"File: {ada_autoencoder_file_path_zip} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "kPUJzZOEFmCY"
      },
      "id": "kPUJzZOEFmCY",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "HwCx1sldDjMC"
      },
      "id": "HwCx1sldDjMC"
    },
    {
      "cell_type": "code",
      "source": [
        "def import_ada_autoencoder():\n",
        "  \"\"\"Import ada_autoencoder directory\"\"\"\n",
        "  subprocess.run(\"osf -p sakjg fetch --force osfstorage/ada_autoencoder.zip\", shell=True)\n",
        "  print(\"ada_autoencoder.zip successfully imported\")\n",
        "  ada_autoencoder_file_path_zip = 'ada_autoencoder.zip'\n",
        "  ada_autoencoder_file_path = 'current_data_dump/ada_autoencoder'\n",
        "  with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(ada_autoencoder_file_path)\n",
        "  extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "  print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "I5nxJr5bGDTR"
      },
      "id": "I5nxJr5bGDTR",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TucNWIIdnBs"
      },
      "source": [
        "## Load global training history"
      ],
      "id": "8TucNWIIdnBs"
    },
    {
      "cell_type": "code",
      "source": [
        "import_ada_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go4cGqlJHOV-",
        "outputId": "8493f4f3-b305-4d16-9cff-ad0749bd008f"
      },
      "id": "go4cGqlJHOV-",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_shuffled_autoencoder_model.keras', 'global_training_log.csv', 'global_training_plot.png', 'global_autoencoder_model.keras', 'global_shuffled_training_log.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unshuffled training history"
      ],
      "metadata": {
        "id": "JY2RndZJDXxt"
      },
      "id": "JY2RndZJDXxt"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_history = pd.DataFrame(pd.read_csv(\"current_data_dump/ada_autoencoder/global_training_log.csv\"))\n",
        "loaded_global_history = pd.melt(loaded_global_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_history = loaded_global_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_history['shuffled'] = False"
      ],
      "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99",
        "outputId": "63146c5c-665e-45ff-8f86-afba54563d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current_data_dump/ada_autoencoder/global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_training_plot = ggplot(loaded_global_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Unshuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_training_plot, \"current_data_dump/ada_autoencoder/global_training_plot.png\")"
      ],
      "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shuffled training history"
      ],
      "metadata": {
        "id": "bSIwS6ydDdXI"
      },
      "id": "bSIwS6ydDdXI"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "lJoOOL9EbNzk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_shuffled_history = pd.DataFrame(pd.read_csv(\"current_data_dump/ada_autoencoder/global_shuffled_training_log.csv\"))\n",
        "loaded_global_shuffled_history = pd.melt(loaded_global_shuffled_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_shuffled_history = loaded_global_shuffled_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_shuffled_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_shuffled_history['shuffled'] = False"
      ],
      "id": "lJoOOL9EbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TK0YRBXybNzl",
        "outputId": "f559b916-7f44-4f0d-f0f9-5cb02b2d71d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current_data_dump/ada_autoencoder/global_shuffled_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_shuffled_training_plot = ggplot(loaded_global_shuffled_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Shuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_shuffled_training_plot, \"current_data_dump/ada_autoencoder/global_shuffled_training_plot.png\")"
      ],
      "id": "TK0YRBXybNzl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYrWdyscsYt"
      },
      "source": [
        "## Combined Training Plots"
      ],
      "id": "nIYrWdyscsYt"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
      },
      "outputs": [],
      "source": [
        "combined_global_training_df = pd.concat([loaded_global_history, loaded_global_shuffled_history])"
      ],
      "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "e1197f06-5503-44a5-ba23-2858da1a82b2",
        "outputId": "819f0af1-4d1a-4d62-ab72-68ba826f214d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 16 x 24 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current_data_dump/ada_autoencoder/combined_global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "combined_global_plot = (\n",
        "  ggplot(combined_global_training_df, aes(x='epoch', y='accuracy', linetype='dataset', color='shuffled')) +\n",
        "  geom_line(size=2) +\n",
        "  labs(title='Learning Curve of Model Trained on Unshuffled vs. Within-Topic Shuffled Data', x='Epoch', y='Accuracy') +\n",
        "  theme(\n",
        "    figure_size=(16,24),\n",
        "    axis_title=element_text(size=32),\n",
        "    axis_text=element_text(size=24),\n",
        "    legend_title=element_text(size=32, lineheight=1.5),\n",
        "    legend_text=element_text(size=24, lineheight=1.5),\n",
        "    plot_title=element_text(size=40, wrap=True, lineheight=1.5),\n",
        "    legend_position=\"bottom\",\n",
        "    legend_key_width=64\n",
        "  ) +\n",
        "  guides(fill = guide_legend(byrow = True))\n",
        ")\n",
        "ggsave(combined_global_plot, \"current_data_dump/ada_autoencoder/combined_global_training_plot.png\")"
      ],
      "id": "e1197f06-5503-44a5-ba23-2858da1a82b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcX4eHsmdAP9"
      },
      "source": [
        "## Category and Debate Training"
      ],
      "id": "GcX4eHsmdAP9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
      },
      "source": [
        "#### Category Data (Economy)"
      ],
      "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
      },
      "outputs": [],
      "source": [
        "economy_embeddings_data = pd.read_pickle(\"current_data_dump/embeddings_dump/economy/economy_embeddings.pkl\")"
      ],
      "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
      },
      "outputs": [],
      "source": [
        "economy_training_df = prepare_training_df(economy_embeddings_data)\n",
        "economy_x_train = make_x_train(economy_training_df)\n",
        "economy_y_train = make_y_train(economy_training_df)\n",
        "economy_x_test = make_x_test(economy_training_df)\n",
        "economy_y_test = make_y_test(economy_training_df)"
      ],
      "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95100c2-7782-4acd-9a0d-699223584b59"
      },
      "source": [
        "#### Debate Data (Economy)"
      ],
      "id": "f95100c2-7782-4acd-9a0d-699223584b59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b961764-4605-47a6-87e8-817eeffe7470"
      },
      "outputs": [],
      "source": [
        "economy_debate_embeddings_data = pd.read_pickle(\"current_data_dump/embeddings_dump/economy/business_economy_general_house_would_prohibit_retailers_selling_certain_items_embeddings.pkl\")"
      ],
      "id": "8b961764-4605-47a6-87e8-817eeffe7470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
      },
      "outputs": [],
      "source": [
        "economy_debate_training_df = prepare_training_df(economy_debate_embeddings_data)\n",
        "economy_debate_x_train = make_x_train(economy_debate_training_df)\n",
        "economy_debate_y_train = make_y_train(economy_debate_training_df)\n",
        "economy_debate_x_test = make_x_test(economy_debate_training_df)\n",
        "economy_debate_y_test = make_y_test(economy_debate_training_df)"
      ],
      "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
      },
      "source": [
        "#### Category Training"
      ],
      "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
      },
      "outputs": [],
      "source": [
        "# Category Model\n",
        "category_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "category_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "category_autoencoder_model.fit(\n",
        "  x=economy_x_train,\n",
        "  y=economy_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data=(economy_x_test, economy_y_test)\n",
        ")"
      ],
      "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
      },
      "source": [
        "#### Debate Training"
      ],
      "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40b37636-96d3-4932-9d0e-6551b846730b"
      },
      "outputs": [],
      "source": [
        "# Debate Model\n",
        "debate_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "debate_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "debate_autoencoder_model.fit(\n",
        "  x=economy_debate_x_train,\n",
        "  y=economy_debate_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=5\n",
        ")"
      ],
      "id": "40b37636-96d3-4932-9d0e-6551b846730b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Export"
      ],
      "metadata": {
        "id": "KN2uP5TfHgmt"
      },
      "id": "KN2uP5TfHgmt"
    },
    {
      "cell_type": "code",
      "source": [
        "export_ada_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxBVn4xAHiDD",
        "outputId": "9e9c9039-8f4a-46b0-b70c-15817c3ec954"
      },
      "id": "cxBVn4xAHiDD",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: /content/current_data_dump/ada_autoencoder\n",
            "\n",
            "File: /content/current_data_dump/ada_autoencoder uploaded at osfstorage\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}