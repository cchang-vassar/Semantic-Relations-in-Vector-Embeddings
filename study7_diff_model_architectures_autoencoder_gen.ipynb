{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study7_diff_model_architectures_autoencoder_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
      },
      "source": [
        "# [ada-002] Autoencoder: Generate Corresponding Embedding"
      ],
      "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try 2 new architectures:\n",
        "\n",
        "\n",
        "1.   2 hidden layers: 1536*2 -> 1536\n",
        "2.   3 hidden layers: 1536\\*4 -> 1536\\*2 -> 1536\n",
        "\n"
      ],
      "metadata": {
        "id": "CvMCKKoYQ6Xf"
      },
      "id": "CvMCKKoYQ6Xf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "sfhHaEtuCFaZ"
      },
      "id": "sfhHaEtuCFaZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
      },
      "source": [
        "### Imports"
      ],
      "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK38cfNTYVw5",
        "outputId": "25b42c98-84ba-43aa-d1ee-3f32fdb5ba73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ],
      "id": "PK38cfNTYVw5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from scipy import spatial\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from plotnine import ggplot, geom_line, aes, ggsave, labs, theme, element_text, guides, guide_legend"
      ],
      "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_fc5dDySK5",
        "outputId": "c2c22193-2e16-4042-9145-bc5497ca0fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQTEV8ZsQtXD"
      },
      "outputs": [],
      "source": [
        "import osfclient.cli"
      ],
      "id": "WQTEV8ZsQtXD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxigtskT2dda"
      },
      "outputs": [],
      "source": [
        "from osfclient.api import OSF\n",
        "from osfclient.models import Project, Storage\n",
        "from io import BytesIO"
      ],
      "id": "cxigtskT2dda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
      },
      "source": [
        "## Data"
      ],
      "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFnWt4JYqWi"
      },
      "source": [
        "### Import training data from OSF"
      ],
      "id": "vIFnWt4JYqWi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxpT2Q9yYpzD",
        "outputId": "f3a586ba-3e5e-4481-b038-4fbd0aa2623f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 128M/128M [00:02<00:00, 61.3Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/data-dump/ada-autoencoder/ada_autoencoder.zip"
      ],
      "id": "UxpT2Q9yYpzD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KuvkPngZtcz",
        "outputId": "403da29b-5db2-400f-d818-cedf9e9b2c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 52.6M/52.6M [00:00<00:00, 82.5Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/data-dump/ada-autoencoder/ada_embeddings_dump.zip"
      ],
      "id": "8KuvkPngZtcz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz8qXrcYZh3e",
        "outputId": "e32a8c9a-d86a-49f0-94ae-e205ee098164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['global_shuffled_autoencoder_model.keras', 'global_training_plot.png', 'global_shuffled_training_plot.png', 'global_autoencoder_model.keras', 'global_training_log.csv', 'global_training_df.pkl', 'combined_global_training_plot.png', 'global_shuffled_training_log.csv', '.ipynb_checkpoints']\n"
          ]
        }
      ],
      "source": [
        "ada_autoencoder_file_path = 'ada_autoencoder.zip'\n",
        "output_folder_path = 'current-data-dump/ada-autoencoder'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "id": "fz8qXrcYZh3e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare training data"
      ],
      "metadata": {
        "id": "l1bbs8pZUZrn"
      },
      "id": "l1bbs8pZUZrn"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_x_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Make training and testing datasets\"\"\"\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  train_rows_df = data.iloc[:cutoff, :]\n",
        "  x_train = train_rows_df[train_rows_df.index % 2 == 0].reset_index(drop=True)\n",
        "  return x_train\n",
        "\n",
        "def make_y_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  train_rows_df = data.iloc[:cutoff, :]\n",
        "  y_train = train_rows_df[train_rows_df.index % 2 != 0].reset_index(drop=True)\n",
        "  return y_train\n",
        "\n",
        "def make_x_test(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  test_rows_df = data.iloc[cutoff:, :]\n",
        "  x_test = test_rows_df[test_rows_df.index % 2 == 0].reset_index(drop=True)\n",
        "  return x_test\n",
        "\n",
        "def make_y_test(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  test_rows_df = data.iloc[cutoff:, :]\n",
        "  y_test = test_rows_df[test_rows_df.index % 2 != 0].reset_index(drop=True)\n",
        "  return y_test"
      ],
      "metadata": {
        "id": "hcglrajCU-97"
      },
      "id": "hcglrajCU-97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_training_df = pd.read_pickle('ada-autoencoder/global_training_df.pkl')"
      ],
      "metadata": {
        "id": "bYJ9PabPT3Ul"
      },
      "id": "bYJ9PabPT3Ul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_x_train = make_x_train(global_training_df)\n",
        "global_y_train = make_y_train(global_training_df)\n",
        "global_x_test = make_x_test(global_training_df)\n",
        "global_y_test = make_y_test(global_training_df)"
      ],
      "metadata": {
        "id": "eVUrmrvhUbTa"
      },
      "id": "eVUrmrvhUbTa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYS3gnudicT"
      },
      "source": [
        "## Metric"
      ],
      "id": "bfYS3gnudicT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  \"\"\"global_metric\"\"\"\n",
        "  global_training_df_32 = tf.cast(global_training_df, dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
      },
      "source": [
        "## 2-layer model"
      ],
      "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdhQDH3Hdf2d"
      },
      "source": [
        "### 2-layer architecture"
      ],
      "id": "wdhQDH3Hdf2d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92def071-b058-49c3-9573-6ee31d041244"
      },
      "outputs": [],
      "source": [
        "# Layers\n",
        "input_layer = tf.keras.layers.Input(shape=(1536, ), name=\"Input\")\n",
        "hidden_layer_1 = tf.keras.layers.Dense(units=1536*2, activation=\"relu\", name=\"Hidden1\")(input_layer)\n",
        "hidden_layer_2 = tf.keras.layers.Dense(units=1536, activation=\"relu\", name=\"Hidden2\")(hidden_layer_1)\n",
        "output_layer = tf.keras.layers.Dense(units=1536, activation=\"linear\", name=\"Output\")(hidden_layer_2)"
      ],
      "id": "92def071-b058-49c3-9573-6ee31d041244"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00",
        "outputId": "38161801-bd8e-4141-f3f0-c335b15c8402",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 1536)]            0         \n",
            "                                                                 \n",
            " Hidden1 (Dense)             (None, 3072)              4721664   \n",
            "                                                                 \n",
            " Hidden2 (Dense)             (None, 1536)              4720128   \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11802624 (45.02 MB)\n",
            "Trainable params: 11802624 (45.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "autoencoder_model_2_layer = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder_model_2_layer.summary()"
      ],
      "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
      },
      "source": [
        "### Global Training"
      ],
      "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "global_autoencoder_model_2_layer = autoencoder_model_2_layer\n",
        "global_autoencoder_model_2_layer.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")"
      ],
      "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619a8fe5-de4a-4a80-867d-b7af0e4b9f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3248/3252 [============================>.] - ETA: 0s - loss: -0.8754 - metric_choose_argument_global_y_train: 0.0157\n",
            "Epoch 1: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 47s 10ms/step - loss: -0.8755 - metric_choose_argument_global_y_train: 0.0157 - val_loss: -0.8858 - val_metric_choose_argument_global_y_train: 0.0197\n",
            "Epoch 2/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9009 - metric_choose_argument_global_y_train: 0.0643\n",
            "Epoch 2: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 27s 8ms/step - loss: -0.9009 - metric_choose_argument_global_y_train: 0.0643 - val_loss: -0.8972 - val_metric_choose_argument_global_y_train: 0.0652\n",
            "Epoch 3/20\n",
            "3248/3252 [============================>.] - ETA: 0s - loss: -0.9121 - metric_choose_argument_global_y_train: 0.1192\n",
            "Epoch 3: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 26s 8ms/step - loss: -0.9121 - metric_choose_argument_global_y_train: 0.1193 - val_loss: -0.9025 - val_metric_choose_argument_global_y_train: 0.1132\n",
            "Epoch 4/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9198 - metric_choose_argument_global_y_train: 0.1993\n",
            "Epoch 4: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 26s 8ms/step - loss: -0.9198 - metric_choose_argument_global_y_train: 0.1993 - val_loss: -0.9064 - val_metric_choose_argument_global_y_train: 0.1501\n",
            "Epoch 5/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9262 - metric_choose_argument_global_y_train: 0.3001\n",
            "Epoch 5: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 26s 8ms/step - loss: -0.9262 - metric_choose_argument_global_y_train: 0.3001 - val_loss: -0.9095 - val_metric_choose_argument_global_y_train: 0.1894\n",
            "Epoch 6/20\n",
            "3247/3252 [============================>.] - ETA: 0s - loss: -0.9317 - metric_choose_argument_global_y_train: 0.4019\n",
            "Epoch 6: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 36s 11ms/step - loss: -0.9317 - metric_choose_argument_global_y_train: 0.4019 - val_loss: -0.9118 - val_metric_choose_argument_global_y_train: 0.2522\n",
            "Epoch 7/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9362 - metric_choose_argument_global_y_train: 0.5243\n",
            "Epoch 7: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 30s 9ms/step - loss: -0.9363 - metric_choose_argument_global_y_train: 0.5246 - val_loss: -0.9124 - val_metric_choose_argument_global_y_train: 0.2780\n",
            "Epoch 8/20\n",
            "3246/3252 [============================>.] - ETA: 0s - loss: -0.9405 - metric_choose_argument_global_y_train: 0.6128\n",
            "Epoch 8: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 28s 9ms/step - loss: -0.9405 - metric_choose_argument_global_y_train: 0.6125 - val_loss: -0.9138 - val_metric_choose_argument_global_y_train: 0.3186\n",
            "Epoch 9/20\n",
            "3248/3252 [============================>.] - ETA: 0s - loss: -0.9440 - metric_choose_argument_global_y_train: 0.7017\n",
            "Epoch 9: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 28s 9ms/step - loss: -0.9440 - metric_choose_argument_global_y_train: 0.7014 - val_loss: -0.9137 - val_metric_choose_argument_global_y_train: 0.3296\n",
            "Epoch 10/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9473 - metric_choose_argument_global_y_train: 0.7718\n",
            "Epoch 10: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 29s 9ms/step - loss: -0.9473 - metric_choose_argument_global_y_train: 0.7715 - val_loss: -0.9141 - val_metric_choose_argument_global_y_train: 0.3616\n",
            "Epoch 11/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9502 - metric_choose_argument_global_y_train: 0.8219\n",
            "Epoch 11: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 27s 8ms/step - loss: -0.9502 - metric_choose_argument_global_y_train: 0.8220 - val_loss: -0.9151 - val_metric_choose_argument_global_y_train: 0.3702\n",
            "Epoch 12/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9527 - metric_choose_argument_global_y_train: 0.8606\n",
            "Epoch 12: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 27s 8ms/step - loss: -0.9527 - metric_choose_argument_global_y_train: 0.8607 - val_loss: -0.9160 - val_metric_choose_argument_global_y_train: 0.3788\n",
            "Epoch 13/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9549 - metric_choose_argument_global_y_train: 0.8834\n",
            "Epoch 13: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 33s 10ms/step - loss: -0.9549 - metric_choose_argument_global_y_train: 0.8835 - val_loss: -0.9156 - val_metric_choose_argument_global_y_train: 0.3948\n",
            "Epoch 14/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9569 - metric_choose_argument_global_y_train: 0.9086\n",
            "Epoch 14: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 28s 9ms/step - loss: -0.9569 - metric_choose_argument_global_y_train: 0.9087 - val_loss: -0.9163 - val_metric_choose_argument_global_y_train: 0.3948\n",
            "Epoch 15/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9585 - metric_choose_argument_global_y_train: 0.9182\n",
            "Epoch 15: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 31s 10ms/step - loss: -0.9585 - metric_choose_argument_global_y_train: 0.9182 - val_loss: -0.9164 - val_metric_choose_argument_global_y_train: 0.3985\n",
            "Epoch 16/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9601 - metric_choose_argument_global_y_train: 0.9360\n",
            "Epoch 16: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 27s 8ms/step - loss: -0.9601 - metric_choose_argument_global_y_train: 0.9360 - val_loss: -0.9165 - val_metric_choose_argument_global_y_train: 0.4010\n",
            "Epoch 17/20\n",
            "3245/3252 [============================>.] - ETA: 0s - loss: -0.9615 - metric_choose_argument_global_y_train: 0.9418\n",
            "Epoch 17: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 26s 8ms/step - loss: -0.9615 - metric_choose_argument_global_y_train: 0.9419 - val_loss: -0.9166 - val_metric_choose_argument_global_y_train: 0.4047\n",
            "Epoch 18/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9627 - metric_choose_argument_global_y_train: 0.9468\n",
            "Epoch 18: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 29s 9ms/step - loss: -0.9627 - metric_choose_argument_global_y_train: 0.9468 - val_loss: -0.9164 - val_metric_choose_argument_global_y_train: 0.4034\n",
            "Epoch 19/20\n",
            "3246/3252 [============================>.] - ETA: 0s - loss: -0.9637 - metric_choose_argument_global_y_train: 0.9513\n",
            "Epoch 19: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 27s 8ms/step - loss: -0.9637 - metric_choose_argument_global_y_train: 0.9514 - val_loss: -0.9171 - val_metric_choose_argument_global_y_train: 0.4157\n",
            "Epoch 20/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9647 - metric_choose_argument_global_y_train: 0.9600\n",
            "Epoch 20: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 26s 8ms/step - loss: -0.9647 - metric_choose_argument_global_y_train: 0.9600 - val_loss: -0.9165 - val_metric_choose_argument_global_y_train: 0.4133\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath='global_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
        "csv_logger_callback = CSVLogger(filename='global_training_log.csv', separator=',', append=True)\n",
        "global_history_2_layer = global_autoencoder_model_2_layer.fit(\n",
        "  x=global_x_train,\n",
        "  y=global_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (global_x_test, global_y_test),\n",
        "  callbacks=[checkpoint_callback, csv_logger_callback]\n",
        ")"
      ],
      "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
      },
      "outputs": [],
      "source": [
        "global_history_df_2_layer = pd.DataFrame(global_history_2_layer.history)"
      ],
      "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada-autoencoder/other-architectures/2-layer-architecture/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_history_df_2_layer.to_csv(f'{output_folder_path}global_training_log.csv')\n",
        "global_autoencoder_model_2_layer.save(f'{output_folder_path}global_autoencoder_model.keras')"
      ],
      "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCBehA7XWssa"
      },
      "source": [
        "## 3-layer model"
      ],
      "id": "OCBehA7XWssa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fb5ygfsWssb"
      },
      "source": [
        "### 3-layer architecture"
      ],
      "id": "7fb5ygfsWssb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IkmzdyIWssb"
      },
      "outputs": [],
      "source": [
        "# Layers\n",
        "input_layer = tf.keras.layers.Input(shape=(1536, ), name=\"Input\")\n",
        "hidden_layer_1 = tf.keras.layers.Dense(units=1536*4, activation=\"relu\", name=\"Hidden1\")(input_layer)\n",
        "hidden_layer_2 = tf.keras.layers.Dense(units=1536*2, activation=\"relu\", name=\"Hidden2\")(hidden_layer_1)\n",
        "hidden_layer_3 = tf.keras.layers.Dense(units=1536, activation=\"relu\", name=\"Hidden3\")(hidden_layer_2)\n",
        "output_layer = tf.keras.layers.Dense(units=1536, activation=\"linear\", name=\"Output\")(hidden_layer_3)"
      ],
      "id": "5IkmzdyIWssb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "305b02a7-9989-442a-de8d-b8947e62f1b1",
        "scrolled": true,
        "id": "YuF_DYjGWssb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 1536)]            0         \n",
            "                                                                 \n",
            " Hidden1 (Dense)             (None, 6144)              9443328   \n",
            "                                                                 \n",
            " Hidden2 (Dense)             (None, 3072)              18877440  \n",
            "                                                                 \n",
            " Hidden3 (Dense)             (None, 1536)              4720128   \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35401728 (135.05 MB)\n",
            "Trainable params: 35401728 (135.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "autoencoder_model_3_layer = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder_model_3_layer.summary()"
      ],
      "id": "YuF_DYjGWssb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pg39NlsWssb"
      },
      "source": [
        "### Global Training"
      ],
      "id": "7Pg39NlsWssb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn-ZPftfWssc"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "global_autoencoder_model_3_layer = autoencoder_model_3_layer\n",
        "global_autoencoder_model_3_layer.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")"
      ],
      "id": "jn-ZPftfWssc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7cbe34-9171-4e59-edc1-25e232f97142",
        "id": "ksrxRX40Wssc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.8639 - metric_choose_argument_global_y_train: 0.0025\n",
            "Epoch 1: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 77s 20ms/step - loss: -0.8639 - metric_choose_argument_global_y_train: 0.0025 - val_loss: -0.8696 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 2/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.8846 - metric_choose_argument_global_y_train: 0.0132\n",
            "Epoch 2: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8846 - metric_choose_argument_global_y_train: 0.0132 - val_loss: -0.8801 - val_metric_choose_argument_global_y_train: 0.0074\n",
            "Epoch 3/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.8943 - metric_choose_argument_global_y_train: 0.0274\n",
            "Epoch 3: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 52s 16ms/step - loss: -0.8943 - metric_choose_argument_global_y_train: 0.0274 - val_loss: -0.8885 - val_metric_choose_argument_global_y_train: 0.0209\n",
            "Epoch 4/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9023 - metric_choose_argument_global_y_train: 0.0532\n",
            "Epoch 4: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 54s 17ms/step - loss: -0.9023 - metric_choose_argument_global_y_train: 0.0532 - val_loss: -0.8924 - val_metric_choose_argument_global_y_train: 0.0295\n",
            "Epoch 5/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9086 - metric_choose_argument_global_y_train: 0.0871\n",
            "Epoch 5: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 51s 16ms/step - loss: -0.9086 - metric_choose_argument_global_y_train: 0.0870 - val_loss: -0.8976 - val_metric_choose_argument_global_y_train: 0.0517\n",
            "Epoch 6/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9140 - metric_choose_argument_global_y_train: 0.1173\n",
            "Epoch 6: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 54s 16ms/step - loss: -0.9140 - metric_choose_argument_global_y_train: 0.1172 - val_loss: -0.9006 - val_metric_choose_argument_global_y_train: 0.0873\n",
            "Epoch 7/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9184 - metric_choose_argument_global_y_train: 0.1674\n",
            "Epoch 7: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 55s 17ms/step - loss: -0.9184 - metric_choose_argument_global_y_train: 0.1676 - val_loss: -0.9024 - val_metric_choose_argument_global_y_train: 0.0898\n",
            "Epoch 8/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9224 - metric_choose_argument_global_y_train: 0.2102\n",
            "Epoch 8: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 56s 17ms/step - loss: -0.9224 - metric_choose_argument_global_y_train: 0.2106 - val_loss: -0.9031 - val_metric_choose_argument_global_y_train: 0.1255\n",
            "Epoch 9/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9258 - metric_choose_argument_global_y_train: 0.2684\n",
            "Epoch 9: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 56s 17ms/step - loss: -0.9258 - metric_choose_argument_global_y_train: 0.2681 - val_loss: -0.9041 - val_metric_choose_argument_global_y_train: 0.1611\n",
            "Epoch 10/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9288 - metric_choose_argument_global_y_train: 0.3376\n",
            "Epoch 10: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 60s 18ms/step - loss: -0.9288 - metric_choose_argument_global_y_train: 0.3376 - val_loss: -0.9062 - val_metric_choose_argument_global_y_train: 0.1722\n",
            "Epoch 11/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9315 - metric_choose_argument_global_y_train: 0.3887\n",
            "Epoch 11: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 55s 17ms/step - loss: -0.9315 - metric_choose_argument_global_y_train: 0.3884 - val_loss: -0.9073 - val_metric_choose_argument_global_y_train: 0.2116\n",
            "Epoch 12/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9340 - metric_choose_argument_global_y_train: 0.4551\n",
            "Epoch 12: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 52s 16ms/step - loss: -0.9340 - metric_choose_argument_global_y_train: 0.4551 - val_loss: -0.9076 - val_metric_choose_argument_global_y_train: 0.2472\n",
            "Epoch 13/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9363 - metric_choose_argument_global_y_train: 0.5143\n",
            "Epoch 13: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 60s 19ms/step - loss: -0.9363 - metric_choose_argument_global_y_train: 0.5145 - val_loss: -0.9087 - val_metric_choose_argument_global_y_train: 0.2669\n",
            "Epoch 14/20\n",
            "3251/3252 [============================>.] - ETA: 0s - loss: -0.9385 - metric_choose_argument_global_y_train: 0.5672\n",
            "Epoch 14: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 55s 17ms/step - loss: -0.9385 - metric_choose_argument_global_y_train: 0.5670 - val_loss: -0.9091 - val_metric_choose_argument_global_y_train: 0.2632\n",
            "Epoch 15/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9405 - metric_choose_argument_global_y_train: 0.6077\n",
            "Epoch 15: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 52s 16ms/step - loss: -0.9405 - metric_choose_argument_global_y_train: 0.6079 - val_loss: -0.9092 - val_metric_choose_argument_global_y_train: 0.2804\n",
            "Epoch 16/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9423 - metric_choose_argument_global_y_train: 0.6556\n",
            "Epoch 16: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 57s 18ms/step - loss: -0.9423 - metric_choose_argument_global_y_train: 0.6556 - val_loss: -0.9104 - val_metric_choose_argument_global_y_train: 0.3161\n",
            "Epoch 17/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9441 - metric_choose_argument_global_y_train: 0.6978\n",
            "Epoch 17: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 51s 16ms/step - loss: -0.9441 - metric_choose_argument_global_y_train: 0.6980 - val_loss: -0.9100 - val_metric_choose_argument_global_y_train: 0.3223\n",
            "Epoch 18/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9456 - metric_choose_argument_global_y_train: 0.7403\n",
            "Epoch 18: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 55s 17ms/step - loss: -0.9456 - metric_choose_argument_global_y_train: 0.7399 - val_loss: -0.9105 - val_metric_choose_argument_global_y_train: 0.3358\n",
            "Epoch 19/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9471 - metric_choose_argument_global_y_train: 0.7654\n",
            "Epoch 19: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 52s 16ms/step - loss: -0.9471 - metric_choose_argument_global_y_train: 0.7654 - val_loss: -0.9114 - val_metric_choose_argument_global_y_train: 0.3407\n",
            "Epoch 20/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9486 - metric_choose_argument_global_y_train: 0.7977\n",
            "Epoch 20: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 56s 17ms/step - loss: -0.9486 - metric_choose_argument_global_y_train: 0.7977 - val_loss: -0.9111 - val_metric_choose_argument_global_y_train: 0.3518\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath='global_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
        "csv_logger_callback = CSVLogger(filename='global_training_log.csv', separator=',', append=True)\n",
        "global_history_3_layer = global_autoencoder_model_3_layer.fit(\n",
        "  x=global_x_train,\n",
        "  y=global_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (global_x_test, global_y_test),\n",
        "  callbacks=[checkpoint_callback, csv_logger_callback]\n",
        ")"
      ],
      "id": "ksrxRX40Wssc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "866LucpKWssc"
      },
      "outputs": [],
      "source": [
        "global_history_df_3_layer = pd.DataFrame(global_history_3_layer.history)"
      ],
      "id": "866LucpKWssc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh73vzfYWssc"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada-autoencoder/other-architectures/3-layer-architecture/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_history_df_3_layer.to_csv(f'{output_folder_path}global_training_log.csv')\n",
        "global_autoencoder_model_3_layer.save(f'{output_folder_path}global_autoencoder_model.keras')"
      ],
      "id": "Rh73vzfYWssc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TucNWIIdnBs"
      },
      "source": [
        "## Plot training history"
      ],
      "id": "8TucNWIIdnBs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-layer architecture training history"
      ],
      "metadata": {
        "id": "JY2RndZJDXxt"
      },
      "id": "JY2RndZJDXxt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "global_history_2_layer = pd.DataFrame(pd.read_csv('current-data-dump/ada-autoencoder/other-architectures/2-layer-architecture/global_training_log.csv'))\n",
        "global_history_2_layer = pd.melt(global_history_2_layer, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "global_history_2_layer = global_history_2_layer.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "global_history_2_layer.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "global_history_2_layer['layers'] = '2'"
      ],
      "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1222c3c5-472e-4efd-f455-46ebdc313d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada-autoencoder/other-architectures/2-layer-architecture/global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_training_plot_2_layer = ggplot(global_history_2_layer, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Unshuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_training_plot_2_layer, \"current-data-dump/ada-autoencoder/other-architectures/2-layer-architecture/global_training_plot.png\")"
      ],
      "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-layer architecture training history"
      ],
      "metadata": {
        "id": "bSIwS6ydDdXI"
      },
      "id": "bSIwS6ydDdXI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJoOOL9EbNzk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "global_history_3_layer = pd.DataFrame(pd.read_csv(\"current-data-dump/ada-autoencoder/other-architectures/3-layer-architecture/global_training_log.csv\"))\n",
        "global_history_3_layer = pd.melt(global_history_3_layer, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "global_history_3_layer = global_history_3_layer.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "global_history_3_layer.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "global_history_3_layer['layers'] = '3'"
      ],
      "id": "lJoOOL9EbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK0YRBXybNzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e5a9c3-20ec-40a7-b335-097096a536cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada-autoencoder/other-architectures/3-layer-architecture/global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_training_plot_3_layer = ggplot(global_history_3_layer, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Shuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_training_plot_3_layer, \"current-data-dump/ada-autoencoder/other-architectures/3-layer-architecture/global_training_plot.png\")"
      ],
      "id": "TK0YRBXybNzl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYrWdyscsYt"
      },
      "source": [
        "## Combined Training Plots"
      ],
      "id": "nIYrWdyscsYt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
      },
      "outputs": [],
      "source": [
        "combined_global_training_df = pd.concat([global_history_2_layer, global_history_3_layer])"
      ],
      "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1197f06-5503-44a5-ba23-2858da1a82b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5100d0-f522-47f0-9875-51947b03d7d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 16 x 24 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada-autoencoder/other-architectures/combined_global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "combined_global_plot = (\n",
        "  ggplot(combined_global_training_df, aes(x='epoch', y='accuracy', linetype='dataset', color='layers')) +\n",
        "  geom_line(size=2) +\n",
        "  labs(title='Learning Curve of 2-Layer vs 3-Layer Model', x='Epoch', y='Accuracy') +\n",
        "  theme(\n",
        "    figure_size=(16,24),\n",
        "    axis_title=element_text(size=32),\n",
        "    axis_text=element_text(size=24),\n",
        "    legend_title=element_text(size=32, lineheight=1.5),\n",
        "    legend_text=element_text(size=24, lineheight=1.5),\n",
        "    plot_title=element_text(size=40, wrap=True, lineheight=1.5),\n",
        "    legend_position=\"bottom\",\n",
        "    legend_key_width=64\n",
        "  ) +\n",
        "  guides(fill = guide_legend(byrow = True))\n",
        ")\n",
        "ggsave(combined_global_plot, \"current-data-dump/ada-autoencoder/other-architectures/combined_global_training_plot.png\")"
      ],
      "id": "e1197f06-5503-44a5-ba23-2858da1a82b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Export"
      ],
      "metadata": {
        "id": "KN2uP5TfHgmt"
      },
      "id": "KN2uP5TfHgmt"
    },
    {
      "cell_type": "code",
      "source": [
        "other_architectures_file_path = 'current-data-dump/ada-autoencoder/other-architectures/'\n",
        "other_architectures_file_path_zip = 'current-data-dump/ada-autoencoder/other-architectures/'\n",
        "shutil.make_archive(other_architectures_file_path_zip, 'zip', other_architectures_file_path)\n",
        "print(f\"Zip file created at: {other_architectures_file_path_zip}\")\n",
        "result = subprocess.run([f\"osf -p sakjg upload --force {other_architectures_file_path_zip}.zip data-dump/ada-autoencoder/other_architectures.zip\"], shell=True, capture_output=True, text=True)\n",
        "print(result.stderr)\n",
        "print(f\"File: {other_architectures_file_path_zip} uploaded at osfstorage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDPaYw1AaMbW",
        "outputId": "7d0519a7-f851-4774-aa4f-ff1173a3d75b"
      },
      "id": "sDPaYw1AaMbW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: current-data-dump/ada-autoencoder/other-architectures/\n",
            "\n",
            "File: current-data-dump/ada-autoencoder/other-architectures/ uploaded at osfstorage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "HwCx1sldDjMC"
      },
      "id": "HwCx1sldDjMC"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada-autoencoder/other_architectures.zip\", shell=True)\n",
        "print(\"other_architectures.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'other_architectures.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/ada-autoencoder/other-architectures'\n",
        "os.makedirs(ada_autoencoder_file_path, exist_ok=True)\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "I5nxJr5bGDTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b7cee9-9614-46e4-fefa-7779080cd129"
      },
      "id": "I5nxJr5bGDTR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "other_architectures.zip successfully imported\n",
            "Files extracted: ['3-layer-architecture', '.zip', 'combined_global_training_plot.png', '2-layer-architecture']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}