{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study2_6_%5Bnomic%5D_counterev_autoencoder_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
      },
      "source": [
        "# [nomic] Autoencoder: Generate Corresponding Embedding"
      ],
      "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "sfhHaEtuCFaZ"
      },
      "id": "sfhHaEtuCFaZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
      },
      "source": [
        "### Imports"
      ],
      "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK38cfNTYVw5",
        "outputId": "062fbec1-70e8-4198-c81e-820f3e34098b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ],
      "id": "PK38cfNTYVw5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from scipy import spatial\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from plotnine import ggplot, geom_line, aes, ggsave, labs, theme, element_text, guides, guide_legend"
      ],
      "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_fc5dDySK5",
        "outputId": "b54773a3-3872-49ec-bc3f-f33d752a6cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQTEV8ZsQtXD"
      },
      "outputs": [],
      "source": [
        "import osfclient.cli"
      ],
      "id": "WQTEV8ZsQtXD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxigtskT2dda"
      },
      "outputs": [],
      "source": [
        "from osfclient.api import OSF\n",
        "from osfclient.models import Project, Storage\n",
        "from io import BytesIO"
      ],
      "id": "cxigtskT2dda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
      },
      "source": [
        "## Data"
      ],
      "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFnWt4JYqWi"
      },
      "source": [
        "### Import corpora data from OSF"
      ],
      "id": "vIFnWt4JYqWi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KuvkPngZtcz",
        "outputId": "f1127e16-a159-4b6d-996c-022cf057b749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0.00/17.7M [00:00<?, ?bytes/s]\r 43% 7.55M/17.7M [00:00<00:00, 75.3Mbytes/s]\r 95% 16.8M/17.7M [00:00<00:00, 61.3Mbytes/s]\r100% 17.7M/17.7M [00:00<00:00, 65.2Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/data-dump/nomic-autoencoder/nomic_evidence_embeddings_dump.zip"
      ],
      "id": "8KuvkPngZtcz"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_file_path = 'nomic_evidence_embeddings_dump.zip'\n",
        "output_folder_path = 'current-data-dump/embeddings-dump'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(embeddings_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkPaiT5xIdeZ",
        "outputId": "66425ed5-f615-4b4c-a7b3-2eed0c092f84"
      },
      "id": "ZkPaiT5xIdeZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['argument_embeddings.pkl', 'evidence_embeddings.pkl', 'bad_argument_embeddings.pkl', 'bad_evidence_embeddings.pkl', '.ipynb_checkpoints']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_pickle('current-data-dump/embeddings-dump/argument_embeddings.pkl')\n",
        "y = pd.read_pickle('current-data-dump/embeddings-dump/evidence_embeddings.pkl')\n",
        "x_train = x.iloc[:1499]\n",
        "x_test = x.iloc[1499:]\n",
        "y_train = y.iloc[:1499]\n",
        "y_train = y_train.rename(columns={'argument': 'evidence'})\n",
        "y_test = y.iloc[1499:]\n",
        "y_test = y_test.rename(columns={'argument': 'evidence'})\n",
        "combined_train_df = pd.concat([x_train, y_train], axis=1).reset_index(drop=True)\n",
        "combined_test_df = pd.concat([x_test, y_test], axis=1).reset_index(drop=True)\n",
        "\n",
        "combined_train_df = combined_train_df.groupby('argument').sample(1)\n",
        "combined_test_df = combined_test_df.groupby('argument').sample(1)\n",
        "x_train = combined_train_df.iloc[:, 1:769].reset_index(drop=True)\n",
        "y_train = combined_train_df.iloc[:, 770:1538].reset_index(drop=True)\n",
        "x_test = combined_test_df.iloc[:, 1:769].reset_index(drop=True)\n",
        "y_test = combined_test_df.iloc[:, 770:1538].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "iH96OsgnsZBR"
      },
      "id": "iH96OsgnsZBR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
      },
      "source": [
        "### Make global data shuffled"
      ],
      "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
      },
      "outputs": [],
      "source": [
        "y_train_shuffled = y_train.copy().sample(frac=1).reset_index(drop=True)"
      ],
      "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save global training df"
      ],
      "metadata": {
        "id": "bxCtUU3xJxMG"
      },
      "id": "bxCtUU3xJxMG"
    },
    {
      "cell_type": "code",
      "source": [
        "global_x_train_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "global_x_train_file_path = f'{global_x_train_folder_path}global_x_train.pkl'\n",
        "global_y_train_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "global_y_train_file_path = f'{global_x_train_folder_path}global_y_train.pkl'\n",
        "os.makedirs(global_x_train_folder_path, exist_ok=True)\n",
        "os.makedirs(global_y_train_folder_path, exist_ok=True)\n",
        "with open(global_x_train_file_path, 'wb') as file:\n",
        "  pickle.dump(x_train, file)\n",
        "  print(f\"File uploaded to {global_x_train_file_path}\")\n",
        "with open(global_y_train_file_path, 'wb') as file:\n",
        "  pickle.dump(y_train, file)\n",
        "  print(f\"File uploaded to {global_y_train_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrMv_TJKJ0h5",
        "outputId": "6cbaf2db-d6ce-4dae-9989-4d3df462f6a0"
      },
      "id": "mrMv_TJKJ0h5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded to current-data-dump/nomic-autoencoder/global_x_train.pkl\n",
            "File uploaded to current-data-dump/nomic-autoencoder/global_y_train.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_x_test_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "global_x_test_file_path = f'{global_x_test_folder_path}global_x_test.pkl'\n",
        "global_y_test_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "global_y_test_file_path = f'{global_x_test_folder_path}global_y_test.pkl'\n",
        "os.makedirs(global_x_test_folder_path, exist_ok=True)\n",
        "os.makedirs(global_y_test_folder_path, exist_ok=True)\n",
        "with open(global_x_test_file_path, 'wb') as file:\n",
        "  pickle.dump(x_test, file)\n",
        "  print(f\"File uploaded to {global_x_test_file_path}\")\n",
        "with open(global_y_test_file_path, 'wb') as file:\n",
        "  pickle.dump(y_test, file)\n",
        "  print(f\"File uploaded to {global_y_test_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kibA0i0aD3I7",
        "outputId": "dc5eead0-fcee-4192-ad0f-e2f31ff8d14f"
      },
      "id": "kibA0i0aD3I7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded to current-data-dump/nomic-autoencoder/global_x_test.pkl\n",
            "File uploaded to current-data-dump/nomic-autoencoder/global_y_test.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
      },
      "source": [
        "## Model"
      ],
      "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdhQDH3Hdf2d"
      },
      "source": [
        "### Architecture"
      ],
      "id": "wdhQDH3Hdf2d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92def071-b058-49c3-9573-6ee31d041244"
      },
      "outputs": [],
      "source": [
        "# Layers\n",
        "input_layer = tf.keras.layers.Input(shape=(768, ), name=\"Input\")\n",
        "hidden_layer = tf.keras.layers.Dense(units=768, activation=\"relu\", name=\"Hidden\")(input_layer)\n",
        "output_layer = tf.keras.layers.Dense(units=768, activation=\"linear\", name=\"Output\")(hidden_layer)"
      ],
      "id": "92def071-b058-49c3-9573-6ee31d041244"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00",
        "outputId": "bca451e4-cd19-4d99-9e6f-dab0bb17592f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 768)]             0         \n",
            "                                                                 \n",
            " Hidden (Dense)              (None, 768)               590592    \n",
            "                                                                 \n",
            " Output (Dense)              (None, 768)               590592    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1181184 (4.51 MB)\n",
            "Trainable params: 1181184 (4.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "autoencoder_model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder_model.summary()"
      ],
      "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYS3gnudicT"
      },
      "source": [
        "### Metric"
      ],
      "id": "bfYS3gnudicT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  \"\"\"global_metric\"\"\"\n",
        "  global_training_df_32 = tf.cast(x_train, dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
      },
      "source": [
        "### Global Training"
      ],
      "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "global_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")"
      ],
      "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7375f764-00ed-4fd5-c7c4-18657acf7639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.7021 - metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 1: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 5s 10ms/step - loss: -0.7045 - metric_choose_argument_global_y_train: 0.0000e+00 - val_loss: -0.7534 - val_metric_choose_argument_global_y_train: 0.0938\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.7596 - metric_choose_argument_global_y_train: 0.0141\n",
            "Epoch 2: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.7596 - metric_choose_argument_global_y_train: 0.0141 - val_loss: -0.7572 - val_metric_choose_argument_global_y_train: 0.1250\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.7774 - metric_choose_argument_global_y_train: 0.1127\n",
            "Epoch 3: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.7774 - metric_choose_argument_global_y_train: 0.1127 - val_loss: -0.7492 - val_metric_choose_argument_global_y_train: 0.0938\n",
            "Epoch 4/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.8060 - metric_choose_argument_global_y_train: 0.3000\n",
            "Epoch 4: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.8053 - metric_choose_argument_global_y_train: 0.2958 - val_loss: -0.7461 - val_metric_choose_argument_global_y_train: 0.1250\n",
            "Epoch 5/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.8410 - metric_choose_argument_global_y_train: 0.6029\n",
            "Epoch 5: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 7ms/step - loss: -0.8395 - metric_choose_argument_global_y_train: 0.5775 - val_loss: -0.7448 - val_metric_choose_argument_global_y_train: 0.1250\n",
            "Epoch 6/100\n",
            "64/71 [==========================>...] - ETA: 0s - loss: -0.8715 - metric_choose_argument_global_y_train: 0.7031\n",
            "Epoch 6: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 7ms/step - loss: -0.8688 - metric_choose_argument_global_y_train: 0.6901 - val_loss: -0.7353 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 7/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.8966 - metric_choose_argument_global_y_train: 0.7500\n",
            "Epoch 7: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 7ms/step - loss: -0.8957 - metric_choose_argument_global_y_train: 0.7606 - val_loss: -0.7173 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 8/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9189 - metric_choose_argument_global_y_train: 0.8358\n",
            "Epoch 8: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9190 - metric_choose_argument_global_y_train: 0.8451 - val_loss: -0.7147 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 9/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9394 - metric_choose_argument_global_y_train: 0.8657\n",
            "Epoch 9: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9385 - metric_choose_argument_global_y_train: 0.8592 - val_loss: -0.7168 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 10/100\n",
            "64/71 [==========================>...] - ETA: 0s - loss: -0.9507 - metric_choose_argument_global_y_train: 0.8750\n",
            "Epoch 10: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 7ms/step - loss: -0.9513 - metric_choose_argument_global_y_train: 0.8732 - val_loss: -0.7096 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 11/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9616 - metric_choose_argument_global_y_train: 0.9273\n",
            "Epoch 11: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9610 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.7063 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 12/100\n",
            "56/71 [======================>.......] - ETA: 0s - loss: -0.9716 - metric_choose_argument_global_y_train: 0.9286\n",
            "Epoch 12: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9693 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.7034 - val_metric_choose_argument_global_y_train: 0.2812\n",
            "Epoch 13/100\n",
            "53/71 [=====================>........] - ETA: 0s - loss: -0.9761 - metric_choose_argument_global_y_train: 0.9245\n",
            "Epoch 13: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9758 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.6982 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 14/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9802 - metric_choose_argument_global_y_train: 0.9444\n",
            "Epoch 14: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9802 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.7022 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 15/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9833 - metric_choose_argument_global_y_train: 0.9636\n",
            "Epoch 15: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9825 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.6931 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9859 - metric_choose_argument_global_y_train: 0.9718\n",
            "Epoch 16: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9859 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7049 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 17/100\n",
            "56/71 [======================>.......] - ETA: 0s - loss: -0.9875 - metric_choose_argument_global_y_train: 0.9821\n",
            "Epoch 17: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9877 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.6970 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 18/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9888 - metric_choose_argument_global_y_train: 0.9714\n",
            "Epoch 18: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9889 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7042 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 19/100\n",
            "56/71 [======================>.......] - ETA: 0s - loss: -0.9897 - metric_choose_argument_global_y_train: 0.9821\n",
            "Epoch 19: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9902 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7038 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 20/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9912 - metric_choose_argument_global_y_train: 0.9630\n",
            "Epoch 20: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9914 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7056 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 21/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9921 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 21: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9921 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7072 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 22/100\n",
            "56/71 [======================>.......] - ETA: 0s - loss: -0.9927 - metric_choose_argument_global_y_train: 0.9464\n",
            "Epoch 22: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9928 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7012 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 23/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9939 - metric_choose_argument_global_y_train: 0.9815\n",
            "Epoch 23: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9936 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7027 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 24/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9939 - metric_choose_argument_global_y_train: 0.9714\n",
            "Epoch 24: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9938 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7059 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 25/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9946 - metric_choose_argument_global_y_train: 0.9559\n",
            "Epoch 25: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9944 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7058 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 26/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9706\n",
            "Epoch 26: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7050 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 27/100\n",
            "56/71 [======================>.......] - ETA: 0s - loss: -0.9954 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 27: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9955 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7051 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 28/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9859\n",
            "Epoch 28: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7113 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 29/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9955 - metric_choose_argument_global_y_train: 0.9701\n",
            "Epoch 29: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7138 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 30/100\n",
            "64/71 [==========================>...] - ETA: 0s - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9844\n",
            "Epoch 30: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9953 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7150 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 31/100\n",
            "63/71 [=========================>....] - ETA: 0s - loss: -0.9951 - metric_choose_argument_global_y_train: 0.9841\n",
            "Epoch 31: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7094 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 32/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9947 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 32: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9948 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7068 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 33/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9948 - metric_choose_argument_global_y_train: 0.9420\n",
            "Epoch 33: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9948 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.7191 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 34/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9951 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 34: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9950 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7125 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 35/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9947 - metric_choose_argument_global_y_train: 0.9710\n",
            "Epoch 35: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9947 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7107 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 36/100\n",
            "59/71 [=======================>......] - ETA: 0s - loss: -0.9942 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 36: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9943 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7040 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 37/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9945 - metric_choose_argument_global_y_train: 0.9701\n",
            "Epoch 37: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9945 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7142 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 38/100\n",
            "66/71 [==========================>...] - ETA: 0s - loss: -0.9951 - metric_choose_argument_global_y_train: 0.9848\n",
            "Epoch 38: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9951 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7147 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 39/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9714\n",
            "Epoch 39: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 9ms/step - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7119 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 40/100\n",
            "61/71 [========================>.....] - ETA: 0s - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9836\n",
            "Epoch 40: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7125 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 41/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9955 - metric_choose_argument_global_y_train: 0.9630\n",
            "Epoch 41: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7082 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 42/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9955 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 42: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7227 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 43/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9403\n",
            "Epoch 43: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.7144 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 44/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9956 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 44: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7158 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 45/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9818\n",
            "Epoch 45: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7134 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 46/100\n",
            "53/71 [=====================>........] - ETA: 0s - loss: -0.9953 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 46: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9954 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7158 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 47/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9953 - metric_choose_argument_global_y_train: 0.9706\n",
            "Epoch 47: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9953 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7082 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 48/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9953 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 48: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7159 - val_metric_choose_argument_global_y_train: 0.2812\n",
            "Epoch 49/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9577\n",
            "Epoch 49: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7168 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 50/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9957 - metric_choose_argument_global_y_train: 0.9444\n",
            "Epoch 50: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9957 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7191 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 51/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9951 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 51: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9951 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7131 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 52/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9950 - metric_choose_argument_global_y_train: 0.9815\n",
            "Epoch 52: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7123 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 53/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9859\n",
            "Epoch 53: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7132 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 54/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9948 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 54: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9950 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7115 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 55/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9948 - metric_choose_argument_global_y_train: 0.9706\n",
            "Epoch 55: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9948 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7103 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 56/100\n",
            "61/71 [========================>.....] - ETA: 0s - loss: -0.9947 - metric_choose_argument_global_y_train: 0.9836\n",
            "Epoch 56: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9948 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7178 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 57/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9951 - metric_choose_argument_global_y_train: 0.9815\n",
            "Epoch 57: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9950 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7172 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 58/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9952 - metric_choose_argument_global_y_train: 0.9818\n",
            "Epoch 58: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9953 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7204 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 59/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 59: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9957 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7175 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 60/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9815\n",
            "Epoch 60: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9957 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7190 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 61/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9957 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 61: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9958 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7178 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 62/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9960 - metric_choose_argument_global_y_train: 0.9855\n",
            "Epoch 62: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9960 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7179 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 63/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9961 - metric_choose_argument_global_y_train: 0.9636\n",
            "Epoch 63: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9960 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7187 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 64/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9962 - metric_choose_argument_global_y_train: 0.9710\n",
            "Epoch 64: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9962 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7202 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 65/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9966 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 65: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7187 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 66/100\n",
            "63/71 [=========================>....] - ETA: 0s - loss: -0.9964 - metric_choose_argument_global_y_train: 0.9841\n",
            "Epoch 66: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7175 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 67/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 67: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7175 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 68/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9857\n",
            "Epoch 68: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 9ms/step - loss: -0.9964 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7199 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 69/100\n",
            "60/71 [========================>.....] - ETA: 0s - loss: -0.9964 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 69: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9964 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7193 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 70/100\n",
            "63/71 [=========================>....] - ETA: 0s - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9683\n",
            "Epoch 70: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7196 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 71/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9964 - metric_choose_argument_global_y_train: 0.9855\n",
            "Epoch 71: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9963 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7183 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 72/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9960 - metric_choose_argument_global_y_train: 0.9851\n",
            "Epoch 72: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9960 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7152 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 73/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9710\n",
            "Epoch 73: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7149 - val_metric_choose_argument_global_y_train: 0.2812\n",
            "Epoch 74/100\n",
            "66/71 [==========================>...] - ETA: 0s - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9848\n",
            "Epoch 74: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9959 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7198 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 75/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9577\n",
            "Epoch 75: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7228 - val_metric_choose_argument_global_y_train: 0.2812\n",
            "Epoch 76/100\n",
            "53/71 [=====================>........] - ETA: 0s - loss: -0.9954 - metric_choose_argument_global_y_train: 0.9623\n",
            "Epoch 76: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9956 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7190 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 77/100\n",
            "54/71 [=====================>........] - ETA: 0s - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9630\n",
            "Epoch 77: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9962 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7170 - val_metric_choose_argument_global_y_train: 0.3125\n",
            "Epoch 78/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9965 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 78: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7155 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 79/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9967 - metric_choose_argument_global_y_train: 0.9859\n",
            "Epoch 79: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9967 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7219 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 80/100\n",
            "65/71 [==========================>...] - ETA: 0s - loss: -0.9964 - metric_choose_argument_global_y_train: 0.9538\n",
            "Epoch 80: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9964 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.7202 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 81/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9964 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 81: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9964 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7196 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 82/100\n",
            "66/71 [==========================>...] - ETA: 0s - loss: -0.9962 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 82: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9963 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7186 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 83/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9963 - metric_choose_argument_global_y_train: 0.9714\n",
            "Epoch 83: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9963 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7196 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 84/100\n",
            "55/71 [======================>.......] - ETA: 0s - loss: -0.9958 - metric_choose_argument_global_y_train: 0.9636\n",
            "Epoch 84: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9961 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7220 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 85/100\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9961 - metric_choose_argument_global_y_train: 0.9718\n",
            "Epoch 85: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9961 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7210 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 86/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9964 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 86: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7211 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 87/100\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9968 - metric_choose_argument_global_y_train: 0.9710\n",
            "Epoch 87: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9967 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7256 - val_metric_choose_argument_global_y_train: 0.2812\n",
            "Epoch 88/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9972 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 88: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9972 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.7223 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 89/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9974 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 89: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9974 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7272 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 90/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9976 - metric_choose_argument_global_y_train: 0.9857\n",
            "Epoch 90: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9976 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7229 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 91/100\n",
            "66/71 [==========================>...] - ETA: 0s - loss: -0.9973 - metric_choose_argument_global_y_train: 0.9848\n",
            "Epoch 91: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9974 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7232 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 92/100\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9972 - metric_choose_argument_global_y_train: 0.9853\n",
            "Epoch 92: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9972 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7214 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 93/100\n",
            "64/71 [==========================>...] - ETA: 0s - loss: -0.9971 - metric_choose_argument_global_y_train: 0.9844\n",
            "Epoch 93: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9971 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7251 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 94/100\n",
            "66/71 [==========================>...] - ETA: 0s - loss: -0.9971 - metric_choose_argument_global_y_train: 0.9848\n",
            "Epoch 94: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9971 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7232 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 95/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9970 - metric_choose_argument_global_y_train: 0.9857\n",
            "Epoch 95: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9970 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7209 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 96/100\n",
            "62/71 [=========================>....] - ETA: 0s - loss: -0.9966 - metric_choose_argument_global_y_train: 1.0000\n",
            "Epoch 96: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7167 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 97/100\n",
            "59/71 [=======================>......] - ETA: 0s - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9153\n",
            "Epoch 97: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.7211 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 98/100\n",
            "63/71 [=========================>....] - ETA: 0s - loss: -0.9962 - metric_choose_argument_global_y_train: 0.9841\n",
            "Epoch 98: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9963 - metric_choose_argument_global_y_train: 0.9859 - val_loss: -0.7158 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 99/100\n",
            "62/71 [=========================>....] - ETA: 0s - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9677\n",
            "Epoch 99: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 7ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7192 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 100/100\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9966 - metric_choose_argument_global_y_train: 0.9701\n",
            "Epoch 100: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9965 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.7220 - val_metric_choose_argument_global_y_train: 0.2500\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath='global_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
        "csv_logger_callback = CSVLogger(filename='global_training_log.csv', separator=',', append=True)\n",
        "global_history = global_autoencoder_model.fit(\n",
        "  x=x_train,\n",
        "  y=y_train,\n",
        "  batch_size=1,\n",
        "  epochs=100,\n",
        "  validation_data = (x_test, y_test),\n",
        "  callbacks=[checkpoint_callback, csv_logger_callback]\n",
        ")"
      ],
      "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
      },
      "outputs": [],
      "source": [
        "global_history_df = pd.DataFrame(global_history.history)"
      ],
      "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_history_df.to_csv(f'{output_folder_path}global_training_log.csv')"
      ],
      "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_autoencoder_model.save(f'{output_folder_path}global_autoencoder_model.keras')"
      ],
      "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
      },
      "source": [
        "### Global Shuffled Training"
      ],
      "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9887abb8-c075-46b4-9eee-b28922a61575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7962dee8-9d1a-41c3-ab64-f0bfc6b82fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "71/71 [==============================] - 2s 17ms/step - loss: -0.6974 - metric_choose_argument_global_y_train: 0.0141 - val_loss: -0.7518 - val_metric_choose_argument_global_y_train: 0.0938\n",
            "Epoch 2/20\n",
            "71/71 [==============================] - 1s 13ms/step - loss: -0.7532 - metric_choose_argument_global_y_train: 0.0282 - val_loss: -0.7518 - val_metric_choose_argument_global_y_train: 0.0938\n",
            "Epoch 3/20\n",
            "71/71 [==============================] - 1s 14ms/step - loss: -0.7637 - metric_choose_argument_global_y_train: 0.0141 - val_loss: -0.7515 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 4/20\n",
            "71/71 [==============================] - 1s 17ms/step - loss: -0.7809 - metric_choose_argument_global_y_train: 0.0986 - val_loss: -0.7354 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 5/20\n",
            "71/71 [==============================] - 1s 19ms/step - loss: -0.8134 - metric_choose_argument_global_y_train: 0.2676 - val_loss: -0.7177 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 6/20\n",
            "71/71 [==============================] - 1s 19ms/step - loss: -0.8448 - metric_choose_argument_global_y_train: 0.4930 - val_loss: -0.7121 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 7/20\n",
            "71/71 [==============================] - 1s 14ms/step - loss: -0.8753 - metric_choose_argument_global_y_train: 0.7042 - val_loss: -0.7129 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 8/20\n",
            "71/71 [==============================] - 1s 15ms/step - loss: -0.9041 - metric_choose_argument_global_y_train: 0.8732 - val_loss: -0.6876 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 9/20\n",
            "71/71 [==============================] - 1s 17ms/step - loss: -0.9244 - metric_choose_argument_global_y_train: 0.8451 - val_loss: -0.6610 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 10/20\n",
            "71/71 [==============================] - 1s 14ms/step - loss: -0.9437 - metric_choose_argument_global_y_train: 0.9014 - val_loss: -0.6600 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 11/20\n",
            "71/71 [==============================] - 1s 14ms/step - loss: -0.9579 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.6657 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 12/20\n",
            "71/71 [==============================] - 1s 15ms/step - loss: -0.9665 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.6603 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 13/20\n",
            "71/71 [==============================] - 1s 15ms/step - loss: -0.9732 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.6612 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 14/20\n",
            "71/71 [==============================] - 1s 15ms/step - loss: -0.9791 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.6551 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 15/20\n",
            "71/71 [==============================] - 1s 16ms/step - loss: -0.9825 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.6567 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 16/20\n",
            "71/71 [==============================] - 1s 18ms/step - loss: -0.9848 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.6555 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 17/20\n",
            "71/71 [==============================] - 1s 20ms/step - loss: -0.9859 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.6610 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 18/20\n",
            "71/71 [==============================] - 1s 16ms/step - loss: -0.9882 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.6543 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 19/20\n",
            "71/71 [==============================] - 1s 16ms/step - loss: -0.9914 - metric_choose_argument_global_y_train: 1.0000 - val_loss: -0.6531 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 20/20\n",
            "71/71 [==============================] - 1s 15ms/step - loss: -0.9925 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.6690 - val_metric_choose_argument_global_y_train: 0.0312\n"
          ]
        }
      ],
      "source": [
        "# Global Shuffled Model\n",
        "global_shuffled_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_shuffled_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")\n",
        "\n",
        "global_shuffled_history = global_shuffled_autoencoder_model.fit(\n",
        "  x=x_train,\n",
        "  y=y_train_shuffled,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (x_test, y_test)\n",
        ")"
      ],
      "id": "9887abb8-c075-46b4-9eee-b28922a61575"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i5lFFqIbNzh"
      },
      "outputs": [],
      "source": [
        "global_shuffled_history_df = pd.DataFrame(global_shuffled_history.history)"
      ],
      "id": "5i5lFFqIbNzh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOtX9nyBbNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_history_df.to_csv(f'{output_folder_path}global_shuffled_training_log.csv')"
      ],
      "id": "KOtX9nyBbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrmhWBS2bNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/nomic-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_autoencoder_model.save(f'{output_folder_path}global_shuffled_autoencoder_model.keras')"
      ],
      "id": "KrmhWBS2bNzk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export data"
      ],
      "metadata": {
        "id": "o4WdvaTBDg0Q"
      },
      "id": "o4WdvaTBDg0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "def export_nomic_autoencoder():\n",
        "  \"\"\"Export nomic_autoencoder directory\"\"\"\n",
        "  nomic_autoencoder_file_path = 'current-data-dump/nomic-autoencoder'\n",
        "  nomic_autoencoder_file_path_zip = 'current-data-dump/nomic-autoencoder'\n",
        "  shutil.make_archive(nomic_autoencoder_file_path_zip, 'zip', nomic_autoencoder_file_path)\n",
        "  print(f\"Zip file created at: {nomic_autoencoder_file_path_zip}\")\n",
        "  result = subprocess.run([f\"osf -p sakjg upload --force {nomic_autoencoder_file_path_zip}.zip data-dump/nomic-evidence-autoencoder/nomic_evidence_autoencoder.zip\"], shell=True, capture_output=True, text=True)\n",
        "  print(result.stderr)\n",
        "  print(f\"File: {nomic_autoencoder_file_path_zip} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "kPUJzZOEFmCY"
      },
      "id": "kPUJzZOEFmCY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_nomic_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1zI9XxWnCZ4",
        "outputId": "1efc4763-1596-458e-fd72-049f2904c577"
      },
      "id": "j1zI9XxWnCZ4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: current-data-dump/nomic-autoencoder\n",
            "\n",
            "File: current-data-dump/nomic-autoencoder uploaded at osfstorage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "HwCx1sldDjMC"
      },
      "id": "HwCx1sldDjMC"
    },
    {
      "cell_type": "code",
      "source": [
        "def import_nomic_autoencoder():\n",
        "  \"\"\"Import nomic_autoencoder directory\"\"\"\n",
        "  subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/nomic-evidence-autoencoder/nomic_evidence_autoencoder.zip\", shell=True)\n",
        "  print(\"nomic_autoencoder.zip successfully imported\")\n",
        "  nomic_autoencoder_file_path_zip = 'nomic_evidence_autoencoder.zip'\n",
        "  nomic_autoencoder_file_path = 'current-data-dump/nomic-autoencoder'\n",
        "  os.makedirs(nomic_autoencoder_file_path, exist_ok=True)\n",
        "  with zipfile.ZipFile(nomic_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(nomic_autoencoder_file_path)\n",
        "  extracted_files = os.listdir(nomic_autoencoder_file_path)\n",
        "  print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "I5nxJr5bGDTR"
      },
      "id": "I5nxJr5bGDTR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TucNWIIdnBs"
      },
      "source": [
        "## Load global training history"
      ],
      "id": "8TucNWIIdnBs"
    },
    {
      "cell_type": "code",
      "source": [
        "import_nomic_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go4cGqlJHOV-",
        "outputId": "fcae7bb4-af05-4cdc-942a-35fcb0d67c5d"
      },
      "id": "go4cGqlJHOV-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nomic_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_x_train.pkl', 'global_y_train.pkl', 'global_training_log.csv', 'global_shuffled_training_log.csv', 'global_autoencoder_model.keras', 'global_shuffled_autoencoder_model.keras', 'global_x_test.pkl', 'global_y_test.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unshuffled training history"
      ],
      "metadata": {
        "id": "JY2RndZJDXxt"
      },
      "id": "JY2RndZJDXxt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_history = pd.DataFrame(pd.read_csv(\"current-data-dump/nomic-autoencoder/global_training_log.csv\"))\n",
        "loaded_global_history = pd.melt(loaded_global_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_history = loaded_global_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_history['shuffled'] = False"
      ],
      "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79445a5b-e4f1-410d-a9d2-97d89423140b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada002-autoencoder/global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_training_plot = ggplot(loaded_global_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Unshuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_training_plot, \"current-data-dump/nomic-autoencoder/global_training_plot.png\")"
      ],
      "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shuffled training history"
      ],
      "metadata": {
        "id": "bSIwS6ydDdXI"
      },
      "id": "bSIwS6ydDdXI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJoOOL9EbNzk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_shuffled_history = pd.DataFrame(pd.read_csv(\"current-data-dump/nomic-autoencoder/global_shuffled_training_log.csv\"))\n",
        "loaded_global_shuffled_history = pd.melt(loaded_global_shuffled_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_shuffled_history = loaded_global_shuffled_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_shuffled_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_shuffled_history['shuffled'] = False"
      ],
      "id": "lJoOOL9EbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK0YRBXybNzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc60fa0-310f-45e8-e05c-450024804054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada002-autoencoder/global_shuffled_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_shuffled_training_plot = ggplot(loaded_global_shuffled_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Shuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_shuffled_training_plot, \"current-data-dump/nomic-autoencoder/global_shuffled_training_plot.png\")"
      ],
      "id": "TK0YRBXybNzl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYrWdyscsYt"
      },
      "source": [
        "## Combined Training Plots"
      ],
      "id": "nIYrWdyscsYt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
      },
      "outputs": [],
      "source": [
        "combined_global_training_df = pd.concat([loaded_global_history, loaded_global_shuffled_history])"
      ],
      "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1197f06-5503-44a5-ba23-2858da1a82b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61155ed5-4a91-439d-b915-64840d4d8308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 16 x 24 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada002-autoencoder/combined_global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "combined_global_plot = (\n",
        "  ggplot(combined_global_training_df, aes(x='epoch', y='accuracy', linetype='dataset', color='shuffled')) +\n",
        "  geom_line(size=2) +\n",
        "  labs(title='Learning Curve of Model Trained on Unshuffled vs. Within-Topic Shuffled Data', x='Epoch', y='Accuracy') +\n",
        "  theme(\n",
        "    figure_size=(16,24),\n",
        "    axis_title=element_text(size=32),\n",
        "    axis_text=element_text(size=24),\n",
        "    legend_title=element_text(size=32, lineheight=1.5),\n",
        "    legend_text=element_text(size=24, lineheight=1.5),\n",
        "    plot_title=element_text(size=40, wrap=True, lineheight=1.5),\n",
        "    legend_position=\"bottom\",\n",
        "    legend_key_width=64\n",
        "  ) +\n",
        "  guides(fill = guide_legend(byrow = True))\n",
        ")\n",
        "ggsave(combined_global_plot, \"current-data-dump/nomic-autoencoder/combined_global_training_plot.png\")"
      ],
      "id": "e1197f06-5503-44a5-ba23-2858da1a82b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcX4eHsmdAP9"
      },
      "source": [
        "## Category and Debate Training"
      ],
      "id": "GcX4eHsmdAP9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
      },
      "source": [
        "#### Category Data (Economy)"
      ],
      "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
      },
      "outputs": [],
      "source": [
        "economy_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/economy/economy_embeddings.pkl\")"
      ],
      "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
      },
      "outputs": [],
      "source": [
        "economy_training_df = prepare_training_df(economy_embeddings_data)\n",
        "economy_x_train = make_x_train(economy_training_df)\n",
        "economy_y_train = make_y_train(economy_training_df)\n",
        "economy_x_test = make_x_test(economy_training_df)\n",
        "economy_y_test = make_y_test(economy_training_df)"
      ],
      "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95100c2-7782-4acd-9a0d-699223584b59"
      },
      "source": [
        "#### Debate Data (Economy)"
      ],
      "id": "f95100c2-7782-4acd-9a0d-699223584b59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b961764-4605-47a6-87e8-817eeffe7470"
      },
      "outputs": [],
      "source": [
        "economy_debate_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/economy/business_economy_general_house_would_prohibit_retailers_selling_certain_items_embeddings.pkl\")"
      ],
      "id": "8b961764-4605-47a6-87e8-817eeffe7470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
      },
      "outputs": [],
      "source": [
        "economy_debate_training_df = prepare_training_df(economy_debate_embeddings_data)\n",
        "economy_debate_x_train = make_x_train(economy_debate_training_df)\n",
        "economy_debate_y_train = make_y_train(economy_debate_training_df)\n",
        "economy_debate_x_test = make_x_test(economy_debate_training_df)\n",
        "economy_debate_y_test = make_y_test(economy_debate_training_df)"
      ],
      "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
      },
      "source": [
        "#### Category Training"
      ],
      "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
      },
      "outputs": [],
      "source": [
        "# Category Model\n",
        "category_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "category_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "category_autoencoder_model.fit(\n",
        "  x=economy_x_train,\n",
        "  y=economy_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data=(economy_x_test, economy_y_test)\n",
        ")"
      ],
      "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
      },
      "source": [
        "#### Debate Training"
      ],
      "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40b37636-96d3-4932-9d0e-6551b846730b"
      },
      "outputs": [],
      "source": [
        "# Debate Model\n",
        "debate_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "debate_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "debate_autoencoder_model.fit(\n",
        "  x=economy_debate_x_train,\n",
        "  y=economy_debate_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=5\n",
        ")"
      ],
      "id": "40b37636-96d3-4932-9d0e-6551b846730b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Export"
      ],
      "metadata": {
        "id": "KN2uP5TfHgmt"
      },
      "id": "KN2uP5TfHgmt"
    },
    {
      "cell_type": "code",
      "source": [
        "export_ada_autoencoder()"
      ],
      "metadata": {
        "id": "cxBVn4xAHiDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338c5362-3364-438c-f11f-7ced644fbdfd"
      },
      "id": "cxBVn4xAHiDD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: current-data-dump/ada-autoencoder\n",
            "\n",
            "File: current-data-dump/ada-autoencoder uploaded at osfstorage\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}