{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study2_4_%5Bada002%5D_counterev_autoencoder_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
      },
      "source": [
        "# [ada-002] Autoencoder: Generate Corresponding Embedding"
      ],
      "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "sfhHaEtuCFaZ"
      },
      "id": "sfhHaEtuCFaZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
      },
      "source": [
        "### Imports"
      ],
      "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK38cfNTYVw5",
        "outputId": "d30b88fb-1c5d-49dc-a493-cd607513cb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ],
      "id": "PK38cfNTYVw5"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from scipy import spatial\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from plotnine import ggplot, geom_line, aes, ggsave, labs, theme, element_text, guides, guide_legend"
      ],
      "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_fc5dDySK5",
        "outputId": "2d384ee7-41e7-415f-92ff-c36cfc2b9044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQTEV8ZsQtXD"
      },
      "outputs": [],
      "source": [
        "import osfclient.cli"
      ],
      "id": "WQTEV8ZsQtXD"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cxigtskT2dda"
      },
      "outputs": [],
      "source": [
        "from osfclient.api import OSF\n",
        "from osfclient.models import Project, Storage\n",
        "from io import BytesIO"
      ],
      "id": "cxigtskT2dda"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
      },
      "source": [
        "## Data"
      ],
      "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFnWt4JYqWi"
      },
      "source": [
        "### Import corpora data from OSF"
      ],
      "id": "vIFnWt4JYqWi"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KuvkPngZtcz",
        "outputId": "732245a3-f071-41cb-97a1-75de29eca6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 33.2M/33.2M [00:00<00:00, 47.6Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/data-dump/ada002-autoencoder/ada_evidence_embeddings_dump.zip"
      ],
      "id": "8KuvkPngZtcz"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_file_path = 'ada_evidence_embeddings_dump.zip'\n",
        "output_folder_path = 'current-data-dump/embeddings-dump'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(embeddings_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkPaiT5xIdeZ",
        "outputId": "02c961ad-a16e-48bf-db27-144559e39bd8"
      },
      "id": "ZkPaiT5xIdeZ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['evidence_embeddings.pkl', 'bad_evidence_embeddings.pkl', 'argument_embeddings.pkl', 'bad_argument_embeddings.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_pickle('current-data-dump/embeddings-dump/argument_embeddings.pkl')\n",
        "y = pd.read_pickle('current-data-dump/embeddings-dump/evidence_embeddings.pkl')\n",
        "x_train = x.iloc[:1499]\n",
        "x_test = x.iloc[1499:]\n",
        "y_train = y.iloc[:1499]\n",
        "y_test = y.iloc[1499:]\n",
        "combined_train_df = pd.concat([x_train, y_train], axis=1)\n",
        "combined_test_df = pd.concat([x_test, y_test], axis=1)\n",
        "\n",
        "combined_train_df = combined_train_df.groupby('argument').sample(1)\n",
        "combined_test_df = combined_test_df.groupby('argument').sample(1)\n",
        "x_train = combined_train_df.iloc[:, 0:1536].reset_index(drop=True)\n",
        "y_train = combined_train_df.iloc[:, 1537:3073].reset_index(drop=True)\n",
        "x_test = combined_test_df.iloc[:, 0:1536].reset_index(drop=True)\n",
        "y_test = combined_test_df.iloc[:, 1537:3073].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "iH96OsgnsZBR"
      },
      "id": "iH96OsgnsZBR",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
      },
      "source": [
        "### Make global data shuffled"
      ],
      "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
      },
      "outputs": [],
      "source": [
        "y_train_shuffled = y_train.copy().sample(frac=1).reset_index(drop=True)"
      ],
      "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save global training df"
      ],
      "metadata": {
        "id": "bxCtUU3xJxMG"
      },
      "id": "bxCtUU3xJxMG"
    },
    {
      "cell_type": "code",
      "source": [
        "global_x_train_folder_path = 'current-data-dump/ada002-autoencoder/'\n",
        "global_x_train_file_path = f'{global_x_train_folder_path}global_x_train.pkl'\n",
        "global_y_train_folder_path = 'current-data-dump/ada002-autoencoder/'\n",
        "global_y_train_file_path = f'{global_x_train_folder_path}global_y_train.pkl'\n",
        "os.makedirs(global_x_train_folder_path, exist_ok=True)\n",
        "os.makedirs(global_y_train_folder_path, exist_ok=True)\n",
        "with open(global_x_train_file_path, 'wb') as file:\n",
        "  pickle.dump(x_train, file)\n",
        "  print(f\"File uploaded to {global_x_train_file_path}\")\n",
        "with open(global_y_train_file_path, 'wb') as file:\n",
        "  pickle.dump(y_train, file)\n",
        "  print(f\"File uploaded to {global_y_train_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrMv_TJKJ0h5",
        "outputId": "63b98012-e312-4767-a670-7312753c044c"
      },
      "id": "mrMv_TJKJ0h5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded to current-data-dump/ada002-autoencoder/global_x_train.pkl\n",
            "File uploaded to current-data-dump/ada002-autoencoder/global_y_train.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
      },
      "source": [
        "## Model"
      ],
      "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdhQDH3Hdf2d"
      },
      "source": [
        "### Architecture"
      ],
      "id": "wdhQDH3Hdf2d"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "92def071-b058-49c3-9573-6ee31d041244"
      },
      "outputs": [],
      "source": [
        "# Layers\n",
        "input_layer = tf.keras.layers.Input(shape=(1536, ), name=\"Input\")\n",
        "hidden_layer = tf.keras.layers.Dense(units=1536, activation=\"relu\", name=\"Hidden\")(input_layer)\n",
        "output_layer = tf.keras.layers.Dense(units=1536, activation=\"linear\", name=\"Output\")(hidden_layer)"
      ],
      "id": "92def071-b058-49c3-9573-6ee31d041244"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00",
        "outputId": "1ad01eec-c24a-4d94-dcb7-a0756067246b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 1536)]            0         \n",
            "                                                                 \n",
            " Hidden (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4721664 (18.01 MB)\n",
            "Trainable params: 4721664 (18.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "autoencoder_model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder_model.summary()"
      ],
      "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYS3gnudicT"
      },
      "source": [
        "### Metric"
      ],
      "id": "bfYS3gnudicT"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  \"\"\"global_metric\"\"\"\n",
        "  global_training_df_32 = tf.cast(x_train, dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
      },
      "source": [
        "### Global Training"
      ],
      "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "global_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")"
      ],
      "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922cfd2c-40c8-4e8c-e0e0-0acf9d88d5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.7253 - metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 1: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 6s 16ms/step - loss: -0.7253 - metric_choose_argument_global_y_train: 0.0000e+00 - val_loss: -0.8136 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 2/20\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.8305 - metric_choose_argument_global_y_train: 0.0882\n",
            "Epoch 2: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 11ms/step - loss: -0.8307 - metric_choose_argument_global_y_train: 0.0986 - val_loss: -0.8322 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 3/20\n",
            "61/71 [========================>.....] - ETA: 0s - loss: -0.8527 - metric_choose_argument_global_y_train: 0.0820\n",
            "Epoch 3: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.8527 - metric_choose_argument_global_y_train: 0.0986 - val_loss: -0.8393 - val_metric_choose_argument_global_y_train: 0.1250\n",
            "Epoch 4/20\n",
            "62/71 [=========================>....] - ETA: 0s - loss: -0.8679 - metric_choose_argument_global_y_train: 0.2097\n",
            "Epoch 4: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.8676 - metric_choose_argument_global_y_train: 0.2254 - val_loss: -0.8399 - val_metric_choose_argument_global_y_train: 0.1250\n",
            "Epoch 5/20\n",
            "58/71 [=======================>......] - ETA: 0s - loss: -0.8862 - metric_choose_argument_global_y_train: 0.5000\n",
            "Epoch 5: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.8850 - metric_choose_argument_global_y_train: 0.4930 - val_loss: -0.8425 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 6/20\n",
            "60/71 [========================>.....] - ETA: 0s - loss: -0.9034 - metric_choose_argument_global_y_train: 0.7833\n",
            "Epoch 6: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9020 - metric_choose_argument_global_y_train: 0.7746 - val_loss: -0.8349 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 7/20\n",
            "58/71 [=======================>......] - ETA: 0s - loss: -0.9185 - metric_choose_argument_global_y_train: 0.7931\n",
            "Epoch 7: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9175 - metric_choose_argument_global_y_train: 0.7746 - val_loss: -0.8358 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 8/20\n",
            "59/71 [=======================>......] - ETA: 0s - loss: -0.9343 - metric_choose_argument_global_y_train: 0.8475\n",
            "Epoch 8: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9336 - metric_choose_argument_global_y_train: 0.8732 - val_loss: -0.8349 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 9/20\n",
            "63/71 [=========================>....] - ETA: 0s - loss: -0.9485 - metric_choose_argument_global_y_train: 0.9048\n",
            "Epoch 9: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9484 - metric_choose_argument_global_y_train: 0.9155 - val_loss: -0.8379 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 10/20\n",
            "57/71 [=======================>......] - ETA: 0s - loss: -0.9589 - metric_choose_argument_global_y_train: 0.9298\n",
            "Epoch 10: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9591 - metric_choose_argument_global_y_train: 0.9155 - val_loss: -0.8319 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 11/20\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9679 - metric_choose_argument_global_y_train: 0.9143\n",
            "Epoch 11: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9679 - metric_choose_argument_global_y_train: 0.9014 - val_loss: -0.8298 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 12/20\n",
            "69/71 [============================>.] - ETA: 0s - loss: -0.9758 - metric_choose_argument_global_y_train: 0.9275\n",
            "Epoch 12: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 9ms/step - loss: -0.9746 - metric_choose_argument_global_y_train: 0.9155 - val_loss: -0.8310 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 13/20\n",
            "57/71 [=======================>......] - ETA: 0s - loss: -0.9801 - metric_choose_argument_global_y_train: 0.9649\n",
            "Epoch 13: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9788 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.8287 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 14/20\n",
            "71/71 [==============================] - ETA: 0s - loss: -0.9831 - metric_choose_argument_global_y_train: 0.9296\n",
            "Epoch 14: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 9ms/step - loss: -0.9831 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.8313 - val_metric_choose_argument_global_y_train: 0.2188\n",
            "Epoch 15/20\n",
            "57/71 [=======================>......] - ETA: 0s - loss: -0.9845 - metric_choose_argument_global_y_train: 0.9298\n",
            "Epoch 15: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 8ms/step - loss: -0.9848 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8307 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 16/20\n",
            "67/71 [===========================>..] - ETA: 0s - loss: -0.9865 - metric_choose_argument_global_y_train: 0.9403\n",
            "Epoch 16: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 2s 30ms/step - loss: -0.9867 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8307 - val_metric_choose_argument_global_y_train: 0.2500\n",
            "Epoch 17/20\n",
            "68/71 [===========================>..] - ETA: 0s - loss: -0.9887 - metric_choose_argument_global_y_train: 0.9412\n",
            "Epoch 17: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 12ms/step - loss: -0.9887 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8316 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 18/20\n",
            "70/71 [============================>.] - ETA: 0s - loss: -0.9896 - metric_choose_argument_global_y_train: 0.9571\n",
            "Epoch 18: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 11ms/step - loss: -0.9897 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.8298 - val_metric_choose_argument_global_y_train: 0.1875\n",
            "Epoch 19/20\n",
            "62/71 [=========================>....] - ETA: 0s - loss: -0.9903 - metric_choose_argument_global_y_train: 0.9677\n",
            "Epoch 19: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 11ms/step - loss: -0.9905 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.8304 - val_metric_choose_argument_global_y_train: 0.1562\n",
            "Epoch 20/20\n",
            "59/71 [=======================>......] - ETA: 0s - loss: -0.9909 - metric_choose_argument_global_y_train: 0.9153\n",
            "Epoch 20: saving model to global_autoencoder_weights.keras\n",
            "71/71 [==============================] - 1s 9ms/step - loss: -0.9913 - metric_choose_argument_global_y_train: 0.9296 - val_loss: -0.8268 - val_metric_choose_argument_global_y_train: 0.2500\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath='global_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
        "csv_logger_callback = CSVLogger(filename='global_training_log.csv', separator=',', append=True)\n",
        "global_history = global_autoencoder_model.fit(\n",
        "  x=x_train,\n",
        "  y=y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (x_test, y_test),\n",
        "  callbacks=[checkpoint_callback, csv_logger_callback]\n",
        ")"
      ],
      "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
      },
      "outputs": [],
      "source": [
        "global_history_df = pd.DataFrame(global_history.history)"
      ],
      "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada002-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_history_df.to_csv(f'{output_folder_path}global_training_log.csv')"
      ],
      "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada002-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_autoencoder_model.save(f'{output_folder_path}global_autoencoder_model.keras')"
      ],
      "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
      },
      "source": [
        "### Global Shuffled Training"
      ],
      "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9887abb8-c075-46b4-9eee-b28922a61575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b89cb5f-291b-4805-b1e7-0d6442d47128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "71/71 [==============================] - 1s 7ms/step - loss: -0.7261 - metric_choose_argument_global_y_train: 0.0000e+00 - val_loss: -0.8009 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 2/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.8284 - metric_choose_argument_global_y_train: 0.0141 - val_loss: -0.8249 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 3/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.8396 - metric_choose_argument_global_y_train: 0.0141 - val_loss: -0.8398 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 4/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.8511 - metric_choose_argument_global_y_train: 0.0282 - val_loss: -0.8342 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 5/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.8645 - metric_choose_argument_global_y_train: 0.0563 - val_loss: -0.8315 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 6/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.8779 - metric_choose_argument_global_y_train: 0.2958 - val_loss: -0.8287 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 7/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.8957 - metric_choose_argument_global_y_train: 0.4789 - val_loss: -0.8246 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 8/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.9159 - metric_choose_argument_global_y_train: 0.6761 - val_loss: -0.8180 - val_metric_choose_argument_global_y_train: 0.0625\n",
            "Epoch 9/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.9312 - metric_choose_argument_global_y_train: 0.7183 - val_loss: -0.8179 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 10/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9476 - metric_choose_argument_global_y_train: 0.8732 - val_loss: -0.8039 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 11/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9579 - metric_choose_argument_global_y_train: 0.9014 - val_loss: -0.8076 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 12/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.9662 - metric_choose_argument_global_y_train: 0.8873 - val_loss: -0.8003 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 13/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9733 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8025 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 14/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.9781 - metric_choose_argument_global_y_train: 0.9155 - val_loss: -0.8073 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 15/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9813 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8074 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 16/20\n",
            "71/71 [==============================] - 0s 5ms/step - loss: -0.9827 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8010 - val_metric_choose_argument_global_y_train: 0.0312\n",
            "Epoch 17/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.9854 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.8033 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 18/20\n",
            "71/71 [==============================] - 0s 4ms/step - loss: -0.9871 - metric_choose_argument_global_y_train: 0.9437 - val_loss: -0.8073 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 19/20\n",
            "71/71 [==============================] - 0s 7ms/step - loss: -0.9889 - metric_choose_argument_global_y_train: 0.9718 - val_loss: -0.8085 - val_metric_choose_argument_global_y_train: 0.0000e+00\n",
            "Epoch 20/20\n",
            "71/71 [==============================] - 0s 6ms/step - loss: -0.9910 - metric_choose_argument_global_y_train: 0.9577 - val_loss: -0.8086 - val_metric_choose_argument_global_y_train: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Global Shuffled Model\n",
        "global_shuffled_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_shuffled_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")\n",
        "\n",
        "global_shuffled_history = global_shuffled_autoencoder_model.fit(\n",
        "  x=x_train,\n",
        "  y=y_train_shuffled,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (x_test, y_test)\n",
        ")"
      ],
      "id": "9887abb8-c075-46b4-9eee-b28922a61575"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5i5lFFqIbNzh"
      },
      "outputs": [],
      "source": [
        "global_shuffled_history_df = pd.DataFrame(global_shuffled_history.history)"
      ],
      "id": "5i5lFFqIbNzh"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KOtX9nyBbNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada002-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_history_df.to_csv(f'{output_folder_path}global_shuffled_training_log.csv')"
      ],
      "id": "KOtX9nyBbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KrmhWBS2bNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada002-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_autoencoder_model.save(f'{output_folder_path}global_shuffled_autoencoder_model.keras')"
      ],
      "id": "KrmhWBS2bNzk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export data"
      ],
      "metadata": {
        "id": "o4WdvaTBDg0Q"
      },
      "id": "o4WdvaTBDg0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "def export_ada_autoencoder():\n",
        "  \"\"\"Export ada_autoencoder directory\"\"\"\n",
        "  ada_autoencoder_file_path = 'current-data-dump/ada002-autoencoder'\n",
        "  ada_autoencoder_file_path_zip = 'current-data-dump/ada002-autoencoder'\n",
        "  shutil.make_archive(ada_autoencoder_file_path_zip, 'zip', ada_autoencoder_file_path)\n",
        "  print(f\"Zip file created at: {ada_autoencoder_file_path_zip}\")\n",
        "  result = subprocess.run([f\"osf -p sakjg upload --force {ada_autoencoder_file_path_zip}.zip data-dump/ada002-evidence-autoencoder/ada002_evidence_autoencoder.zip\"], shell=True, capture_output=True, text=True)\n",
        "  print(result.stderr)\n",
        "  print(f\"File: {ada_autoencoder_file_path_zip} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "kPUJzZOEFmCY"
      },
      "id": "kPUJzZOEFmCY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_ada_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1zI9XxWnCZ4",
        "outputId": "c210423e-470e-4e72-e387-4ca926348171"
      },
      "id": "j1zI9XxWnCZ4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: current-data-dump/ada002-autoencoder\n",
            "\n",
            "File: current-data-dump/ada002-autoencoder uploaded at osfstorage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "HwCx1sldDjMC"
      },
      "id": "HwCx1sldDjMC"
    },
    {
      "cell_type": "code",
      "source": [
        "def import_ada_autoencoder():\n",
        "  \"\"\"Import ada_autoencoder directory\"\"\"\n",
        "  subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada002-evidence-autoencoder/ada002_evidence_autoencoder.zip\", shell=True)\n",
        "  print(\"ada_autoencoder.zip successfully imported\")\n",
        "  ada_autoencoder_file_path_zip = 'ada002_evidence_autoencoder.zip'\n",
        "  ada_autoencoder_file_path = 'current-data-dump/ada002-autoencoder'\n",
        "  os.makedirs(ada_autoencoder_file_path, exist_ok=True)\n",
        "  with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(ada_autoencoder_file_path)\n",
        "  extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "  print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "I5nxJr5bGDTR"
      },
      "id": "I5nxJr5bGDTR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TucNWIIdnBs"
      },
      "source": [
        "## Load global training history"
      ],
      "id": "8TucNWIIdnBs"
    },
    {
      "cell_type": "code",
      "source": [
        "import_ada_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go4cGqlJHOV-",
        "outputId": "d54a913c-475e-420b-ffdb-c5e5d4a781e6"
      },
      "id": "go4cGqlJHOV-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_autoencoder_model.keras', 'global_shuffled_autoencoder_model.keras', 'global_shuffled_training_log.csv', 'global_shuffled_training_plot.png', 'global_training_plot.png', 'combined_global_training_plot.png', 'global_training_df.pkl', 'global_training_log.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unshuffled training history"
      ],
      "metadata": {
        "id": "JY2RndZJDXxt"
      },
      "id": "JY2RndZJDXxt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_history = pd.DataFrame(pd.read_csv(\"current-data-dump/ada002-autoencoder/global_training_log.csv\"))\n",
        "loaded_global_history = pd.melt(loaded_global_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_history = loaded_global_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_history['shuffled'] = False"
      ],
      "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79445a5b-e4f1-410d-a9d2-97d89423140b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada002-autoencoder/global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_training_plot = ggplot(loaded_global_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Unshuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_training_plot, \"current-data-dump/ada002-autoencoder/global_training_plot.png\")"
      ],
      "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shuffled training history"
      ],
      "metadata": {
        "id": "bSIwS6ydDdXI"
      },
      "id": "bSIwS6ydDdXI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJoOOL9EbNzk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_shuffled_history = pd.DataFrame(pd.read_csv(\"current-data-dump/ada002-autoencoder/global_shuffled_training_log.csv\"))\n",
        "loaded_global_shuffled_history = pd.melt(loaded_global_shuffled_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_shuffled_history = loaded_global_shuffled_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_shuffled_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_shuffled_history['shuffled'] = False"
      ],
      "id": "lJoOOL9EbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK0YRBXybNzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc60fa0-310f-45e8-e05c-450024804054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada002-autoencoder/global_shuffled_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_shuffled_training_plot = ggplot(loaded_global_shuffled_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Shuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_shuffled_training_plot, \"current-data-dump/ada002-autoencoder/global_shuffled_training_plot.png\")"
      ],
      "id": "TK0YRBXybNzl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYrWdyscsYt"
      },
      "source": [
        "## Combined Training Plots"
      ],
      "id": "nIYrWdyscsYt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
      },
      "outputs": [],
      "source": [
        "combined_global_training_df = pd.concat([loaded_global_history, loaded_global_shuffled_history])"
      ],
      "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1197f06-5503-44a5-ba23-2858da1a82b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61155ed5-4a91-439d-b915-64840d4d8308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 16 x 24 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada002-autoencoder/combined_global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "combined_global_plot = (\n",
        "  ggplot(combined_global_training_df, aes(x='epoch', y='accuracy', linetype='dataset', color='shuffled')) +\n",
        "  geom_line(size=2) +\n",
        "  labs(title='Learning Curve of Model Trained on Unshuffled vs. Within-Topic Shuffled Data', x='Epoch', y='Accuracy') +\n",
        "  theme(\n",
        "    figure_size=(16,24),\n",
        "    axis_title=element_text(size=32),\n",
        "    axis_text=element_text(size=24),\n",
        "    legend_title=element_text(size=32, lineheight=1.5),\n",
        "    legend_text=element_text(size=24, lineheight=1.5),\n",
        "    plot_title=element_text(size=40, wrap=True, lineheight=1.5),\n",
        "    legend_position=\"bottom\",\n",
        "    legend_key_width=64\n",
        "  ) +\n",
        "  guides(fill = guide_legend(byrow = True))\n",
        ")\n",
        "ggsave(combined_global_plot, \"current-data-dump/ada002-autoencoder/combined_global_training_plot.png\")"
      ],
      "id": "e1197f06-5503-44a5-ba23-2858da1a82b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Training Plots"
      ],
      "metadata": {
        "id": "UsYV2MXHUZeV"
      },
      "id": "UsYV2MXHUZeV"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada002-evidence-autoencoder/ada002_evidence_autoencoder.zip\", shell=True)\n",
        "print(\"ada_autoencoder.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'ada002_evidence_autoencoder.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/ada002-autoencoder'\n",
        "os.makedirs(ada_autoencoder_file_path, exist_ok=True)\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "Z4j_Q9XaUZAk"
      },
      "id": "Z4j_Q9XaUZAk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-evidence-autoencoder/ada003_evidence_autoencoder.zip\", shell=True)\n",
        "print(\"ada_autoencoder.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'ada003_evidence_autoencoder.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/ada003-autoencoder'\n",
        "os.makedirs(ada_autoencoder_file_path, exist_ok=True)\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "jNZblhksUfSM"
      },
      "id": "jNZblhksUfSM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/nomic-evidence-autoencoder/nomic_evidence_autoencoder.zip\", shell=True)\n",
        "print(\"ada_autoencoder.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'nomic_evidence_autoencoder.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/nomic-autoencoder'\n",
        "os.makedirs(ada_autoencoder_file_path, exist_ok=True)\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "Ha14TFQzUiAj",
        "outputId": "0aa6dcd9-75f4-46f4-93e9-e71ab5ccd9e8"
      },
      "id": "Ha14TFQzUiAj",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada_autoencoder.zip successfully imported\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'nomic_evidence_autoencoder.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-36a9010f09ec>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mada_autoencoder_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'current-data-dump/nomic-autoencoder'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_autoencoder_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_autoencoder_file_path_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_autoencoder_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mextracted_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_autoencoder_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nomic_evidence_autoencoder.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNn3JFJMUnTx"
      },
      "id": "wNn3JFJMUnTx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcX4eHsmdAP9"
      },
      "source": [
        "## Category and Debate Training"
      ],
      "id": "GcX4eHsmdAP9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
      },
      "source": [
        "#### Category Data (Economy)"
      ],
      "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
      },
      "outputs": [],
      "source": [
        "economy_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/economy/economy_embeddings.pkl\")"
      ],
      "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
      },
      "outputs": [],
      "source": [
        "economy_training_df = prepare_training_df(economy_embeddings_data)\n",
        "economy_x_train = make_x_train(economy_training_df)\n",
        "economy_y_train = make_y_train(economy_training_df)\n",
        "economy_x_test = make_x_test(economy_training_df)\n",
        "economy_y_test = make_y_test(economy_training_df)"
      ],
      "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95100c2-7782-4acd-9a0d-699223584b59"
      },
      "source": [
        "#### Debate Data (Economy)"
      ],
      "id": "f95100c2-7782-4acd-9a0d-699223584b59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b961764-4605-47a6-87e8-817eeffe7470"
      },
      "outputs": [],
      "source": [
        "economy_debate_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/economy/business_economy_general_house_would_prohibit_retailers_selling_certain_items_embeddings.pkl\")"
      ],
      "id": "8b961764-4605-47a6-87e8-817eeffe7470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
      },
      "outputs": [],
      "source": [
        "economy_debate_training_df = prepare_training_df(economy_debate_embeddings_data)\n",
        "economy_debate_x_train = make_x_train(economy_debate_training_df)\n",
        "economy_debate_y_train = make_y_train(economy_debate_training_df)\n",
        "economy_debate_x_test = make_x_test(economy_debate_training_df)\n",
        "economy_debate_y_test = make_y_test(economy_debate_training_df)"
      ],
      "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
      },
      "source": [
        "#### Category Training"
      ],
      "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
      },
      "outputs": [],
      "source": [
        "# Category Model\n",
        "category_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "category_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "category_autoencoder_model.fit(\n",
        "  x=economy_x_train,\n",
        "  y=economy_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data=(economy_x_test, economy_y_test)\n",
        ")"
      ],
      "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
      },
      "source": [
        "#### Debate Training"
      ],
      "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40b37636-96d3-4932-9d0e-6551b846730b"
      },
      "outputs": [],
      "source": [
        "# Debate Model\n",
        "debate_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "debate_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "debate_autoencoder_model.fit(\n",
        "  x=economy_debate_x_train,\n",
        "  y=economy_debate_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=5\n",
        ")"
      ],
      "id": "40b37636-96d3-4932-9d0e-6551b846730b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Export"
      ],
      "metadata": {
        "id": "KN2uP5TfHgmt"
      },
      "id": "KN2uP5TfHgmt"
    },
    {
      "cell_type": "code",
      "source": [
        "export_ada_autoencoder()"
      ],
      "metadata": {
        "id": "cxBVn4xAHiDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338c5362-3364-438c-f11f-7ced644fbdfd"
      },
      "id": "cxBVn4xAHiDD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: current-data-dump/ada-autoencoder\n",
            "\n",
            "File: current-data-dump/ada-autoencoder uploaded at osfstorage\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}