{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study10_%5Bada003%5Dautoencoder_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
      },
      "source": [
        "# [ada-003] Autoencoder: Generate Corresponding Embedding"
      ],
      "id": "54d02564-93ff-4682-a3c9-866bc4a9e461"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "sfhHaEtuCFaZ"
      },
      "id": "sfhHaEtuCFaZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
      },
      "source": [
        "### Imports"
      ],
      "id": "494f9bbb-1e6d-422d-b934-24de3609ae38"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK38cfNTYVw5",
        "outputId": "b87eb056-d475-45e2-b2cd-21fb88ffdf75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ],
      "id": "PK38cfNTYVw5"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from scipy import spatial\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from plotnine import ggplot, geom_line, aes, ggsave, labs, theme, element_text, guides, guide_legend"
      ],
      "id": "34847cf8-a4c0-4fa9-b386-acb94ffc7b7f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_fc5dDySK5",
        "outputId": "f6606b6b-5f40-4b28-fee3-e283f8f51b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQTEV8ZsQtXD"
      },
      "outputs": [],
      "source": [
        "import osfclient.cli"
      ],
      "id": "WQTEV8ZsQtXD"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cxigtskT2dda"
      },
      "outputs": [],
      "source": [
        "from osfclient.api import OSF\n",
        "from osfclient.models import Project, Storage\n",
        "from io import BytesIO"
      ],
      "id": "cxigtskT2dda"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
      },
      "source": [
        "## Data"
      ],
      "id": "ac3facd4-9d46-4916-866b-2dfe7209cbc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFnWt4JYqWi"
      },
      "source": [
        "### Import corpora data from OSF"
      ],
      "id": "vIFnWt4JYqWi"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxpT2Q9yYpzD",
        "outputId": "5e5155a0-b1d8-40da-dfbf-b5ca9fa76866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 121M/121M [00:05<00:00, 22.3Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/corpora/arguana_corpus.zip"
      ],
      "id": "UxpT2Q9yYpzD"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KuvkPngZtcz",
        "outputId": "fe5844a4-f89e-4287-c5be-7d9df56d323b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 53.4M/53.4M [00:02<00:00, 24.8Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p sakjg fetch osfstorage/data-dump/ada003-autoencoder/ada_embeddings_dump.zip"
      ],
      "id": "8KuvkPngZtcz"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz8qXrcYZh3e",
        "outputId": "5784a662-ff3c-4239-b771-7da5e9a853d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['__MACOSX', 'arguana_corpus']\n"
          ]
        }
      ],
      "source": [
        "corpora_file_path = 'arguana_corpus.zip'\n",
        "output_folder_path = 'arguana-corpus'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(corpora_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "id": "fz8qXrcYZh3e"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUrn5AETZwpv",
        "outputId": "b04aa047-bb8d-4770-bbcb-524ded668263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['global_embeddings.pkl', 'economy']\n"
          ]
        }
      ],
      "source": [
        "embeddings_dump_file_path = 'ada_embeddings_dump.zip'\n",
        "output_folder_path = 'current-data-dump/embeddings-dump'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(embeddings_dump_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(output_folder_path)\n",
        "\n",
        "extracted_files = os.listdir(output_folder_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "id": "XUrn5AETZwpv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUmuCm4MYuzG"
      },
      "source": [
        "### Functions for preparing training data"
      ],
      "id": "NUmuCm4MYuzG"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1c418d64-8e44-4bb4-a85c-050f9197756f"
      },
      "outputs": [],
      "source": [
        "def prepare_training_df(data: pd.DataFrame):\n",
        "  \"\"\"Drop rows that do not follow 'point' -> 'counter' pattern\"\"\"\n",
        "  point_indices = data[data['type'] == 'point'].index\n",
        "  counter_indices = data[data['type'] == 'counter'].index\n",
        "  drop_indices = []\n",
        "  for idx in point_indices:\n",
        "    if (idx == len(data)-1) or (idx + 1 < len(data) and data.loc[idx + 1, 'type'] != 'counter'):\n",
        "      drop_indices.append(idx)\n",
        "  for idx in counter_indices:\n",
        "    if idx > 0 and data.loc[idx - 1, 'type'] != 'point':\n",
        "      drop_indices.append(idx)\n",
        "  data = data.drop(drop_indices)\n",
        "  data = data.select_dtypes(include=[np.number])\n",
        "  data = data.reset_index(drop=True)\n",
        "  return data"
      ],
      "id": "1c418d64-8e44-4bb4-a85c-050f9197756f"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f1b3452b-e0ce-4050-9a06-f392505474d0"
      },
      "outputs": [],
      "source": [
        "def prepare_training_df_shuffled(data: pd.DataFrame):\n",
        "  \"\"\"Drop rows that do not follow 'point' -> 'counter' pattern\"\"\"\n",
        "  point_indices = data[data['type'] == 'point'].index\n",
        "  counter_indices = data[data['type'] == 'counter'].index\n",
        "  drop_indices = []\n",
        "  for idx in point_indices:\n",
        "    if (idx == len(data)-1) or (idx + 1 < len(data) and data.loc[idx + 1, 'type'] != 'counter'):\n",
        "      drop_indices.append(idx)\n",
        "  for idx in counter_indices:\n",
        "    if idx > 0 and data.loc[idx - 1, 'type'] != 'point':\n",
        "      drop_indices.append(idx)\n",
        "  data = data.drop(drop_indices)\n",
        "  data = data.reset_index(drop=True)\n",
        "  return data"
      ],
      "id": "f1b3452b-e0ce-4050-9a06-f392505474d0"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8f4dffbb-31cf-4236-a7a7-ed53b2ec98b8"
      },
      "outputs": [],
      "source": [
        "def make_x_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Make training and testing datasets\"\"\"\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  train_rows_df = data.iloc[:cutoff, :]\n",
        "  x_train = train_rows_df[train_rows_df.index % 2 == 0].reset_index(drop=True)\n",
        "  return x_train\n",
        "\n",
        "def make_y_train(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  train_rows_df = data.iloc[:cutoff, :]\n",
        "  y_train = train_rows_df[train_rows_df.index % 2 != 0].reset_index(drop=True)\n",
        "  return y_train\n",
        "\n",
        "def make_x_test(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  test_rows_df = data.iloc[cutoff:, :]\n",
        "  x_test = test_rows_df[test_rows_df.index % 2 == 0].reset_index(drop=True)\n",
        "  return x_test\n",
        "\n",
        "def make_y_test(data: pd.DataFrame) -> pd.DataFrame:\n",
        "  cutoff = int(0.8 * data.shape[0])\n",
        "  if cutoff % 2 != 0:\n",
        "    cutoff = cutoff - 1\n",
        "  test_rows_df = data.iloc[cutoff:, :]\n",
        "  y_test = test_rows_df[test_rows_df.index % 2 != 0].reset_index(drop=True)\n",
        "  return y_test"
      ],
      "id": "8f4dffbb-31cf-4236-a7a7-ed53b2ec98b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0beb081-2126-4a1a-bc5e-5fc775407314"
      },
      "source": [
        "### Make global data"
      ],
      "id": "e0beb081-2126-4a1a-bc5e-5fc775407314"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "189ca924-572d-4b56-9288-5dd0a03b6782"
      },
      "outputs": [],
      "source": [
        "global_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/global_embeddings.pkl\")"
      ],
      "id": "189ca924-572d-4b56-9288-5dd0a03b6782"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "32fbc58f-b070-40c3-a1b9-820a9f8616f6"
      },
      "outputs": [],
      "source": [
        "global_training_df = prepare_training_df(global_embeddings_data)"
      ],
      "id": "32fbc58f-b070-40c3-a1b9-820a9f8616f6"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ba13fea2-4018-471a-929d-a7dffb83af42"
      },
      "outputs": [],
      "source": [
        "global_x_train = make_x_train(global_training_df)"
      ],
      "id": "ba13fea2-4018-471a-929d-a7dffb83af42"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6ddf9949-701d-4722-88c8-eee4d2e39828"
      },
      "outputs": [],
      "source": [
        "global_y_train = make_y_train(global_training_df)"
      ],
      "id": "6ddf9949-701d-4722-88c8-eee4d2e39828"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ea9a7137-fc4e-4b3a-9696-90c8ad10f795"
      },
      "outputs": [],
      "source": [
        "global_x_test = make_x_test(global_training_df)"
      ],
      "id": "ea9a7137-fc4e-4b3a-9696-90c8ad10f795"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9834f07d-9e2c-4046-86d2-29db8cb2ae5d"
      },
      "outputs": [],
      "source": [
        "global_y_test = make_y_test(global_training_df)"
      ],
      "id": "9834f07d-9e2c-4046-86d2-29db8cb2ae5d"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5d54a04a-d779-45af-a297-3356e8c6adf3"
      },
      "outputs": [],
      "source": [
        "global_y_train_test = pd.concat([global_y_train, global_y_test], axis=0)"
      ],
      "id": "5d54a04a-d779-45af-a297-3356e8c6adf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
      },
      "source": [
        "### Make global data shuffled"
      ],
      "id": "c47aa916-847b-4567-bd68-5cedaebea19a"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
      },
      "outputs": [],
      "source": [
        "global_training_df_shuffled = prepare_training_df_shuffled(global_embeddings_data)"
      ],
      "id": "0a44df78-8d41-40be-9c08-f38e48fc075d"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9e08cd74-7f3e-4be7-8d19-f5b43cecca2e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "global_y_train_shuffled = make_y_train(global_training_df_shuffled)"
      ],
      "id": "9e08cd74-7f3e-4be7-8d19-f5b43cecca2e"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "45961bd5-55e4-4e29-b785-4f03007f9f73",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "global_y_train_shuffled = global_y_train_shuffled.groupby(['topic'], sort=False)\n",
        "global_y_train_shuffled = global_y_train_shuffled.sample(frac=1).reset_index(drop=True)\n",
        "global_y_train_shuffled = global_y_train_shuffled.select_dtypes(include=[np.number])"
      ],
      "id": "45961bd5-55e4-4e29-b785-4f03007f9f73"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save global training df"
      ],
      "metadata": {
        "id": "bxCtUU3xJxMG"
      },
      "id": "bxCtUU3xJxMG"
    },
    {
      "cell_type": "code",
      "source": [
        "global_training_df_folder_path = 'current-data-dump/ada-autoencoder/'\n",
        "global_training_df_file_path = f'{global_training_df_folder_path}global_training_df.pkl'\n",
        "os.makedirs(global_training_df_folder_path, exist_ok=True)\n",
        "with open(global_training_df_file_path, 'wb') as file:\n",
        "  pickle.dump(global_training_df, file)\n",
        "  print(f\"File uploaded to {global_training_df_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrMv_TJKJ0h5",
        "outputId": "6f6ea28a-c6f8-4e07-d292-52e026f2588b"
      },
      "id": "mrMv_TJKJ0h5",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded to current-data-dump/ada-autoencoder/global_training_df.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
      },
      "source": [
        "## Model"
      ],
      "id": "ff884757-cec0-4a6f-9aa9-adf6da62b03e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdhQDH3Hdf2d"
      },
      "source": [
        "### Architecture"
      ],
      "id": "wdhQDH3Hdf2d"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "92def071-b058-49c3-9573-6ee31d041244"
      },
      "outputs": [],
      "source": [
        "# Layers\n",
        "input_layer = tf.keras.layers.Input(shape=(1536, ), name=\"Input\")\n",
        "hidden_layer = tf.keras.layers.Dense(units=1536, activation=\"relu\", name=\"Hidden\")(input_layer)\n",
        "output_layer = tf.keras.layers.Dense(units=1536, activation=\"linear\", name=\"Output\")(hidden_layer)"
      ],
      "id": "92def071-b058-49c3-9573-6ee31d041244"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00",
        "outputId": "48e18107-c930-4bb3-b9db-96ff329e74d1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 1536)]            0         \n",
            "                                                                 \n",
            " Hidden (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            " Output (Dense)              (None, 1536)              2360832   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4721664 (18.01 MB)\n",
            "Trainable params: 4721664 (18.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "autoencoder_model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder_model.summary()"
      ],
      "id": "3eee1114-bf20-4fa0-9ece-a9fadccd9d00"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfYS3gnudicT"
      },
      "source": [
        "### Metric"
      ],
      "id": "bfYS3gnudicT"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  \"\"\"global_metric\"\"\"\n",
        "  global_training_df_32 = tf.cast(global_training_df, dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "id": "953e0def-15fb-4bf6-8393-e2106f27ef2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
      },
      "source": [
        "### Global Training"
      ],
      "id": "2cf3ede1-7c60-45d4-ae84-c2a525b39fc7"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
      },
      "outputs": [],
      "source": [
        "# Global Model\n",
        "global_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")"
      ],
      "id": "e8d36670-a5cc-4e7e-bcbc-6f53eb5d5fe6"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d096c69-a94b-47d5-8531-9c7a4f28dfa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.6428 - metric_choose_argument_global_y_train: 0.0539\n",
            "Epoch 1: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 37s 7ms/step - loss: -0.6429 - metric_choose_argument_global_y_train: 0.0538 - val_loss: -0.6680 - val_metric_choose_argument_global_y_train: 0.1107\n",
            "Epoch 2/20\n",
            "3243/3252 [============================>.] - ETA: 0s - loss: -0.7391 - metric_choose_argument_global_y_train: 0.1980\n",
            "Epoch 2: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.7390 - metric_choose_argument_global_y_train: 0.1974 - val_loss: -0.7007 - val_metric_choose_argument_global_y_train: 0.2005\n",
            "Epoch 3/20\n",
            "3246/3252 [============================>.] - ETA: 0s - loss: -0.7848 - metric_choose_argument_global_y_train: 0.3897\n",
            "Epoch 3: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.7847 - metric_choose_argument_global_y_train: 0.3896 - val_loss: -0.7138 - val_metric_choose_argument_global_y_train: 0.2866\n",
            "Epoch 4/20\n",
            "3248/3252 [============================>.] - ETA: 0s - loss: -0.8184 - metric_choose_argument_global_y_train: 0.6090\n",
            "Epoch 4: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.8184 - metric_choose_argument_global_y_train: 0.6092 - val_loss: -0.7219 - val_metric_choose_argument_global_y_train: 0.3518\n",
            "Epoch 5/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.8436 - metric_choose_argument_global_y_train: 0.7598\n",
            "Epoch 5: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8436 - metric_choose_argument_global_y_train: 0.7598 - val_loss: -0.7254 - val_metric_choose_argument_global_y_train: 0.3678\n",
            "Epoch 6/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.8620 - metric_choose_argument_global_y_train: 0.8554\n",
            "Epoch 6: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.8620 - metric_choose_argument_global_y_train: 0.8555 - val_loss: -0.7288 - val_metric_choose_argument_global_y_train: 0.4108\n",
            "Epoch 7/20\n",
            "3248/3252 [============================>.] - ETA: 0s - loss: -0.8762 - metric_choose_argument_global_y_train: 0.9089\n",
            "Epoch 7: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.8762 - metric_choose_argument_global_y_train: 0.9090 - val_loss: -0.7285 - val_metric_choose_argument_global_y_train: 0.4170\n",
            "Epoch 8/20\n",
            "3247/3252 [============================>.] - ETA: 0s - loss: -0.8874 - metric_choose_argument_global_y_train: 0.9393\n",
            "Epoch 8: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8874 - metric_choose_argument_global_y_train: 0.9394 - val_loss: -0.7305 - val_metric_choose_argument_global_y_train: 0.4121\n",
            "Epoch 9/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.8956 - metric_choose_argument_global_y_train: 0.9504\n",
            "Epoch 9: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8956 - metric_choose_argument_global_y_train: 0.9505 - val_loss: -0.7297 - val_metric_choose_argument_global_y_train: 0.4268\n",
            "Epoch 10/20\n",
            "3245/3252 [============================>.] - ETA: 0s - loss: -0.9029 - metric_choose_argument_global_y_train: 0.9596\n",
            "Epoch 10: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9028 - metric_choose_argument_global_y_train: 0.9597 - val_loss: -0.7310 - val_metric_choose_argument_global_y_train: 0.4256\n",
            "Epoch 11/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9084 - metric_choose_argument_global_y_train: 0.9606\n",
            "Epoch 11: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9084 - metric_choose_argument_global_y_train: 0.9606 - val_loss: -0.7317 - val_metric_choose_argument_global_y_train: 0.4317\n",
            "Epoch 12/20\n",
            "3245/3252 [============================>.] - ETA: 0s - loss: -0.9134 - metric_choose_argument_global_y_train: 0.9683\n",
            "Epoch 12: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9134 - metric_choose_argument_global_y_train: 0.9677 - val_loss: -0.7319 - val_metric_choose_argument_global_y_train: 0.4293\n",
            "Epoch 13/20\n",
            "3250/3252 [============================>.] - ETA: 0s - loss: -0.9175 - metric_choose_argument_global_y_train: 0.9692\n",
            "Epoch 13: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.9175 - metric_choose_argument_global_y_train: 0.9692 - val_loss: -0.7304 - val_metric_choose_argument_global_y_train: 0.4244\n",
            "Epoch 14/20\n",
            "3247/3252 [============================>.] - ETA: 0s - loss: -0.9211 - metric_choose_argument_global_y_train: 0.9717\n",
            "Epoch 14: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 6ms/step - loss: -0.9211 - metric_choose_argument_global_y_train: 0.9717 - val_loss: -0.7310 - val_metric_choose_argument_global_y_train: 0.4133\n",
            "Epoch 15/20\n",
            "3241/3252 [============================>.] - ETA: 0s - loss: -0.9243 - metric_choose_argument_global_y_train: 0.9716\n",
            "Epoch 15: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9243 - metric_choose_argument_global_y_train: 0.9717 - val_loss: -0.7293 - val_metric_choose_argument_global_y_train: 0.4280\n",
            "Epoch 16/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9270 - metric_choose_argument_global_y_train: 0.9726\n",
            "Epoch 16: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.9270 - metric_choose_argument_global_y_train: 0.9726 - val_loss: -0.7308 - val_metric_choose_argument_global_y_train: 0.4268\n",
            "Epoch 17/20\n",
            "3249/3252 [============================>.] - ETA: 0s - loss: -0.9293 - metric_choose_argument_global_y_train: 0.9720\n",
            "Epoch 17: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.9293 - metric_choose_argument_global_y_train: 0.9720 - val_loss: -0.7287 - val_metric_choose_argument_global_y_train: 0.4244\n",
            "Epoch 18/20\n",
            "3241/3252 [============================>.] - ETA: 0s - loss: -0.9317 - metric_choose_argument_global_y_train: 0.9744\n",
            "Epoch 18: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.9317 - metric_choose_argument_global_y_train: 0.9745 - val_loss: -0.7300 - val_metric_choose_argument_global_y_train: 0.4244\n",
            "Epoch 19/20\n",
            "3244/3252 [============================>.] - ETA: 0s - loss: -0.9336 - metric_choose_argument_global_y_train: 0.9738\n",
            "Epoch 19: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.9336 - metric_choose_argument_global_y_train: 0.9736 - val_loss: -0.7301 - val_metric_choose_argument_global_y_train: 0.4244\n",
            "Epoch 20/20\n",
            "3252/3252 [==============================] - ETA: 0s - loss: -0.9354 - metric_choose_argument_global_y_train: 0.9717\n",
            "Epoch 20: saving model to global_autoencoder_weights.keras\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.9354 - metric_choose_argument_global_y_train: 0.9717 - val_loss: -0.7292 - val_metric_choose_argument_global_y_train: 0.4268\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(filepath='global_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
        "csv_logger_callback = CSVLogger(filename='global_training_log.csv', separator=',', append=True)\n",
        "global_history = global_autoencoder_model.fit(\n",
        "  x=global_x_train,\n",
        "  y=global_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (global_x_test, global_y_test),\n",
        "  callbacks=[checkpoint_callback, csv_logger_callback]\n",
        ")"
      ],
      "id": "ab4f9337-5f8e-48ea-995d-444f82e27dd2"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
      },
      "outputs": [],
      "source": [
        "global_history_df = pd.DataFrame(global_history.history)"
      ],
      "id": "fa362204-e8f0-4894-b526-b99e560e4d4d"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_history_df.to_csv(f'{output_folder_path}global_training_log.csv')"
      ],
      "id": "336a4b91-c030-49f1-aae0-cd32fc5462da"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_autoencoder_model.save(f'{output_folder_path}global_autoencoder_model.keras')"
      ],
      "id": "f6096f95-2d3d-43fd-9675-13b2e2ff1a28"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
      },
      "source": [
        "### Global Shuffled Training"
      ],
      "id": "d5b0cabd-28d9-4e8c-a775-59346bcf37a3"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9887abb8-c075-46b4-9eee-b28922a61575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f70abe5-4e36-4c85-e757-e8a61907574b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3252/3252 [==============================] - 33s 7ms/step - loss: -0.6000 - metric_choose_argument_global_y_train: 0.0178 - val_loss: -0.6385 - val_metric_choose_argument_global_y_train: 0.0603\n",
            "Epoch 2/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.6845 - metric_choose_argument_global_y_train: 0.0529 - val_loss: -0.6577 - val_metric_choose_argument_global_y_train: 0.0664\n",
            "Epoch 3/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.7221 - metric_choose_argument_global_y_train: 0.0984 - val_loss: -0.6640 - val_metric_choose_argument_global_y_train: 0.0836\n",
            "Epoch 4/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.7492 - metric_choose_argument_global_y_train: 0.1845 - val_loss: -0.6567 - val_metric_choose_argument_global_y_train: 0.0689\n",
            "Epoch 5/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.7725 - metric_choose_argument_global_y_train: 0.3137 - val_loss: -0.6433 - val_metric_choose_argument_global_y_train: 0.0713\n",
            "Epoch 6/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.7914 - metric_choose_argument_global_y_train: 0.4643 - val_loss: -0.6380 - val_metric_choose_argument_global_y_train: 0.0763\n",
            "Epoch 7/20\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.8075 - metric_choose_argument_global_y_train: 0.5621 - val_loss: -0.6261 - val_metric_choose_argument_global_y_train: 0.0787\n",
            "Epoch 8/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8199 - metric_choose_argument_global_y_train: 0.6258 - val_loss: -0.6173 - val_metric_choose_argument_global_y_train: 0.0701\n",
            "Epoch 9/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8310 - metric_choose_argument_global_y_train: 0.6860 - val_loss: -0.6097 - val_metric_choose_argument_global_y_train: 0.0738\n",
            "Epoch 10/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8392 - metric_choose_argument_global_y_train: 0.7051 - val_loss: -0.6038 - val_metric_choose_argument_global_y_train: 0.0713\n",
            "Epoch 11/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8463 - metric_choose_argument_global_y_train: 0.7306 - val_loss: -0.5953 - val_metric_choose_argument_global_y_train: 0.0713\n",
            "Epoch 12/20\n",
            "3252/3252 [==============================] - 18s 5ms/step - loss: -0.8526 - metric_choose_argument_global_y_train: 0.7420 - val_loss: -0.5941 - val_metric_choose_argument_global_y_train: 0.0738\n",
            "Epoch 13/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8574 - metric_choose_argument_global_y_train: 0.7494 - val_loss: -0.5886 - val_metric_choose_argument_global_y_train: 0.0689\n",
            "Epoch 14/20\n",
            "3252/3252 [==============================] - 21s 6ms/step - loss: -0.8618 - metric_choose_argument_global_y_train: 0.7552 - val_loss: -0.5868 - val_metric_choose_argument_global_y_train: 0.0750\n",
            "Epoch 15/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8657 - metric_choose_argument_global_y_train: 0.7500 - val_loss: -0.5820 - val_metric_choose_argument_global_y_train: 0.0590\n",
            "Epoch 16/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8690 - metric_choose_argument_global_y_train: 0.7522 - val_loss: -0.5838 - val_metric_choose_argument_global_y_train: 0.0652\n",
            "Epoch 17/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8722 - metric_choose_argument_global_y_train: 0.7595 - val_loss: -0.5815 - val_metric_choose_argument_global_y_train: 0.0677\n",
            "Epoch 18/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8747 - metric_choose_argument_global_y_train: 0.7583 - val_loss: -0.5757 - val_metric_choose_argument_global_y_train: 0.0664\n",
            "Epoch 19/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8773 - metric_choose_argument_global_y_train: 0.7632 - val_loss: -0.5752 - val_metric_choose_argument_global_y_train: 0.0664\n",
            "Epoch 20/20\n",
            "3252/3252 [==============================] - 17s 5ms/step - loss: -0.8793 - metric_choose_argument_global_y_train: 0.7632 - val_loss: -0.5752 - val_metric_choose_argument_global_y_train: 0.0627\n"
          ]
        }
      ],
      "source": [
        "# Global Shuffled Model\n",
        "global_shuffled_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "global_shuffled_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"cosine_similarity\",\n",
        "  metrics=[metric_choose_argument_global_y_train]\n",
        ")\n",
        "\n",
        "global_shuffled_history = global_shuffled_autoencoder_model.fit(\n",
        "  x=global_x_train,\n",
        "  y=global_y_train_shuffled,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data = (global_x_test, global_y_test)\n",
        ")"
      ],
      "id": "9887abb8-c075-46b4-9eee-b28922a61575"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "5i5lFFqIbNzh"
      },
      "outputs": [],
      "source": [
        "global_shuffled_history_df = pd.DataFrame(global_shuffled_history.history)"
      ],
      "id": "5i5lFFqIbNzh"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KOtX9nyBbNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_history_df.to_csv(f'{output_folder_path}global_shuffled_training_log.csv')"
      ],
      "id": "KOtX9nyBbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KrmhWBS2bNzk"
      },
      "outputs": [],
      "source": [
        "output_folder_path = 'current-data-dump/ada-autoencoder/'\n",
        "os.makedirs(output_folder_path, exist_ok=True)\n",
        "global_shuffled_autoencoder_model.save(f'{output_folder_path}global_shuffled_autoencoder_model.keras')"
      ],
      "id": "KrmhWBS2bNzk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export data"
      ],
      "metadata": {
        "id": "o4WdvaTBDg0Q"
      },
      "id": "o4WdvaTBDg0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "def export_ada_autoencoder():\n",
        "  \"\"\"Export ada_autoencoder directory\"\"\"\n",
        "  ada_autoencoder_file_path = 'current-data-dump/ada-autoencoder'\n",
        "  ada_autoencoder_file_path_zip = 'current-data-dump/ada-autoencoder'\n",
        "  shutil.make_archive(ada_autoencoder_file_path_zip, 'zip', ada_autoencoder_file_path)\n",
        "  print(f\"Zip file created at: {ada_autoencoder_file_path_zip}\")\n",
        "  result = subprocess.run([f\"osf -p sakjg upload --force {ada_autoencoder_file_path_zip}.zip data-dump/ada003-autoencoder/ada_autoencoder.zip\"], shell=True, capture_output=True, text=True)\n",
        "  print(result.stderr)\n",
        "  print(f\"File: {ada_autoencoder_file_path_zip} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "kPUJzZOEFmCY"
      },
      "id": "kPUJzZOEFmCY",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "HwCx1sldDjMC"
      },
      "id": "HwCx1sldDjMC"
    },
    {
      "cell_type": "code",
      "source": [
        "def import_ada_autoencoder():\n",
        "  \"\"\"Import ada_autoencoder directory\"\"\"\n",
        "  subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-autoencoder/ada_autoencoder.zip\", shell=True)\n",
        "  print(\"ada_autoencoder.zip successfully imported\")\n",
        "  ada_autoencoder_file_path_zip = 'ada_autoencoder.zip'\n",
        "  ada_autoencoder_file_path = 'current-data-dump/ada-autoencoder'\n",
        "  os.makedirs(ada_autoencoder_file_path, exist_ok=True)\n",
        "  with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(ada_autoencoder_file_path)\n",
        "  extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "  print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "I5nxJr5bGDTR"
      },
      "id": "I5nxJr5bGDTR",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TucNWIIdnBs"
      },
      "source": [
        "## Load global training history"
      ],
      "id": "8TucNWIIdnBs"
    },
    {
      "cell_type": "code",
      "source": [
        "import_ada_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go4cGqlJHOV-",
        "outputId": "d54a913c-475e-420b-ffdb-c5e5d4a781e6"
      },
      "id": "go4cGqlJHOV-",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_autoencoder_model.keras', 'global_shuffled_autoencoder_model.keras', 'global_shuffled_training_log.csv', 'global_shuffled_training_plot.png', 'global_training_plot.png', 'combined_global_training_plot.png', 'global_training_df.pkl', 'global_training_log.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unshuffled training history"
      ],
      "metadata": {
        "id": "JY2RndZJDXxt"
      },
      "id": "JY2RndZJDXxt"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_history = pd.DataFrame(pd.read_csv(\"current-data-dump/ada-autoencoder/global_training_log.csv\"))\n",
        "loaded_global_history = pd.melt(loaded_global_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_history = loaded_global_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_history['shuffled'] = False"
      ],
      "id": "3bce8a2b-e99c-4718-b2ed-445622266ea4"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690e3cdb-4717-4fff-a541-4d6e95112667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada-autoencoder/global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_training_plot = ggplot(loaded_global_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Unshuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_training_plot, \"current-data-dump/ada-autoencoder/global_training_plot.png\")"
      ],
      "id": "cfd55739-2fa0-434c-beef-64be4e2b4e99"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shuffled training history"
      ],
      "metadata": {
        "id": "bSIwS6ydDdXI"
      },
      "id": "bSIwS6ydDdXI"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "lJoOOL9EbNzk",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Access training history\n",
        "loaded_global_shuffled_history = pd.DataFrame(pd.read_csv(\"current-data-dump/ada-autoencoder/global_shuffled_training_log.csv\"))\n",
        "loaded_global_shuffled_history = pd.melt(loaded_global_shuffled_history, id_vars='Unnamed: 0', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
        "loaded_global_shuffled_history = loaded_global_shuffled_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
        "loaded_global_shuffled_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True)\n",
        "loaded_global_shuffled_history['shuffled'] = False"
      ],
      "id": "lJoOOL9EbNzk"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TK0YRBXybNzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8cc73b-b988-4550-d264-a95cf731e287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada-autoencoder/global_shuffled_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "global_shuffled_training_plot = ggplot(loaded_global_shuffled_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Shuffled Data', x='Epoch', y='Accuracy')\n",
        "ggsave(global_shuffled_training_plot, \"current-data-dump/ada-autoencoder/global_shuffled_training_plot.png\")"
      ],
      "id": "TK0YRBXybNzl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIYrWdyscsYt"
      },
      "source": [
        "## Combined Training Plots"
      ],
      "id": "nIYrWdyscsYt"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
      },
      "outputs": [],
      "source": [
        "combined_global_training_df = pd.concat([loaded_global_history, loaded_global_shuffled_history])"
      ],
      "id": "aa005bf9-931d-45d2-b0e0-149b78878886"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "e1197f06-5503-44a5-ba23-2858da1a82b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790cd839-a486-4b6b-f45c-1c2720db0db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 16 x 24 in image.\n",
            "/usr/local/lib/python3.10/dist-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: current-data-dump/ada-autoencoder/combined_global_training_plot.png\n"
          ]
        }
      ],
      "source": [
        "combined_global_plot = (\n",
        "  ggplot(combined_global_training_df, aes(x='epoch', y='accuracy', linetype='dataset', color='shuffled')) +\n",
        "  geom_line(size=2) +\n",
        "  labs(title='Learning Curve of Model Trained on Unshuffled vs. Within-Topic Shuffled Data', x='Epoch', y='Accuracy') +\n",
        "  theme(\n",
        "    figure_size=(16,24),\n",
        "    axis_title=element_text(size=32),\n",
        "    axis_text=element_text(size=24),\n",
        "    legend_title=element_text(size=32, lineheight=1.5),\n",
        "    legend_text=element_text(size=24, lineheight=1.5),\n",
        "    plot_title=element_text(size=40, wrap=True, lineheight=1.5),\n",
        "    legend_position=\"bottom\",\n",
        "    legend_key_width=64\n",
        "  ) +\n",
        "  guides(fill = guide_legend(byrow = True))\n",
        ")\n",
        "ggsave(combined_global_plot, \"current-data-dump/ada-autoencoder/combined_global_training_plot.png\")"
      ],
      "id": "e1197f06-5503-44a5-ba23-2858da1a82b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcX4eHsmdAP9"
      },
      "source": [
        "## Category and Debate Training"
      ],
      "id": "GcX4eHsmdAP9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
      },
      "source": [
        "#### Category Data (Economy)"
      ],
      "id": "597d7170-ccb1-42dc-adbf-74c10e3d167e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
      },
      "outputs": [],
      "source": [
        "economy_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/economy/economy_embeddings.pkl\")"
      ],
      "id": "063ce863-2c1b-4923-a4a6-5292b4eb46ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
      },
      "outputs": [],
      "source": [
        "economy_training_df = prepare_training_df(economy_embeddings_data)\n",
        "economy_x_train = make_x_train(economy_training_df)\n",
        "economy_y_train = make_y_train(economy_training_df)\n",
        "economy_x_test = make_x_test(economy_training_df)\n",
        "economy_y_test = make_y_test(economy_training_df)"
      ],
      "id": "da8f6826-fd45-42a9-ad58-128c029e1765"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95100c2-7782-4acd-9a0d-699223584b59"
      },
      "source": [
        "#### Debate Data (Economy)"
      ],
      "id": "f95100c2-7782-4acd-9a0d-699223584b59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b961764-4605-47a6-87e8-817eeffe7470"
      },
      "outputs": [],
      "source": [
        "economy_debate_embeddings_data = pd.read_pickle(\"current-data-dump/embeddings-dump/economy/business_economy_general_house_would_prohibit_retailers_selling_certain_items_embeddings.pkl\")"
      ],
      "id": "8b961764-4605-47a6-87e8-817eeffe7470"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
      },
      "outputs": [],
      "source": [
        "economy_debate_training_df = prepare_training_df(economy_debate_embeddings_data)\n",
        "economy_debate_x_train = make_x_train(economy_debate_training_df)\n",
        "economy_debate_y_train = make_y_train(economy_debate_training_df)\n",
        "economy_debate_x_test = make_x_test(economy_debate_training_df)\n",
        "economy_debate_y_test = make_y_test(economy_debate_training_df)"
      ],
      "id": "3ed1f1ce-df8b-4f66-b70a-9888cfd28b65"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
      },
      "source": [
        "#### Category Training"
      ],
      "id": "1b8c0c9d-40c8-44f9-bd14-9bba700bd814"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
      },
      "outputs": [],
      "source": [
        "# Category Model\n",
        "category_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "category_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "category_autoencoder_model.fit(\n",
        "  x=economy_x_train,\n",
        "  y=economy_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=20,\n",
        "  validation_data=(economy_x_test, economy_y_test)\n",
        ")"
      ],
      "id": "ec2272bb-8d23-4fee-82be-2bc619856840"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
      },
      "source": [
        "#### Debate Training"
      ],
      "id": "856d8fe6-e696-41ce-b918-b8404ffec630"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40b37636-96d3-4932-9d0e-6551b846730b"
      },
      "outputs": [],
      "source": [
        "# Debate Model\n",
        "debate_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
        "debate_autoencoder_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "  loss=\"mse\",\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "debate_autoencoder_model.fit(\n",
        "  x=economy_debate_x_train,\n",
        "  y=economy_debate_y_train,\n",
        "  batch_size=1,\n",
        "  epochs=5\n",
        ")"
      ],
      "id": "40b37636-96d3-4932-9d0e-6551b846730b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Export"
      ],
      "metadata": {
        "id": "KN2uP5TfHgmt"
      },
      "id": "KN2uP5TfHgmt"
    },
    {
      "cell_type": "code",
      "source": [
        "export_ada_autoencoder()"
      ],
      "metadata": {
        "id": "cxBVn4xAHiDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338c5362-3364-438c-f11f-7ced644fbdfd"
      },
      "id": "cxBVn4xAHiDD",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file created at: current-data-dump/ada-autoencoder\n",
            "\n",
            "File: current-data-dump/ada-autoencoder uploaded at osfstorage\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}