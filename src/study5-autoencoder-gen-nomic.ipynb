{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ec7ac3-f001-4642-8882-b2eadab3b1bc",
   "metadata": {},
   "source": [
    "# [Nomic] Autoencoder: Generate Corresponding Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98dd00d-ca0f-42ae-8fc5-8b3a84572364",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a4bb68-c601-4847-8f3a-290519da14cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 14:11:50.755027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from plotnine import ggplot, geom_line, aes, ggsave, labs, theme, element_text, guides, guide_legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4911e-32b3-40fe-8868-17d1acd6ae13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2805a861-c57d-4b7a-87d0-297cb7bb1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that do not follow 'point' -> 'counter' pattern\n",
    "def prepare_training_df(data: pd.DataFrame):\n",
    "    point_indices = data[data['type'] == 'point'].index\n",
    "    counter_indices = data[data['type'] == 'counter'].index\n",
    "    drop_indices = []\n",
    "    for idx in point_indices:\n",
    "        if (idx == len(data)-1) or (idx + 1 < len(data) and data.loc[idx + 1, 'type'] != 'counter'):\n",
    "            drop_indices.append(idx)\n",
    "    for idx in counter_indices:\n",
    "        if idx > 0 and data.loc[idx - 1, 'type'] != 'point':\n",
    "            drop_indices.append(idx)\n",
    "    data = data.drop(drop_indices)\n",
    "    data = data.select_dtypes(include=[np.number])\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abf74bd-40e8-41a1-9158-cc772318cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that do not follow 'point' -> 'counter' pattern\n",
    "def prepare_training_df_shuffled(data: pd.DataFrame):\n",
    "    point_indices = data[data['type'] == 'point'].index\n",
    "    counter_indices = data[data['type'] == 'counter'].index\n",
    "    drop_indices = []\n",
    "    for idx in point_indices:\n",
    "        if (idx == len(data)-1) or (idx + 1 < len(data) and data.loc[idx + 1, 'type'] != 'counter'):\n",
    "            drop_indices.append(idx)\n",
    "    for idx in counter_indices:\n",
    "        if idx > 0 and data.loc[idx - 1, 'type'] != 'point':\n",
    "            drop_indices.append(idx)\n",
    "    data = data.drop(drop_indices)\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc1ffbb-0dd5-4fb7-a2af-4fa3401da2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and testing datasets\n",
    "def make_x_train(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cutoff = int(0.8 * data.shape[0])\n",
    "    if cutoff % 2 != 0:\n",
    "        cutoff = cutoff - 1\n",
    "    train_rows_df = data.iloc[:cutoff, :]\n",
    "    x_train = train_rows_df[train_rows_df.index % 2 == 0].reset_index(drop=True)\n",
    "    return x_train\n",
    "    \n",
    "def make_y_train(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cutoff = int(0.8 * data.shape[0])\n",
    "    if cutoff % 2 != 0:\n",
    "        cutoff = cutoff - 1\n",
    "    train_rows_df = data.iloc[:cutoff, :]\n",
    "    y_train = train_rows_df[train_rows_df.index % 2 != 0].reset_index(drop=True)\n",
    "    return y_train\n",
    "\n",
    "def make_x_test(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cutoff = int(0.8 * data.shape[0])\n",
    "    if cutoff % 2 != 0:\n",
    "        cutoff = cutoff - 1\n",
    "    test_rows_df = data.iloc[cutoff:, :]\n",
    "    x_test = test_rows_df[test_rows_df.index % 2 == 0].reset_index(drop=True)\n",
    "    return x_test\n",
    "\n",
    "def make_y_test(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cutoff = int(0.8 * data.shape[0])\n",
    "    if cutoff % 2 != 0:\n",
    "        cutoff = cutoff - 1\n",
    "    test_rows_df = data.iloc[cutoff:, :]\n",
    "    y_test = test_rows_df[test_rows_df.index % 2 != 0].reset_index(drop=True)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0fe1d2-7f55-448a-b8c6-a7c46e7c637a",
   "metadata": {},
   "source": [
    "#### Global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca48654f-ca99-463c-95c3-bc5c67d49cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_embeddings_data = pd.read_pickle(\"../data_dump/nomic_embeddings_dump/global_sd_embeddings.pkl\")\n",
    "global_sq_embeddings_data = pd.read_pickle(\"../data_dump/nomic_embeddings_dump/global_sq_embeddings.pkl\")\n",
    "global_clu_embeddings_data = pd.read_pickle(\"../data_dump/nomic_embeddings_dump/global_clu_embeddings.pkl\")\n",
    "global_cla_embeddings_data = pd.read_pickle(\"../data_dump/nomic_embeddings_dump/global_cla_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9f15e3-8e6c-429a-a590-2b43d0233118",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_training_df = prepare_training_df(global_sd_embeddings_data)\n",
    "global_sq_training_df = prepare_training_df(global_sq_embeddings_data)\n",
    "global_clu_training_df = prepare_training_df(global_clu_embeddings_data)\n",
    "global_cla_training_df = prepare_training_df(global_cla_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b0aff5-d523-4547-bf92-f5b22a033be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_x_train = make_x_train(global_sd_training_df)\n",
    "global_sq_x_train = make_x_train(global_sq_training_df)\n",
    "global_clu_x_train = make_x_train(global_clu_training_df)\n",
    "global_cla_x_train = make_x_train(global_cla_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56341332-7e50-459d-96ec-cb2ab2b8c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_y_train = make_y_train(global_sd_training_df)\n",
    "global_sq_y_train = make_y_train(global_sq_training_df)\n",
    "global_clu_y_train = make_y_train(global_clu_training_df)\n",
    "global_cla_y_train = make_y_train(global_cla_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e3058f-79d5-4aef-900e-90f518fb058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_x_test = make_x_test(global_sd_training_df)\n",
    "global_sq_x_test = make_x_test(global_sq_training_df)\n",
    "global_clu_x_test = make_x_test(global_clu_training_df)\n",
    "global_cla_x_test = make_x_test(global_cla_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38293b96-f4e5-482f-ae88-c2d7c5e6e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_y_test = make_y_test(global_sd_training_df)\n",
    "global_sq_y_test = make_y_test(global_sq_training_df)\n",
    "global_clu_y_test = make_y_test(global_clu_training_df)\n",
    "global_cla_y_test = make_y_test(global_cla_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea17ecaa-1b1b-4234-be2f-8958eb4b6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_y_train_test = pd.concat([global_sd_y_train, global_sd_y_test], axis=0)\n",
    "global_sq_y_train_test = pd.concat([global_sq_y_train, global_sq_y_test], axis=0)\n",
    "global_clu_y_train_test = pd.concat([global_clu_y_train, global_clu_y_test], axis=0)\n",
    "global_cla_y_train_test = pd.concat([global_cla_y_train, global_cla_y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cea5d9-0c17-4be6-a3c0-78bf8bb517ea",
   "metadata": {},
   "source": [
    "#### Global data shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9aa81cf-11ac-4ea9-bdf8-866dbc2fd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_training_df_shuffled = prepare_training_df_shuffled(global_sd_embeddings_data)\n",
    "global_sq_training_df_shuffled = prepare_training_df_shuffled(global_sq_embeddings_data)\n",
    "global_clu_training_df_shuffled = prepare_training_df_shuffled(global_clu_embeddings_data)\n",
    "global_cla_training_df_shuffled = prepare_training_df_shuffled(global_cla_embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b86a2b2-d542-4daf-b7d1-19ebb8382834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_sd_y_train_shuffled = make_y_train(global_sd_training_df_shuffled)\n",
    "global_sq_y_train_shuffled = make_y_train(global_sq_training_df_shuffled)\n",
    "global_clu_y_train_shuffled = make_y_train(global_clu_training_df_shuffled)\n",
    "global_cla_y_train_shuffled = make_y_train(global_cla_training_df_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6a27ad8-3ab8-45c1-b412-dbbf82d32931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_sd_y_train_shuffled = global_sd_y_train_shuffled.groupby(['topic'], sort=False)\n",
    "global_sd_y_train_shuffled = global_sd_y_train_shuffled.sample(frac=1).reset_index(drop=True)\n",
    "global_sd_y_train_shuffled = global_sd_y_train_shuffled.select_dtypes(include=[np.number])\n",
    "\n",
    "global_sq_y_train_shuffled = global_sq_y_train_shuffled.groupby(['topic'], sort=False)\n",
    "global_sq_y_train_shuffled = global_sq_y_train_shuffled.sample(frac=1).reset_index(drop=True)\n",
    "global_sq_y_train_shuffled = global_sq_y_train_shuffled.select_dtypes(include=[np.number])\n",
    "\n",
    "global_clu_y_train_shuffled = global_clu_y_train_shuffled.groupby(['topic'], sort=False)\n",
    "global_clu_y_train_shuffled = global_clu_y_train_shuffled.sample(frac=1).reset_index(drop=True)\n",
    "global_clu_y_train_shuffled = global_clu_y_train_shuffled.select_dtypes(include=[np.number])\n",
    "\n",
    "global_cla_y_train_shuffled = global_cla_y_train_shuffled.groupby(['topic'], sort=False)\n",
    "global_cla_y_train_shuffled = global_cla_y_train_shuffled.sample(frac=1).reset_index(drop=True)\n",
    "global_cla_y_train_shuffled = global_cla_y_train_shuffled.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88110c7-68a6-4439-b4f2-768e080074c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93feaaf0-1fad-4f75-b546-d66198c4fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers\n",
    "input_layer = tf.keras.layers.Input(shape=(768, ), name=\"Input\")\n",
    "hidden_layer = tf.keras.layers.Dense(units=768, activation=\"relu\", name=\"Hidden\")(input_layer)\n",
    "output_layer = tf.keras.layers.Dense(units=768, activation=\"linear\", name=\"Output\")(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62655a3a-717c-4800-b06a-d8147740236c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 768)]             0         \n",
      "                                                                 \n",
      " Hidden (Dense)              (None, 768)               590592    \n",
      "                                                                 \n",
      " Output (Dense)              (None, 768)               590592    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1181184 (4.51 MB)\n",
      "Trainable params: 1181184 (4.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "autoencoder_model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b555b3f8-300b-4341-97e7-c14f67358e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_choose_argument_global_sd_y_train(y_true, y_pred):\n",
    "    \"\"\"global_sd_metric\"\"\"\n",
    "    global_sd_training_df_32 = tf.cast(global_sd_training_df, dtype=tf.float32)\n",
    "    \n",
    "    cos_sim_pred = tf.matmul(global_sd_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_sd_training_df_32, axis=1), [-1, 1])\n",
    "    cos_sim_true = tf.matmul(global_sd_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_sd_training_df_32, axis=1), [-1, 1])\n",
    "\n",
    "    max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
    "    max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
    "\n",
    "    return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24a15f84-9423-421a-ad76-56f0d1729ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_choose_argument_global_sq_y_train(y_true, y_pred):\n",
    "    \"\"\"global_sq_metric\"\"\"\n",
    "    global_sq_training_df_32 = tf.cast(global_sq_training_df, dtype=tf.float32)\n",
    "    \n",
    "    cos_sim_pred = tf.matmul(global_sq_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_sq_training_df_32, axis=1), [-1, 1])\n",
    "    cos_sim_true = tf.matmul(global_sq_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_sq_training_df_32, axis=1), [-1, 1])\n",
    "\n",
    "    max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
    "    max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
    "\n",
    "    return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76e44eb2-f020-44b7-a567-3ddde7b44a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_choose_argument_global_clu_y_train(y_true, y_pred):\n",
    "    \"\"\"global_clu_metric\"\"\"\n",
    "    global_clu_training_df_32 = tf.cast(global_clu_training_df, dtype=tf.float32)\n",
    "    \n",
    "    cos_sim_pred = tf.matmul(global_clu_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_clu_training_df_32, axis=1), [-1, 1])\n",
    "    cos_sim_true = tf.matmul(global_clu_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_clu_training_df_32, axis=1), [-1, 1])\n",
    "\n",
    "    max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
    "    max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
    "\n",
    "    return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "503f94f2-6b33-4869-b3e3-5be564938aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_choose_argument_global_cla_y_train(y_true, y_pred):\n",
    "    \"\"\"global_cla_metric\"\"\"\n",
    "    global_cla_training_df_32 = tf.cast(global_cla_training_df, dtype=tf.float32)\n",
    "    \n",
    "    cos_sim_pred = tf.matmul(global_cla_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_cla_training_df_32, axis=1), [-1, 1])\n",
    "    cos_sim_true = tf.matmul(global_cla_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_cla_training_df_32, axis=1), [-1, 1])\n",
    "\n",
    "    max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
    "    max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
    "\n",
    "    return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a58c13-c646-4917-b46e-68feb7d2fa14",
   "metadata": {},
   "source": [
    "#### Global Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "468fd859-1bb5-423c-856f-c68ea7a3573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global SD Model\n",
    "global_sd_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_sd_autoencoder_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_sd_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0164d591-551a-40b6-8d76-1b31b8412303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global SQ Model\n",
    "global_sq_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_sq_autoencoder_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_sq_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "907c2bcc-9dc5-43f0-a108-e8ddce0ef64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global CLU Model\n",
    "global_clu_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_clu_autoencoder_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_clu_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3e2a936-c4aa-4765-83df-7918e230b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global CLA Model\n",
    "global_cla_autoencoder_model = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_cla_autoencoder_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_cla_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580e44ab-0401-4077-a038-7e94b14a6540",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d732d24-44ea-4e1d-b722-256ebd7b6a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.7921 - metric_choose_argument_global_sd_y_train: 0.0197\n",
      "Epoch 1: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 52s 15ms/step - loss: -0.7921 - metric_choose_argument_global_sd_y_train: 0.0200 - val_loss: -0.8054 - val_metric_choose_argument_global_sd_y_train: 0.0492\n",
      "Epoch 2/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8271 - metric_choose_argument_global_sd_y_train: 0.0800\n",
      "Epoch 2: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 45s 14ms/step - loss: -0.8271 - metric_choose_argument_global_sd_y_train: 0.0800 - val_loss: -0.8184 - val_metric_choose_argument_global_sd_y_train: 0.0713\n",
      "Epoch 3/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8431 - metric_choose_argument_global_sd_y_train: 0.1508\n",
      "Epoch 3: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 41s 12ms/step - loss: -0.8431 - metric_choose_argument_global_sd_y_train: 0.1507 - val_loss: -0.8238 - val_metric_choose_argument_global_sd_y_train: 0.1169\n",
      "Epoch 4/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8548 - metric_choose_argument_global_sd_y_train: 0.2615\n",
      "Epoch 4: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.8548 - metric_choose_argument_global_sd_y_train: 0.2614 - val_loss: -0.8279 - val_metric_choose_argument_global_sd_y_train: 0.1390\n",
      "Epoch 5/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8639 - metric_choose_argument_global_sd_y_train: 0.3529\n",
      "Epoch 5: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8639 - metric_choose_argument_global_sd_y_train: 0.3530 - val_loss: -0.8298 - val_metric_choose_argument_global_sd_y_train: 0.2017\n",
      "Epoch 6/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8712 - metric_choose_argument_global_sd_y_train: 0.4508\n",
      "Epoch 6: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 43s 13ms/step - loss: -0.8712 - metric_choose_argument_global_sd_y_train: 0.4508 - val_loss: -0.8317 - val_metric_choose_argument_global_sd_y_train: 0.2202\n",
      "Epoch 7/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8771 - metric_choose_argument_global_sd_y_train: 0.5325\n",
      "Epoch 7: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.8771 - metric_choose_argument_global_sd_y_train: 0.5323 - val_loss: -0.8316 - val_metric_choose_argument_global_sd_y_train: 0.2608\n",
      "Epoch 8/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8818 - metric_choose_argument_global_sd_y_train: 0.5974\n",
      "Epoch 8: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8818 - metric_choose_argument_global_sd_y_train: 0.5975 - val_loss: -0.8309 - val_metric_choose_argument_global_sd_y_train: 0.2780\n",
      "Epoch 9/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8859 - metric_choose_argument_global_sd_y_train: 0.6626\n",
      "Epoch 9: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 42s 13ms/step - loss: -0.8859 - metric_choose_argument_global_sd_y_train: 0.6624 - val_loss: -0.8326 - val_metric_choose_argument_global_sd_y_train: 0.3161\n",
      "Epoch 10/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8893 - metric_choose_argument_global_sd_y_train: 0.7070\n",
      "Epoch 10: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 42s 13ms/step - loss: -0.8893 - metric_choose_argument_global_sd_y_train: 0.7073 - val_loss: -0.8322 - val_metric_choose_argument_global_sd_y_train: 0.3296\n",
      "Epoch 11/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8923 - metric_choose_argument_global_sd_y_train: 0.7538\n",
      "Epoch 11: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.8923 - metric_choose_argument_global_sd_y_train: 0.7534 - val_loss: -0.8318 - val_metric_choose_argument_global_sd_y_train: 0.3604\n",
      "Epoch 12/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8950 - metric_choose_argument_global_sd_y_train: 0.7829\n",
      "Epoch 12: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8950 - metric_choose_argument_global_sd_y_train: 0.7829 - val_loss: -0.8320 - val_metric_choose_argument_global_sd_y_train: 0.3801\n",
      "Epoch 13/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8972 - metric_choose_argument_global_sd_y_train: 0.8152\n",
      "Epoch 13: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8972 - metric_choose_argument_global_sd_y_train: 0.8152 - val_loss: -0.8325 - val_metric_choose_argument_global_sd_y_train: 0.3788\n",
      "Epoch 14/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8993 - metric_choose_argument_global_sd_y_train: 0.8398\n",
      "Epoch 14: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8993 - metric_choose_argument_global_sd_y_train: 0.8398 - val_loss: -0.8326 - val_metric_choose_argument_global_sd_y_train: 0.3850\n",
      "Epoch 15/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9013 - metric_choose_argument_global_sd_y_train: 0.8643\n",
      "Epoch 15: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.9012 - metric_choose_argument_global_sd_y_train: 0.8638 - val_loss: -0.8319 - val_metric_choose_argument_global_sd_y_train: 0.3924\n",
      "Epoch 16/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.9028 - metric_choose_argument_global_sd_y_train: 0.8763\n",
      "Epoch 16: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9028 - metric_choose_argument_global_sd_y_train: 0.8764 - val_loss: -0.8337 - val_metric_choose_argument_global_sd_y_train: 0.3961\n",
      "Epoch 17/20\n",
      "3247/3252 [============================>.] - ETA: 0s - loss: -0.9044 - metric_choose_argument_global_sd_y_train: 0.8922\n",
      "Epoch 17: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.9044 - metric_choose_argument_global_sd_y_train: 0.8921 - val_loss: -0.8325 - val_metric_choose_argument_global_sd_y_train: 0.4133\n",
      "Epoch 18/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9058 - metric_choose_argument_global_sd_y_train: 0.9012\n",
      "Epoch 18: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9057 - metric_choose_argument_global_sd_y_train: 0.9010 - val_loss: -0.8326 - val_metric_choose_argument_global_sd_y_train: 0.4096\n",
      "Epoch 19/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.9070 - metric_choose_argument_global_sd_y_train: 0.9148\n",
      "Epoch 19: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.9070 - metric_choose_argument_global_sd_y_train: 0.9148 - val_loss: -0.8310 - val_metric_choose_argument_global_sd_y_train: 0.4010\n",
      "Epoch 20/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.9082 - metric_choose_argument_global_sd_y_train: 0.9191\n",
      "Epoch 20: saving model to nomic_autoencoder/global_sd_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.9082 - metric_choose_argument_global_sd_y_train: 0.9191 - val_loss: -0.8316 - val_metric_choose_argument_global_sd_y_train: 0.4157\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_sd_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_sd_training_log.csv', separator=',', append=True)\n",
    "\n",
    "global_sd_history = global_sd_autoencoder_model.fit(\n",
    "    x=global_sd_x_train,\n",
    "    y=global_sd_y_train,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_sd_x_test, global_sd_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e71b2f6-5988-4571-870e-0297f4cdcafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_autoencoder_model.save('nomic_autoencoder/global_sd_autoencoder_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b1b5ebe-6c92-4984-87ab-8b9bb094fa50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.7573 - metric_choose_argument_global_sq_y_train: 0.0197\n",
      "Epoch 1: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 44s 13ms/step - loss: -0.7573 - metric_choose_argument_global_sq_y_train: 0.0197 - val_loss: -0.7664 - val_metric_choose_argument_global_sq_y_train: 0.0492\n",
      "Epoch 2/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.7999 - metric_choose_argument_global_sq_y_train: 0.0723\n",
      "Epoch 2: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.7999 - metric_choose_argument_global_sq_y_train: 0.0723 - val_loss: -0.7862 - val_metric_choose_argument_global_sq_y_train: 0.0861\n",
      "Epoch 3/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8195 - metric_choose_argument_global_sq_y_train: 0.1618\n",
      "Epoch 3: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8195 - metric_choose_argument_global_sq_y_train: 0.1617 - val_loss: -0.7932 - val_metric_choose_argument_global_sq_y_train: 0.1156\n",
      "Epoch 4/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8342 - metric_choose_argument_global_sq_y_train: 0.2736\n",
      "Epoch 4: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8342 - metric_choose_argument_global_sq_y_train: 0.2737 - val_loss: -0.7979 - val_metric_choose_argument_global_sq_y_train: 0.1710\n",
      "Epoch 5/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8456 - metric_choose_argument_global_sq_y_train: 0.3778\n",
      "Epoch 5: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8456 - metric_choose_argument_global_sq_y_train: 0.3779 - val_loss: -0.8019 - val_metric_choose_argument_global_sq_y_train: 0.2140\n",
      "Epoch 6/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8546 - metric_choose_argument_global_sq_y_train: 0.4928\n",
      "Epoch 6: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8546 - metric_choose_argument_global_sq_y_train: 0.4926 - val_loss: -0.8021 - val_metric_choose_argument_global_sq_y_train: 0.2558\n",
      "Epoch 7/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8620 - metric_choose_argument_global_sq_y_train: 0.5711\n",
      "Epoch 7: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8620 - metric_choose_argument_global_sq_y_train: 0.5713 - val_loss: -0.8032 - val_metric_choose_argument_global_sq_y_train: 0.2915\n",
      "Epoch 8/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8678 - metric_choose_argument_global_sq_y_train: 0.6436\n",
      "Epoch 8: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8678 - metric_choose_argument_global_sq_y_train: 0.6436 - val_loss: -0.8041 - val_metric_choose_argument_global_sq_y_train: 0.3235\n",
      "Epoch 9/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8726 - metric_choose_argument_global_sq_y_train: 0.7113\n",
      "Epoch 9: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8727 - metric_choose_argument_global_sq_y_train: 0.7116 - val_loss: -0.8043 - val_metric_choose_argument_global_sq_y_train: 0.3309\n",
      "Epoch 10/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8768 - metric_choose_argument_global_sq_y_train: 0.7538\n",
      "Epoch 10: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8768 - metric_choose_argument_global_sq_y_train: 0.7534 - val_loss: -0.8040 - val_metric_choose_argument_global_sq_y_train: 0.3555\n",
      "Epoch 11/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8804 - metric_choose_argument_global_sq_y_train: 0.7839\n",
      "Epoch 11: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8804 - metric_choose_argument_global_sq_y_train: 0.7838 - val_loss: -0.8028 - val_metric_choose_argument_global_sq_y_train: 0.3678\n",
      "Epoch 12/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8834 - metric_choose_argument_global_sq_y_train: 0.8235\n",
      "Epoch 12: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8834 - metric_choose_argument_global_sq_y_train: 0.8235 - val_loss: -0.8033 - val_metric_choose_argument_global_sq_y_train: 0.3776\n",
      "Epoch 13/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8861 - metric_choose_argument_global_sq_y_train: 0.8476\n",
      "Epoch 13: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8861 - metric_choose_argument_global_sq_y_train: 0.8475 - val_loss: -0.8027 - val_metric_choose_argument_global_sq_y_train: 0.3788\n",
      "Epoch 14/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8885 - metric_choose_argument_global_sq_y_train: 0.8720\n",
      "Epoch 14: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 36s 11ms/step - loss: -0.8885 - metric_choose_argument_global_sq_y_train: 0.8721 - val_loss: -0.8030 - val_metric_choose_argument_global_sq_y_train: 0.3924\n",
      "Epoch 15/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8906 - metric_choose_argument_global_sq_y_train: 0.8837\n",
      "Epoch 15: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8906 - metric_choose_argument_global_sq_y_train: 0.8838 - val_loss: -0.8027 - val_metric_choose_argument_global_sq_y_train: 0.3899\n",
      "Epoch 16/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8925 - metric_choose_argument_global_sq_y_train: 0.8981\n",
      "Epoch 16: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8925 - metric_choose_argument_global_sq_y_train: 0.8982 - val_loss: -0.8017 - val_metric_choose_argument_global_sq_y_train: 0.3948\n",
      "Epoch 17/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8943 - metric_choose_argument_global_sq_y_train: 0.9117\n",
      "Epoch 17: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8943 - metric_choose_argument_global_sq_y_train: 0.9111 - val_loss: -0.8017 - val_metric_choose_argument_global_sq_y_train: 0.4034\n",
      "Epoch 18/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8958 - metric_choose_argument_global_sq_y_train: 0.9236\n",
      "Epoch 18: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8959 - metric_choose_argument_global_sq_y_train: 0.9237 - val_loss: -0.8013 - val_metric_choose_argument_global_sq_y_train: 0.4047\n",
      "Epoch 19/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8973 - metric_choose_argument_global_sq_y_train: 0.9293\n",
      "Epoch 19: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8973 - metric_choose_argument_global_sq_y_train: 0.9293 - val_loss: -0.8011 - val_metric_choose_argument_global_sq_y_train: 0.4084\n",
      "Epoch 20/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8986 - metric_choose_argument_global_sq_y_train: 0.9354\n",
      "Epoch 20: saving model to nomic_autoencoder/global_sq_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8986 - metric_choose_argument_global_sq_y_train: 0.9354 - val_loss: -0.8014 - val_metric_choose_argument_global_sq_y_train: 0.4059\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_sq_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_sq_training_log.csv', separator=',', append=True)\n",
    "\n",
    "global_sq_history = global_sq_autoencoder_model.fit(\n",
    "    x=global_sq_x_train,\n",
    "    y=global_sq_y_train,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_sq_x_test, global_sq_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc8518ad-4051-4b9e-b62c-3c0d044171fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sq_autoencoder_model.save('nomic_autoencoder/global_sq_autoencoder_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6e60153-0329-4810-81c4-6372d628de63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3247/3252 [============================>.] - ETA: 0s - loss: -0.7952 - metric_choose_argument_global_clu_y_train: 0.0330\n",
      "Epoch 1: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 42s 12ms/step - loss: -0.7953 - metric_choose_argument_global_clu_y_train: 0.0329 - val_loss: -0.8054 - val_metric_choose_argument_global_clu_y_train: 0.0812\n",
      "Epoch 2/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8361 - metric_choose_argument_global_clu_y_train: 0.0950\n",
      "Epoch 2: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8361 - metric_choose_argument_global_clu_y_train: 0.0953 - val_loss: -0.8191 - val_metric_choose_argument_global_clu_y_train: 0.0898\n",
      "Epoch 3/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8526 - metric_choose_argument_global_clu_y_train: 0.1480\n",
      "Epoch 3: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8526 - metric_choose_argument_global_clu_y_train: 0.1479 - val_loss: -0.8281 - val_metric_choose_argument_global_clu_y_train: 0.1328\n",
      "Epoch 4/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8637 - metric_choose_argument_global_clu_y_train: 0.2335\n",
      "Epoch 4: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8637 - metric_choose_argument_global_clu_y_train: 0.2337 - val_loss: -0.8322 - val_metric_choose_argument_global_clu_y_train: 0.1562\n",
      "Epoch 5/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8724 - metric_choose_argument_global_clu_y_train: 0.3282\n",
      "Epoch 5: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8724 - metric_choose_argument_global_clu_y_train: 0.3281 - val_loss: -0.8337 - val_metric_choose_argument_global_clu_y_train: 0.1919\n",
      "Epoch 6/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8791 - metric_choose_argument_global_clu_y_train: 0.4116\n",
      "Epoch 6: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8791 - metric_choose_argument_global_clu_y_train: 0.4111 - val_loss: -0.8379 - val_metric_choose_argument_global_clu_y_train: 0.2214\n",
      "Epoch 7/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8848 - metric_choose_argument_global_clu_y_train: 0.4925\n",
      "Epoch 7: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8847 - metric_choose_argument_global_clu_y_train: 0.4923 - val_loss: -0.8371 - val_metric_choose_argument_global_clu_y_train: 0.2485\n",
      "Epoch 8/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8895 - metric_choose_argument_global_clu_y_train: 0.5712\n",
      "Epoch 8: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8895 - metric_choose_argument_global_clu_y_train: 0.5713 - val_loss: -0.8371 - val_metric_choose_argument_global_clu_y_train: 0.2915\n",
      "Epoch 9/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8936 - metric_choose_argument_global_clu_y_train: 0.6201\n",
      "Epoch 9: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8936 - metric_choose_argument_global_clu_y_train: 0.6202 - val_loss: -0.8371 - val_metric_choose_argument_global_clu_y_train: 0.2940\n",
      "Epoch 10/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8969 - metric_choose_argument_global_clu_y_train: 0.6807\n",
      "Epoch 10: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8969 - metric_choose_argument_global_clu_y_train: 0.6805 - val_loss: -0.8364 - val_metric_choose_argument_global_clu_y_train: 0.3284\n",
      "Epoch 11/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8999 - metric_choose_argument_global_clu_y_train: 0.7158\n",
      "Epoch 11: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 12ms/step - loss: -0.8998 - metric_choose_argument_global_clu_y_train: 0.7159 - val_loss: -0.8366 - val_metric_choose_argument_global_clu_y_train: 0.3370\n",
      "Epoch 12/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9024 - metric_choose_argument_global_clu_y_train: 0.7553\n",
      "Epoch 12: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.9024 - metric_choose_argument_global_clu_y_train: 0.7555 - val_loss: -0.8373 - val_metric_choose_argument_global_clu_y_train: 0.3530\n",
      "Epoch 13/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.9048 - metric_choose_argument_global_clu_y_train: 0.7880\n",
      "Epoch 13: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.9048 - metric_choose_argument_global_clu_y_train: 0.7878 - val_loss: -0.8379 - val_metric_choose_argument_global_clu_y_train: 0.3690\n",
      "Epoch 14/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9068 - metric_choose_argument_global_clu_y_train: 0.8113\n",
      "Epoch 14: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.9068 - metric_choose_argument_global_clu_y_train: 0.8115 - val_loss: -0.8370 - val_metric_choose_argument_global_clu_y_train: 0.3678\n",
      "Epoch 15/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.9086 - metric_choose_argument_global_clu_y_train: 0.8373\n",
      "Epoch 15: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 35s 11ms/step - loss: -0.9086 - metric_choose_argument_global_clu_y_train: 0.8373 - val_loss: -0.8366 - val_metric_choose_argument_global_clu_y_train: 0.3850\n",
      "Epoch 16/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.9103 - metric_choose_argument_global_clu_y_train: 0.8573\n",
      "Epoch 16: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9103 - metric_choose_argument_global_clu_y_train: 0.8573 - val_loss: -0.8367 - val_metric_choose_argument_global_clu_y_train: 0.3899\n",
      "Epoch 17/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.9118 - metric_choose_argument_global_clu_y_train: 0.8650\n",
      "Epoch 17: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.9118 - metric_choose_argument_global_clu_y_train: 0.8650 - val_loss: -0.8364 - val_metric_choose_argument_global_clu_y_train: 0.3998\n",
      "Epoch 18/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9132 - metric_choose_argument_global_clu_y_train: 0.8840\n",
      "Epoch 18: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.9132 - metric_choose_argument_global_clu_y_train: 0.8838 - val_loss: -0.8366 - val_metric_choose_argument_global_clu_y_train: 0.4121\n",
      "Epoch 19/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.9145 - metric_choose_argument_global_clu_y_train: 0.8938\n",
      "Epoch 19: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.9145 - metric_choose_argument_global_clu_y_train: 0.8939 - val_loss: -0.8364 - val_metric_choose_argument_global_clu_y_train: 0.4010\n",
      "Epoch 20/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9157 - metric_choose_argument_global_clu_y_train: 0.9052\n",
      "Epoch 20: saving model to nomic_autoencoder/global_clu_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.9157 - metric_choose_argument_global_clu_y_train: 0.9050 - val_loss: -0.8353 - val_metric_choose_argument_global_clu_y_train: 0.4121\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_clu_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_clu_training_log.csv', separator=',', append=True)\n",
    "\n",
    "global_clu_history = global_clu_autoencoder_model.fit(\n",
    "    x=global_clu_x_train,\n",
    "    y=global_clu_y_train,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_clu_x_test, global_clu_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a9cfbb7-83b4-4490-92f5-d06a7e2500ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_clu_autoencoder_model.save('nomic_autoencoder/global_clu_autoencoder_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f6b6408-3ccb-4c1b-b6ad-bfc08dc47d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.7879 - metric_choose_argument_global_cla_y_train: 0.0280\n",
      "Epoch 1: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 43s 12ms/step - loss: -0.7880 - metric_choose_argument_global_cla_y_train: 0.0283 - val_loss: -0.7986 - val_metric_choose_argument_global_cla_y_train: 0.0517\n",
      "Epoch 2/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8281 - metric_choose_argument_global_cla_y_train: 0.0812\n",
      "Epoch 2: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8281 - metric_choose_argument_global_cla_y_train: 0.0812 - val_loss: -0.8154 - val_metric_choose_argument_global_cla_y_train: 0.0763\n",
      "Epoch 3/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8447 - metric_choose_argument_global_cla_y_train: 0.1443\n",
      "Epoch 3: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8447 - metric_choose_argument_global_cla_y_train: 0.1442 - val_loss: -0.8220 - val_metric_choose_argument_global_cla_y_train: 0.1107\n",
      "Epoch 4/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8566 - metric_choose_argument_global_cla_y_train: 0.2358\n",
      "Epoch 4: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8566 - metric_choose_argument_global_cla_y_train: 0.2355 - val_loss: -0.8245 - val_metric_choose_argument_global_cla_y_train: 0.1427\n",
      "Epoch 5/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8662 - metric_choose_argument_global_cla_y_train: 0.3447\n",
      "Epoch 5: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8662 - metric_choose_argument_global_cla_y_train: 0.3447 - val_loss: -0.8295 - val_metric_choose_argument_global_cla_y_train: 0.2042\n",
      "Epoch 6/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8738 - metric_choose_argument_global_cla_y_train: 0.4240\n",
      "Epoch 6: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8738 - metric_choose_argument_global_cla_y_train: 0.4240 - val_loss: -0.8305 - val_metric_choose_argument_global_cla_y_train: 0.2128\n",
      "Epoch 7/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8802 - metric_choose_argument_global_cla_y_train: 0.5166\n",
      "Epoch 7: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8802 - metric_choose_argument_global_cla_y_train: 0.5169 - val_loss: -0.8325 - val_metric_choose_argument_global_cla_y_train: 0.2509\n",
      "Epoch 8/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8854 - metric_choose_argument_global_cla_y_train: 0.5817\n",
      "Epoch 8: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8854 - metric_choose_argument_global_cla_y_train: 0.5818 - val_loss: -0.8325 - val_metric_choose_argument_global_cla_y_train: 0.2804\n",
      "Epoch 9/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8898 - metric_choose_argument_global_cla_y_train: 0.6506\n",
      "Epoch 9: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8899 - metric_choose_argument_global_cla_y_train: 0.6507 - val_loss: -0.8335 - val_metric_choose_argument_global_cla_y_train: 0.3100\n",
      "Epoch 10/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8937 - metric_choose_argument_global_cla_y_train: 0.6988\n",
      "Epoch 10: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 33s 10ms/step - loss: -0.8937 - metric_choose_argument_global_cla_y_train: 0.6990 - val_loss: -0.8338 - val_metric_choose_argument_global_cla_y_train: 0.3173\n",
      "Epoch 11/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8972 - metric_choose_argument_global_cla_y_train: 0.7496\n",
      "Epoch 11: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8972 - metric_choose_argument_global_cla_y_train: 0.7494 - val_loss: -0.8330 - val_metric_choose_argument_global_cla_y_train: 0.3469\n",
      "Epoch 12/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.9000 - metric_choose_argument_global_cla_y_train: 0.7828\n",
      "Epoch 12: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.9000 - metric_choose_argument_global_cla_y_train: 0.7829 - val_loss: -0.8343 - val_metric_choose_argument_global_cla_y_train: 0.3801\n",
      "Epoch 13/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.9026 - metric_choose_argument_global_cla_y_train: 0.8193\n",
      "Epoch 13: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9026 - metric_choose_argument_global_cla_y_train: 0.8195 - val_loss: -0.8334 - val_metric_choose_argument_global_cla_y_train: 0.3665\n",
      "Epoch 14/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.9049 - metric_choose_argument_global_cla_y_train: 0.8480\n",
      "Epoch 14: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9049 - metric_choose_argument_global_cla_y_train: 0.8481 - val_loss: -0.8335 - val_metric_choose_argument_global_cla_y_train: 0.3788\n",
      "Epoch 15/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.9070 - metric_choose_argument_global_cla_y_train: 0.8683\n",
      "Epoch 15: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9070 - metric_choose_argument_global_cla_y_train: 0.8684 - val_loss: -0.8333 - val_metric_choose_argument_global_cla_y_train: 0.3875\n",
      "Epoch 16/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.9089 - metric_choose_argument_global_cla_y_train: 0.8850\n",
      "Epoch 16: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.9089 - metric_choose_argument_global_cla_y_train: 0.8850 - val_loss: -0.8328 - val_metric_choose_argument_global_cla_y_train: 0.4047\n",
      "Epoch 17/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.9105 - metric_choose_argument_global_cla_y_train: 0.8991\n",
      "Epoch 17: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9105 - metric_choose_argument_global_cla_y_train: 0.8991 - val_loss: -0.8329 - val_metric_choose_argument_global_cla_y_train: 0.3961\n",
      "Epoch 18/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.9122 - metric_choose_argument_global_cla_y_train: 0.9148\n",
      "Epoch 18: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 34s 11ms/step - loss: -0.9122 - metric_choose_argument_global_cla_y_train: 0.9148 - val_loss: -0.8323 - val_metric_choose_argument_global_cla_y_train: 0.3998\n",
      "Epoch 19/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.9136 - metric_choose_argument_global_cla_y_train: 0.9209\n",
      "Epoch 19: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9135 - metric_choose_argument_global_cla_y_train: 0.9210 - val_loss: -0.8332 - val_metric_choose_argument_global_cla_y_train: 0.4121\n",
      "Epoch 20/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.9149 - metric_choose_argument_global_cla_y_train: 0.9311\n",
      "Epoch 20: saving model to nomic_autoencoder/global_cla_autoencoder_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.9149 - metric_choose_argument_global_cla_y_train: 0.9311 - val_loss: -0.8321 - val_metric_choose_argument_global_cla_y_train: 0.4133\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_cla_autoencoder_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_cla_training_log.csv', separator=',', append=True)\n",
    "\n",
    "global_cla_history = global_cla_autoencoder_model.fit(\n",
    "    x=global_cla_x_train,\n",
    "    y=global_cla_y_train,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_cla_x_test, global_cla_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64040bbc-a1aa-4cea-94bc-e659bba8a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cla_autoencoder_model.save('nomic_autoencoder/global_cla_autoencoder_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202d007-c0cf-448b-9839-7743563c6214",
   "metadata": {},
   "source": [
    "## Load  Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "874a7439-7c16-4da5-b3a2-875fd9b721fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Access training history\n",
    "loaded_sd_global_history = pd.DataFrame(pd.read_csv(\"nomic_autoencoder/global_sd_training_log.csv\"))\n",
    "loaded_sd_global_history = pd.melt(loaded_sd_global_history, id_vars='epoch', value_vars=['metric_choose_argument_global_sd_y_train', 'val_metric_choose_argument_global_sd_y_train'], var_name='dataset', value_name='accuracy')\n",
    "loaded_sd_global_history = loaded_sd_global_history.replace(['metric_choose_argument_global_sd_y_train', 'val_metric_choose_argument_global_sd_y_train'], ['training set', 'validation set'])\n",
    "loaded_sd_global_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True) \n",
    "loaded_sd_global_history['shuffled'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4479fcd0-51eb-450f-8654-f3c88666e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access training history\n",
    "loaded_sq_global_history = pd.DataFrame(pd.read_csv(\"nomic_autoencoder/global_sq_training_log.csv\"))\n",
    "loaded_sq_global_history = pd.melt(loaded_sq_global_history, id_vars='epoch', value_vars=['metric_choose_argument_global_sq_y_train', 'val_metric_choose_argument_global_sq_y_train'], var_name='dataset', value_name='accuracy')\n",
    "loaded_sq_global_history = loaded_sq_global_history.replace(['metric_choose_argument_global_sq_y_train', 'val_metric_choose_argument_global_sq_y_train'], ['training set', 'validation set'])\n",
    "# loaded_sq_global_history.rename(columns = {'Unnamed: 0':'epoch'}, inplace = True) \n",
    "loaded_sq_global_history['shuffled'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c071ed6-ba52-4f34-9ee5-901b6d9cf345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access training history\n",
    "loaded_clu_global_history = pd.DataFrame(pd.read_csv(\"nomic_autoencoder/global_clu_training_log.csv\"))\n",
    "loaded_clu_global_history = pd.melt(loaded_clu_global_history, id_vars='epoch', value_vars=['metric_choose_argument_global_clu_y_train', 'val_metric_choose_argument_global_clu_y_train'], var_name='dataset', value_name='accuracy')\n",
    "loaded_clu_global_history = loaded_clu_global_history.replace(['metric_choose_argument_global_clu_y_train', 'val_metric_choose_argument_global_clu_y_train'], ['training set', 'validation set'])\n",
    "loaded_clu_global_history['shuffled'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "039cf477-7a01-4d42-9792-dd521321719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access training history\n",
    "loaded_cla_global_history = pd.DataFrame(pd.read_csv(\"nomic_autoencoder/global_cla_training_log.csv\"))\n",
    "loaded_cla_global_history = pd.melt(loaded_cla_global_history, id_vars='epoch', value_vars=['metric_choose_argument_global_cla_y_train', 'val_metric_choose_argument_global_cla_y_train'], var_name='dataset', value_name='accuracy')\n",
    "loaded_cla_global_history = loaded_cla_global_history.replace(['metric_choose_argument_global_cla_y_train', 'val_metric_choose_argument_global_cla_y_train'], ['training set', 'validation set'])\n",
    "loaded_cla_global_history['shuffled'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1524d08-a966-43bc-9ed7-66f18d2bc2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/usr/local/lib/python3.11/site-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: ../data_dump/nomic_training_plots_dump/global_sd_training_plot.png\n"
     ]
    }
   ],
   "source": [
    "global_sd_training_plot = ggplot(loaded_sd_global_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Unshuffled Data', x='Epoch', y='Accuracy')\n",
    "ggsave(global_sd_training_plot, \"../data_dump/nomic_training_plots_dump/global_sd_training_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c30397-a19b-47d6-ad5e-1cf94fdf83fb",
   "metadata": {},
   "source": [
    "## Global Shuffled Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56823b00-23ee-4317-a902-5d512df28ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Shuffled SD Model\n",
    "global_sd_autoencoder_model_shuffled = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_sd_autoencoder_model_shuffled.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_sd_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ccb71ae-6dd8-4014-9c2b-b176b2a1529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Shuffled SQ Model\n",
    "global_sq_autoencoder_model_shuffled = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_sq_autoencoder_model_shuffled.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_sq_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aab757f6-00cb-4a18-983b-5f36f39b0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Shuffled CLU Model\n",
    "global_clu_autoencoder_model_shuffled = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_clu_autoencoder_model_shuffled.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_clu_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b58b044-0a28-4a08-8587-fd55996c7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Shuffled CLA Model\n",
    "global_cla_autoencoder_model_shuffled = tf.keras.models.clone_model(autoencoder_model)\n",
    "global_cla_autoencoder_model_shuffled.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"cosine_similarity\",\n",
    "    metrics=[metric_choose_argument_global_cla_y_train]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ac12e-d6a4-47aa-b0d0-53f7796116fd",
   "metadata": {},
   "source": [
    "## Shuffled Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cd431e0-1d94-495d-b63e-72899a3112ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8172 - metric_choose_argument_global_sd_y_train: 0.0862\n",
      "Epoch 1: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 43s 13ms/step - loss: -0.8173 - metric_choose_argument_global_sd_y_train: 0.0861 - val_loss: -0.8293 - val_metric_choose_argument_global_sd_y_train: 0.2362\n",
      "Epoch 2/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8327 - metric_choose_argument_global_sd_y_train: 0.1001\n",
      "Epoch 2: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 44s 14ms/step - loss: -0.8327 - metric_choose_argument_global_sd_y_train: 0.1002 - val_loss: -0.8294 - val_metric_choose_argument_global_sd_y_train: 0.2202\n",
      "Epoch 3/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8411 - metric_choose_argument_global_sd_y_train: 0.1200\n",
      "Epoch 3: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 43s 13ms/step - loss: -0.8411 - metric_choose_argument_global_sd_y_train: 0.1199 - val_loss: -0.8283 - val_metric_choose_argument_global_sd_y_train: 0.1980\n",
      "Epoch 4/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8472 - metric_choose_argument_global_sd_y_train: 0.1530\n",
      "Epoch 4: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 71s 22ms/step - loss: -0.8472 - metric_choose_argument_global_sd_y_train: 0.1528 - val_loss: -0.8268 - val_metric_choose_argument_global_sd_y_train: 0.1759\n",
      "Epoch 5/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8523 - metric_choose_argument_global_sd_y_train: 0.1848\n",
      "Epoch 5: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 65s 20ms/step - loss: -0.8523 - metric_choose_argument_global_sd_y_train: 0.1848 - val_loss: -0.8236 - val_metric_choose_argument_global_sd_y_train: 0.1599\n",
      "Epoch 6/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8566 - metric_choose_argument_global_sd_y_train: 0.2259\n",
      "Epoch 6: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8566 - metric_choose_argument_global_sd_y_train: 0.2260 - val_loss: -0.8208 - val_metric_choose_argument_global_sd_y_train: 0.1488\n",
      "Epoch 7/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8602 - metric_choose_argument_global_sd_y_train: 0.2694\n",
      "Epoch 7: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8602 - metric_choose_argument_global_sd_y_train: 0.2694 - val_loss: -0.8188 - val_metric_choose_argument_global_sd_y_train: 0.1328\n",
      "Epoch 8/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8635 - metric_choose_argument_global_sd_y_train: 0.3123\n",
      "Epoch 8: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8635 - metric_choose_argument_global_sd_y_train: 0.3121 - val_loss: -0.8165 - val_metric_choose_argument_global_sd_y_train: 0.1292\n",
      "Epoch 9/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8663 - metric_choose_argument_global_sd_y_train: 0.3566\n",
      "Epoch 9: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8663 - metric_choose_argument_global_sd_y_train: 0.3567 - val_loss: -0.8130 - val_metric_choose_argument_global_sd_y_train: 0.1169\n",
      "Epoch 10/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8687 - metric_choose_argument_global_sd_y_train: 0.3982\n",
      "Epoch 10: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8687 - metric_choose_argument_global_sd_y_train: 0.3982 - val_loss: -0.8102 - val_metric_choose_argument_global_sd_y_train: 0.0996\n",
      "Epoch 11/20\n",
      "3247/3252 [============================>.] - ETA: 0s - loss: -0.8711 - metric_choose_argument_global_sd_y_train: 0.4336\n",
      "Epoch 11: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 42s 13ms/step - loss: -0.8711 - metric_choose_argument_global_sd_y_train: 0.4330 - val_loss: -0.8090 - val_metric_choose_argument_global_sd_y_train: 0.0898\n",
      "Epoch 12/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8731 - metric_choose_argument_global_sd_y_train: 0.4738\n",
      "Epoch 12: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8730 - metric_choose_argument_global_sd_y_train: 0.4736 - val_loss: -0.8074 - val_metric_choose_argument_global_sd_y_train: 0.0849\n",
      "Epoch 13/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8749 - metric_choose_argument_global_sd_y_train: 0.5034\n",
      "Epoch 13: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 48s 15ms/step - loss: -0.8749 - metric_choose_argument_global_sd_y_train: 0.5034 - val_loss: -0.8050 - val_metric_choose_argument_global_sd_y_train: 0.0812\n",
      "Epoch 14/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8766 - metric_choose_argument_global_sd_y_train: 0.5332\n",
      "Epoch 14: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8767 - metric_choose_argument_global_sd_y_train: 0.5332 - val_loss: -0.8022 - val_metric_choose_argument_global_sd_y_train: 0.0738\n",
      "Epoch 15/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8781 - metric_choose_argument_global_sd_y_train: 0.5494\n",
      "Epoch 15: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 54s 17ms/step - loss: -0.8781 - metric_choose_argument_global_sd_y_train: 0.5492 - val_loss: -0.8003 - val_metric_choose_argument_global_sd_y_train: 0.0775\n",
      "Epoch 16/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8795 - metric_choose_argument_global_sd_y_train: 0.5815\n",
      "Epoch 16: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 51s 16ms/step - loss: -0.8795 - metric_choose_argument_global_sd_y_train: 0.5812 - val_loss: -0.7995 - val_metric_choose_argument_global_sd_y_train: 0.0713\n",
      "Epoch 17/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8807 - metric_choose_argument_global_sd_y_train: 0.6010\n",
      "Epoch 17: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 52s 16ms/step - loss: -0.8807 - metric_choose_argument_global_sd_y_train: 0.6009 - val_loss: -0.7961 - val_metric_choose_argument_global_sd_y_train: 0.0664\n",
      "Epoch 18/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8820 - metric_choose_argument_global_sd_y_train: 0.6298\n",
      "Epoch 18: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8820 - metric_choose_argument_global_sd_y_train: 0.6298 - val_loss: -0.7948 - val_metric_choose_argument_global_sd_y_train: 0.0664\n",
      "Epoch 19/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8830 - metric_choose_argument_global_sd_y_train: 0.6352\n",
      "Epoch 19: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 47s 14ms/step - loss: -0.8830 - metric_choose_argument_global_sd_y_train: 0.6353 - val_loss: -0.7930 - val_metric_choose_argument_global_sd_y_train: 0.0640\n",
      "Epoch 20/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8840 - metric_choose_argument_global_sd_y_train: 0.6574\n",
      "Epoch 20: saving model to nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8840 - metric_choose_argument_global_sd_y_train: 0.6571 - val_loss: -0.7921 - val_metric_choose_argument_global_sd_y_train: 0.0603\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_sd_autoencoder_shuffled_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_sd_training_shuffled_log.csv', separator=',', append=True)\n",
    "\n",
    "global_sd_history = global_sd_autoencoder_model.fit(\n",
    "    x=global_sd_x_train,\n",
    "    y=global_sd_y_train_shuffled,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_sd_x_test, global_sd_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d7c7363-93d4-46b2-b966-bb5d1b14d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sd_autoencoder_model.save('nomic_autoencoder/global_sd_autoencoder_shuffled_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a9573a7-0553-49bf-ba8c-36f8c7171b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.7393 - metric_choose_argument_global_sq_y_train: 0.0052\n",
      "Epoch 1: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 59s 17ms/step - loss: -0.7393 - metric_choose_argument_global_sq_y_train: 0.0052 - val_loss: -0.7534 - val_metric_choose_argument_global_sq_y_train: 0.0123\n",
      "Epoch 2/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.7738 - metric_choose_argument_global_sq_y_train: 0.0212\n",
      "Epoch 2: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 54s 17ms/step - loss: -0.7738 - metric_choose_argument_global_sq_y_train: 0.0212 - val_loss: -0.7676 - val_metric_choose_argument_global_sq_y_train: 0.0234\n",
      "Epoch 3/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.7911 - metric_choose_argument_global_sq_y_train: 0.0437\n",
      "Epoch 3: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.7911 - metric_choose_argument_global_sq_y_train: 0.0437 - val_loss: -0.7740 - val_metric_choose_argument_global_sq_y_train: 0.0320\n",
      "Epoch 4/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8042 - metric_choose_argument_global_sq_y_train: 0.0732\n",
      "Epoch 4: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 55s 17ms/step - loss: -0.8042 - metric_choose_argument_global_sq_y_train: 0.0732 - val_loss: -0.7750 - val_metric_choose_argument_global_sq_y_train: 0.0332\n",
      "Epoch 5/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8142 - metric_choose_argument_global_sq_y_train: 0.1230\n",
      "Epoch 5: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 50s 16ms/step - loss: -0.8142 - metric_choose_argument_global_sq_y_train: 0.1230 - val_loss: -0.7755 - val_metric_choose_argument_global_sq_y_train: 0.0394\n",
      "Epoch 6/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8225 - metric_choose_argument_global_sq_y_train: 0.1578\n",
      "Epoch 6: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 49s 15ms/step - loss: -0.8225 - metric_choose_argument_global_sq_y_train: 0.1577 - val_loss: -0.7725 - val_metric_choose_argument_global_sq_y_train: 0.0455\n",
      "Epoch 7/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8291 - metric_choose_argument_global_sq_y_train: 0.2276\n",
      "Epoch 7: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8291 - metric_choose_argument_global_sq_y_train: 0.2276 - val_loss: -0.7719 - val_metric_choose_argument_global_sq_y_train: 0.0492\n",
      "Epoch 8/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8346 - metric_choose_argument_global_sq_y_train: 0.2762\n",
      "Epoch 8: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 52s 16ms/step - loss: -0.8346 - metric_choose_argument_global_sq_y_train: 0.2761 - val_loss: -0.7694 - val_metric_choose_argument_global_sq_y_train: 0.0529\n",
      "Epoch 9/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8395 - metric_choose_argument_global_sq_y_train: 0.3270\n",
      "Epoch 9: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 56s 17ms/step - loss: -0.8395 - metric_choose_argument_global_sq_y_train: 0.3272 - val_loss: -0.7665 - val_metric_choose_argument_global_sq_y_train: 0.0541\n",
      "Epoch 10/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8436 - metric_choose_argument_global_sq_y_train: 0.3914\n",
      "Epoch 10: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 60s 19ms/step - loss: -0.8436 - metric_choose_argument_global_sq_y_train: 0.3915 - val_loss: -0.7634 - val_metric_choose_argument_global_sq_y_train: 0.0394\n",
      "Epoch 11/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8471 - metric_choose_argument_global_sq_y_train: 0.4266\n",
      "Epoch 11: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 59s 18ms/step - loss: -0.8471 - metric_choose_argument_global_sq_y_train: 0.4265 - val_loss: -0.7613 - val_metric_choose_argument_global_sq_y_train: 0.0455\n",
      "Epoch 12/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8501 - metric_choose_argument_global_sq_y_train: 0.4751\n",
      "Epoch 12: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 58s 18ms/step - loss: -0.8501 - metric_choose_argument_global_sq_y_train: 0.4751 - val_loss: -0.7596 - val_metric_choose_argument_global_sq_y_train: 0.0541\n",
      "Epoch 13/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8525 - metric_choose_argument_global_sq_y_train: 0.5108\n",
      "Epoch 13: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8525 - metric_choose_argument_global_sq_y_train: 0.5105 - val_loss: -0.7583 - val_metric_choose_argument_global_sq_y_train: 0.0467\n",
      "Epoch 14/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8551 - metric_choose_argument_global_sq_y_train: 0.5409\n",
      "Epoch 14: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 57s 18ms/step - loss: -0.8551 - metric_choose_argument_global_sq_y_train: 0.5409 - val_loss: -0.7564 - val_metric_choose_argument_global_sq_y_train: 0.0517\n",
      "Epoch 15/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8571 - metric_choose_argument_global_sq_y_train: 0.5603\n",
      "Epoch 15: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 60s 18ms/step - loss: -0.8571 - metric_choose_argument_global_sq_y_train: 0.5603 - val_loss: -0.7544 - val_metric_choose_argument_global_sq_y_train: 0.0517\n",
      "Epoch 16/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8590 - metric_choose_argument_global_sq_y_train: 0.5916\n",
      "Epoch 16: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 57s 17ms/step - loss: -0.8590 - metric_choose_argument_global_sq_y_train: 0.5916 - val_loss: -0.7534 - val_metric_choose_argument_global_sq_y_train: 0.0467\n",
      "Epoch 17/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8607 - metric_choose_argument_global_sq_y_train: 0.6063\n",
      "Epoch 17: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 62s 19ms/step - loss: -0.8607 - metric_choose_argument_global_sq_y_train: 0.6061 - val_loss: -0.7504 - val_metric_choose_argument_global_sq_y_train: 0.0455\n",
      "Epoch 18/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8622 - metric_choose_argument_global_sq_y_train: 0.6275\n",
      "Epoch 18: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 48s 15ms/step - loss: -0.8622 - metric_choose_argument_global_sq_y_train: 0.6276 - val_loss: -0.7501 - val_metric_choose_argument_global_sq_y_train: 0.0492\n",
      "Epoch 19/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8637 - metric_choose_argument_global_sq_y_train: 0.6376\n",
      "Epoch 19: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8637 - metric_choose_argument_global_sq_y_train: 0.6378 - val_loss: -0.7494 - val_metric_choose_argument_global_sq_y_train: 0.0504\n",
      "Epoch 20/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8650 - metric_choose_argument_global_sq_y_train: 0.6534\n",
      "Epoch 20: saving model to nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8650 - metric_choose_argument_global_sq_y_train: 0.6531 - val_loss: -0.7464 - val_metric_choose_argument_global_sq_y_train: 0.0480\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_sq_autoencoder_shuffled_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_sq_training_shuffled_log.csv', separator=',', append=True)\n",
    "\n",
    "global_sq_history = global_sq_autoencoder_model.fit(\n",
    "    x=global_sq_x_train,\n",
    "    y=global_sq_y_train_shuffled,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_sq_x_test, global_sq_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6928ced1-9826-435e-946d-427e8da83e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sq_autoencoder_model.save('nomic_autoencoder/global_sq_autoencoder_shuffled_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d77dce7e-101b-4307-81d3-8e9e1f9e1bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.7750 - metric_choose_argument_global_clu_y_train: 0.0120\n",
      "Epoch 1: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 57s 17ms/step - loss: -0.7750 - metric_choose_argument_global_clu_y_train: 0.0120 - val_loss: -0.7894 - val_metric_choose_argument_global_clu_y_train: 0.0320\n",
      "Epoch 2/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8100 - metric_choose_argument_global_clu_y_train: 0.0265\n",
      "Epoch 2: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 52s 16ms/step - loss: -0.8099 - metric_choose_argument_global_clu_y_train: 0.0264 - val_loss: -0.8030 - val_metric_choose_argument_global_clu_y_train: 0.0443\n",
      "Epoch 3/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8252 - metric_choose_argument_global_clu_y_train: 0.0498\n",
      "Epoch 3: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 56s 17ms/step - loss: -0.8252 - metric_choose_argument_global_clu_y_train: 0.0498 - val_loss: -0.8085 - val_metric_choose_argument_global_clu_y_train: 0.0529\n",
      "Epoch 4/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8358 - metric_choose_argument_global_clu_y_train: 0.0732\n",
      "Epoch 4: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 59s 18ms/step - loss: -0.8358 - metric_choose_argument_global_clu_y_train: 0.0732 - val_loss: -0.8102 - val_metric_choose_argument_global_clu_y_train: 0.0615\n",
      "Epoch 5/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8439 - metric_choose_argument_global_clu_y_train: 0.1009\n",
      "Epoch 5: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 47s 14ms/step - loss: -0.8439 - metric_choose_argument_global_clu_y_train: 0.1012 - val_loss: -0.8101 - val_metric_choose_argument_global_clu_y_train: 0.0627\n",
      "Epoch 6/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8507 - metric_choose_argument_global_clu_y_train: 0.1370\n",
      "Epoch 6: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 44s 13ms/step - loss: -0.8507 - metric_choose_argument_global_clu_y_train: 0.1368 - val_loss: -0.8090 - val_metric_choose_argument_global_clu_y_train: 0.0590\n",
      "Epoch 7/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8561 - metric_choose_argument_global_clu_y_train: 0.1800\n",
      "Epoch 7: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8561 - metric_choose_argument_global_clu_y_train: 0.1805 - val_loss: -0.8075 - val_metric_choose_argument_global_clu_y_train: 0.0664\n",
      "Epoch 8/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8610 - metric_choose_argument_global_clu_y_train: 0.2289\n",
      "Epoch 8: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8609 - metric_choose_argument_global_clu_y_train: 0.2288 - val_loss: -0.8076 - val_metric_choose_argument_global_clu_y_train: 0.0664\n",
      "Epoch 9/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8648 - metric_choose_argument_global_clu_y_train: 0.2795\n",
      "Epoch 9: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.8648 - metric_choose_argument_global_clu_y_train: 0.2795 - val_loss: -0.8028 - val_metric_choose_argument_global_clu_y_train: 0.0763\n",
      "Epoch 10/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8685 - metric_choose_argument_global_clu_y_train: 0.3359\n",
      "Epoch 10: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.8685 - metric_choose_argument_global_clu_y_train: 0.3355 - val_loss: -0.8004 - val_metric_choose_argument_global_clu_y_train: 0.0590\n",
      "Epoch 11/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8712 - metric_choose_argument_global_clu_y_train: 0.3687\n",
      "Epoch 11: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 41s 13ms/step - loss: -0.8712 - metric_choose_argument_global_clu_y_train: 0.3687 - val_loss: -0.7989 - val_metric_choose_argument_global_clu_y_train: 0.0627\n",
      "Epoch 12/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8740 - metric_choose_argument_global_clu_y_train: 0.4099\n",
      "Epoch 12: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 49s 15ms/step - loss: -0.8740 - metric_choose_argument_global_clu_y_train: 0.4099 - val_loss: -0.7975 - val_metric_choose_argument_global_clu_y_train: 0.0763\n",
      "Epoch 13/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8765 - metric_choose_argument_global_clu_y_train: 0.4440\n",
      "Epoch 13: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 51s 16ms/step - loss: -0.8764 - metric_choose_argument_global_clu_y_train: 0.4437 - val_loss: -0.7943 - val_metric_choose_argument_global_clu_y_train: 0.0677\n",
      "Epoch 14/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8785 - metric_choose_argument_global_clu_y_train: 0.4757\n",
      "Epoch 14: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8785 - metric_choose_argument_global_clu_y_train: 0.4757 - val_loss: -0.7918 - val_metric_choose_argument_global_clu_y_train: 0.0677\n",
      "Epoch 15/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8805 - metric_choose_argument_global_clu_y_train: 0.5126\n",
      "Epoch 15: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8805 - metric_choose_argument_global_clu_y_train: 0.5126 - val_loss: -0.7907 - val_metric_choose_argument_global_clu_y_train: 0.0677\n",
      "Epoch 16/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8821 - metric_choose_argument_global_clu_y_train: 0.5419\n",
      "Epoch 16: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 40s 12ms/step - loss: -0.8821 - metric_choose_argument_global_clu_y_train: 0.5415 - val_loss: -0.7894 - val_metric_choose_argument_global_clu_y_train: 0.0701\n",
      "Epoch 17/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8837 - metric_choose_argument_global_clu_y_train: 0.5623\n",
      "Epoch 17: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 42s 13ms/step - loss: -0.8837 - metric_choose_argument_global_clu_y_train: 0.5621 - val_loss: -0.7869 - val_metric_choose_argument_global_clu_y_train: 0.0640\n",
      "Epoch 18/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8853 - metric_choose_argument_global_clu_y_train: 0.5867\n",
      "Epoch 18: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 43s 13ms/step - loss: -0.8853 - metric_choose_argument_global_clu_y_train: 0.5867 - val_loss: -0.7868 - val_metric_choose_argument_global_clu_y_train: 0.0652\n",
      "Epoch 19/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8866 - metric_choose_argument_global_clu_y_train: 0.5898\n",
      "Epoch 19: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 42s 13ms/step - loss: -0.8866 - metric_choose_argument_global_clu_y_train: 0.5898 - val_loss: -0.7848 - val_metric_choose_argument_global_clu_y_train: 0.0689\n",
      "Epoch 20/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8878 - metric_choose_argument_global_clu_y_train: 0.6189\n",
      "Epoch 20: saving model to nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 44s 14ms/step - loss: -0.8878 - metric_choose_argument_global_clu_y_train: 0.6190 - val_loss: -0.7858 - val_metric_choose_argument_global_clu_y_train: 0.0713\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_clu_autoencoder_shuffled_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_clu_training_shuffled_log.csv', separator=',', append=True)\n",
    "\n",
    "global_clu_history = global_clu_autoencoder_model.fit(\n",
    "    x=global_clu_x_train,\n",
    "    y=global_clu_y_train_shuffled,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_clu_x_test, global_clu_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68fcfd03-4535-4a6e-bef8-8e555c5f5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_clu_autoencoder_model.save('nomic_autoencoder/global_clu_autoencoder_shuffled_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d19ab69-e058-4825-b69f-add288862d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.7663 - metric_choose_argument_global_cla_y_train: 0.0077\n",
      "Epoch 1: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 48s 14ms/step - loss: -0.7663 - metric_choose_argument_global_cla_y_train: 0.0080 - val_loss: -0.7826 - val_metric_choose_argument_global_cla_y_train: 0.0271\n",
      "Epoch 2/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.7995 - metric_choose_argument_global_cla_y_train: 0.0194\n",
      "Epoch 2: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 51s 16ms/step - loss: -0.7995 - metric_choose_argument_global_cla_y_train: 0.0194 - val_loss: -0.7980 - val_metric_choose_argument_global_cla_y_train: 0.0221\n",
      "Epoch 3/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8145 - metric_choose_argument_global_cla_y_train: 0.0320\n",
      "Epoch 3: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 52s 16ms/step - loss: -0.8145 - metric_choose_argument_global_cla_y_train: 0.0320 - val_loss: -0.8017 - val_metric_choose_argument_global_cla_y_train: 0.0467\n",
      "Epoch 4/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8249 - metric_choose_argument_global_cla_y_train: 0.0557\n",
      "Epoch 4: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 53s 16ms/step - loss: -0.8250 - metric_choose_argument_global_cla_y_train: 0.0557 - val_loss: -0.8038 - val_metric_choose_argument_global_cla_y_train: 0.0369\n",
      "Epoch 5/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8337 - metric_choose_argument_global_cla_y_train: 0.0825\n",
      "Epoch 5: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 37s 12ms/step - loss: -0.8337 - metric_choose_argument_global_cla_y_train: 0.0824 - val_loss: -0.8029 - val_metric_choose_argument_global_cla_y_train: 0.0431\n",
      "Epoch 6/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8403 - metric_choose_argument_global_cla_y_train: 0.1182\n",
      "Epoch 6: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8403 - metric_choose_argument_global_cla_y_train: 0.1184 - val_loss: -0.8022 - val_metric_choose_argument_global_cla_y_train: 0.0504\n",
      "Epoch 7/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8462 - metric_choose_argument_global_cla_y_train: 0.1606\n",
      "Epoch 7: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8462 - metric_choose_argument_global_cla_y_train: 0.1605 - val_loss: -0.8013 - val_metric_choose_argument_global_cla_y_train: 0.0517\n",
      "Epoch 8/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8512 - metric_choose_argument_global_cla_y_train: 0.1967\n",
      "Epoch 8: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8512 - metric_choose_argument_global_cla_y_train: 0.1968 - val_loss: -0.7994 - val_metric_choose_argument_global_cla_y_train: 0.0615\n",
      "Epoch 9/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8556 - metric_choose_argument_global_cla_y_train: 0.2483\n",
      "Epoch 9: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8555 - metric_choose_argument_global_cla_y_train: 0.2482 - val_loss: -0.7966 - val_metric_choose_argument_global_cla_y_train: 0.0590\n",
      "Epoch 10/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8592 - metric_choose_argument_global_cla_y_train: 0.2926\n",
      "Epoch 10: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8592 - metric_choose_argument_global_cla_y_train: 0.2927 - val_loss: -0.7942 - val_metric_choose_argument_global_cla_y_train: 0.0615\n",
      "Epoch 11/20\n",
      "3250/3252 [============================>.] - ETA: 0s - loss: -0.8627 - metric_choose_argument_global_cla_y_train: 0.3375\n",
      "Epoch 11: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8627 - metric_choose_argument_global_cla_y_train: 0.3373 - val_loss: -0.7911 - val_metric_choose_argument_global_cla_y_train: 0.0689\n",
      "Epoch 12/20\n",
      "3249/3252 [============================>.] - ETA: 0s - loss: -0.8655 - metric_choose_argument_global_cla_y_train: 0.3783\n",
      "Epoch 12: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8655 - metric_choose_argument_global_cla_y_train: 0.3782 - val_loss: -0.7883 - val_metric_choose_argument_global_cla_y_train: 0.0615\n",
      "Epoch 13/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8682 - metric_choose_argument_global_cla_y_train: 0.4223\n",
      "Epoch 13: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 37s 11ms/step - loss: -0.8681 - metric_choose_argument_global_cla_y_train: 0.4222 - val_loss: -0.7882 - val_metric_choose_argument_global_cla_y_train: 0.0701\n",
      "Epoch 14/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8706 - metric_choose_argument_global_cla_y_train: 0.4661\n",
      "Epoch 14: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 38s 12ms/step - loss: -0.8706 - metric_choose_argument_global_cla_y_train: 0.4659 - val_loss: -0.7848 - val_metric_choose_argument_global_cla_y_train: 0.0701\n",
      "Epoch 15/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8726 - metric_choose_argument_global_cla_y_train: 0.4905\n",
      "Epoch 15: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 43s 13ms/step - loss: -0.8726 - metric_choose_argument_global_cla_y_train: 0.4905 - val_loss: -0.7833 - val_metric_choose_argument_global_cla_y_train: 0.0590\n",
      "Epoch 16/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8744 - metric_choose_argument_global_cla_y_train: 0.5260\n",
      "Epoch 16: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 43s 13ms/step - loss: -0.8744 - metric_choose_argument_global_cla_y_train: 0.5261 - val_loss: -0.7809 - val_metric_choose_argument_global_cla_y_train: 0.0738\n",
      "Epoch 17/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8761 - metric_choose_argument_global_cla_y_train: 0.5454\n",
      "Epoch 17: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 51s 16ms/step - loss: -0.8761 - metric_choose_argument_global_cla_y_train: 0.5455 - val_loss: -0.7790 - val_metric_choose_argument_global_cla_y_train: 0.0689\n",
      "Epoch 18/20\n",
      "3251/3252 [============================>.] - ETA: 0s - loss: -0.8778 - metric_choose_argument_global_cla_y_train: 0.5626\n",
      "Epoch 18: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 44s 13ms/step - loss: -0.8778 - metric_choose_argument_global_cla_y_train: 0.5624 - val_loss: -0.7784 - val_metric_choose_argument_global_cla_y_train: 0.0627\n",
      "Epoch 19/20\n",
      "3248/3252 [============================>.] - ETA: 0s - loss: -0.8792 - metric_choose_argument_global_cla_y_train: 0.5933\n",
      "Epoch 19: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 47s 14ms/step - loss: -0.8792 - metric_choose_argument_global_cla_y_train: 0.5935 - val_loss: -0.7757 - val_metric_choose_argument_global_cla_y_train: 0.0713\n",
      "Epoch 20/20\n",
      "3252/3252 [==============================] - ETA: 0s - loss: -0.8805 - metric_choose_argument_global_cla_y_train: 0.6095\n",
      "Epoch 20: saving model to nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras\n",
      "3252/3252 [==============================] - 39s 12ms/step - loss: -0.8805 - metric_choose_argument_global_cla_y_train: 0.6095 - val_loss: -0.7762 - val_metric_choose_argument_global_cla_y_train: 0.0627\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='nomic_autoencoder/global_cla_autoencoder_shuffled_weights.keras', save_best_only=False, save_weights_only=False, verbose=1)\n",
    "csv_logger_callback = CSVLogger(filename='nomic_autoencoder/global_cla_training_shuffled_log.csv', separator=',', append=True)\n",
    "\n",
    "global_cla_history = global_cla_autoencoder_model.fit(\n",
    "    x=global_cla_x_train,\n",
    "    y=global_cla_y_train_shuffled,\n",
    "    batch_size=1,\n",
    "    epochs=20,\n",
    "    validation_data = (global_cla_x_test, global_cla_y_test),\n",
    "    callbacks=[checkpoint_callback, csv_logger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "331f1ff0-503b-4cf5-831c-6a98b8446327",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cla_autoencoder_model.save('nomic_autoencoder/global_cla_autoencoder_shuffled_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a0634-f5ad-4350-b636-b7c81e41d53c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "271e3a92-e121-42da-936f-50b024f795e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_global_shuffled_history = pd.read_csv(\"./global_training_shuffled_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fc6ee9fc-85d5-46c9-b348-fad8988b540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_global_shuffled_history = loaded_global_shuffled_history.loc[0:19]\n",
    "loaded_global_shuffled_history = pd.melt(loaded_global_shuffled_history, id_vars='epoch', value_vars=['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], var_name='dataset', value_name='accuracy')\n",
    "loaded_global_shuffled_history = loaded_global_shuffled_history.replace(['metric_choose_argument_global_y_train', 'val_metric_choose_argument_global_y_train'], ['training set', 'validation set'])\n",
    "loaded_global_shuffled_history['shuffled'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "04685606-1a9e-4a98-86bf-f8423ebb4a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>shuffled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.035363</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.073801</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.108549</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.154367</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.217405</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.273063</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.338561</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.405904</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.464945</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.507688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.539053</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.577798</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.591636</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.622694</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.646986</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.649754</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.671894</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.056581</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.067651</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.067651</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.071341</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.084871</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.077491</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.070111</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.075031</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.063961</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.067651</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.071341</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.073801</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.062731</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch         dataset  accuracy  shuffled\n",
       "0       0    training set  0.012608      True\n",
       "1       1    training set  0.035363      True\n",
       "2       2    training set  0.048893      True\n",
       "3       3    training set  0.073801      True\n",
       "4       4    training set  0.108549      True\n",
       "5       5    training set  0.154367      True\n",
       "6       6    training set  0.217405      True\n",
       "7       7    training set  0.273063      True\n",
       "8       8    training set  0.338561      True\n",
       "9       9    training set  0.405904      True\n",
       "10     10    training set  0.464945      True\n",
       "11     11    training set  0.507688      True\n",
       "12     12    training set  0.539053      True\n",
       "13     13    training set  0.577798      True\n",
       "14     14    training set  0.591636      True\n",
       "15     15    training set  0.622694      True\n",
       "16     16    training set  0.646986      True\n",
       "17     17    training set  0.649754      True\n",
       "18     18    training set  0.671894      True\n",
       "19     19    training set  0.680197      True\n",
       "20      0  validation set  0.033210      True\n",
       "21      1  validation set  0.056581      True\n",
       "22      2  validation set  0.067651      True\n",
       "23      3  validation set  0.067651      True\n",
       "24      4  validation set  0.072571      True\n",
       "25      5  validation set  0.072571      True\n",
       "26      6  validation set  0.071341      True\n",
       "27      7  validation set  0.084871      True\n",
       "28      8  validation set  0.077491      True\n",
       "29      9  validation set  0.070111      True\n",
       "30     10  validation set  0.075031      True\n",
       "31     11  validation set  0.072571      True\n",
       "32     12  validation set  0.063961      True\n",
       "33     13  validation set  0.066421      True\n",
       "34     14  validation set  0.067651      True\n",
       "35     15  validation set  0.071341      True\n",
       "36     16  validation set  0.073801      True\n",
       "37     17  validation set  0.066421      True\n",
       "38     18  validation set  0.066421      True\n",
       "39     19  validation set  0.062731      True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_global_shuffled_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e41c22f3-717f-451e-b65d-89a4283b55c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/usr/local/lib/python3.11/site-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: ../data_dump/training_plots_dump/global_shuffled_training_plot.png\n"
     ]
    }
   ],
   "source": [
    "global_training_shuffled_plot = ggplot(loaded_global_shuffled_history, aes(x='epoch', y='accuracy', linetype='dataset')) + geom_line() + labs(title='Learning Curve of Model Trained on Within-Topic Shuffled Data', x='Epoch', y='Accuracy')\n",
    "ggsave(global_training_shuffled_plot, \"../data_dump/training_plots_dump/global_shuffled_training_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c645786f-b40b-4973-b164-90b0e0df519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>shuffled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.124231</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.200800</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.281058</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>training set</td>\n",
       "      <td>0.382226</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.071341</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.073801</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>17</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19</td>\n",
       "      <td>validation set</td>\n",
       "      <td>0.062731</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch         dataset  accuracy  shuffled\n",
       "0       0    training set  0.040283     False\n",
       "1       1    training set  0.124231     False\n",
       "2       2    training set  0.200800     False\n",
       "3       3    training set  0.281058     False\n",
       "4       4    training set  0.382226     False\n",
       "..    ...             ...       ...       ...\n",
       "35     15  validation set  0.071341      True\n",
       "36     16  validation set  0.073801      True\n",
       "37     17  validation set  0.066421      True\n",
       "38     18  validation set  0.066421      True\n",
       "39     19  validation set  0.062731      True\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_global_training_df = pd.concat([loaded_global_history, loaded_global_shuffled_history])\n",
    "combined_global_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b8bea898-c3f5-475f-a304-91911ec6dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/plotnine/ggplot.py:587: PlotnineWarning: Saving 16 x 24 in image.\n",
      "/usr/local/lib/python3.11/site-packages/plotnine/ggplot.py:588: PlotnineWarning: Filename: ../data_dump/training_plots_dump/combined_global_training_plot.png\n"
     ]
    }
   ],
   "source": [
    "combined_global_plot = (\n",
    "    ggplot(combined_global_training_df, aes(x='epoch', y='accuracy', linetype='dataset', color='shuffled')) +\n",
    "    geom_line(size=2) +\n",
    "    labs(title='Learning Curve of Model Trained on Unshuffled vs. Within-Topic Shuffled Data', x='Epoch', y='Accuracy') +\n",
    "    theme(\n",
    "        figure_size=(16,24),\n",
    "        axis_title=element_text(size=32),\n",
    "        axis_text=element_text(size=24),\n",
    "        legend_title=element_text(size=32, lineheight=1.5),\n",
    "        legend_text=element_text(size=24, lineheight=1.5),\n",
    "        plot_title=element_text(size=40, wrap=True, lineheight=1.5),\n",
    "        legend_position=\"bottom\",\n",
    "        legend_key_width=64\n",
    "    ) +\n",
    "    guides(fill = guide_legend(byrow = True))\n",
    ")\n",
    "ggsave(combined_global_plot, \"../data_dump/training_plots_dump/combined_global_training_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
