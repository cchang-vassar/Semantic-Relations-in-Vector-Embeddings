{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study6_nomic_autoencoder_choose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ec119b-3682-48e1-80a4-d50af48ee755",
      "metadata": {
        "id": "c8ec119b-3682-48e1-80a4-d50af48ee755"
      },
      "source": [
        "# [nomic] Autoencoder: Choose Corresponding Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d6be4b-ee66-48b6-b449-cfe1abf83dff",
      "metadata": {
        "id": "c9d6be4b-ee66-48b6-b449-cfe1abf83dff"
      },
      "source": [
        "Given an embedding, can a model be trained to choose the correct embeddings corresponding to its counterargument from a list of them?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "rraCIAGnMU04"
      },
      "id": "rraCIAGnMU04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "x6lP1bVYImnN"
      },
      "id": "x6lP1bVYImnN"
    },
    {
      "cell_type": "code",
      "source": [
        "# General imports\n",
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from google.colab import userdata\n",
        "import pickle\n",
        "import statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from scipy import spatial\n",
        "from tenacity import (\n",
        "  retry,\n",
        "  stop_after_attempt,\n",
        "  wait_random_exponential\n",
        ")"
      ],
      "metadata": {
        "id": "uG3AaiqUInby"
      },
      "id": "uG3AaiqUInby",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3d414a7-b583-49f1-87a3-cc4ccf9af314"
      },
      "source": [
        "### Nomic Setup"
      ],
      "id": "b3d414a7-b583-49f1-87a3-cc4ccf9af314"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66e54b84-2cd3-462a-b38d-b2b3d418eb22",
        "outputId": "4cf8a8ca-59de-4992-ae3f-c6e79e18237d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nomic in /usr/local/lib/python3.10/dist-packages (3.0.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nomic) (8.1.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from nomic) (4.0.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from nomic) (0.7.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from nomic) (13.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nomic) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nomic) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nomic) (1.5.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from nomic) (2.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nomic) (4.66.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from nomic) (14.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from nomic) (9.4.0)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from nomic) (2.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->nomic) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->nomic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->nomic) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->nomic) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nomic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nomic) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nomic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nomic) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->nomic) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->nomic) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nomic"
      ],
      "id": "66e54b84-2cd3-462a-b38d-b2b3d418eb22"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "AMznQiaLfOQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02c145d-58b4-4733-fb32-3598dcc9bf0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m112.6/156.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m923.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.5.1\n"
          ]
        }
      ],
      "id": "AMznQiaLfOQ9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "1y_GWDUBg98F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87ce577-e4c3-444c-ad71-b92a3f603905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ],
      "id": "1y_GWDUBg98F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98c8f10b-60c2-4170-8c60-eb59e0e5a4d1"
      },
      "outputs": [],
      "source": [
        "import nomic\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "id": "98c8f10b-60c2-4170-8c60-eb59e0e5a4d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS_fc5dDySK5",
        "outputId": "95377ff7-dbb0-4988-ef97-da2182ec3c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Corpora Data"
      ],
      "metadata": {
        "id": "4TgJ2Ob4MFbl"
      },
      "id": "4TgJ2Ob4MFbl"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/corpora/gpr_corpus.zip\", shell=True)\n",
        "print(\"gpr_corpus.zip successfully imported\")\n",
        "gpr_corpus_file_path_zip = 'gpr_corpus.zip'\n",
        "gpr_corpus_file_path = 'corpora/gpr-corpus'\n",
        "with zipfile.ZipFile(gpr_corpus_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(gpr_corpus_file_path)\n",
        "extracted_files = os.listdir(gpr_corpus_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxFLKKkTNvR-",
        "outputId": "9c0514ad-f1a5-47b0-de3a-b9feb89b40af"
      },
      "id": "SxFLKKkTNvR-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpr_corpus.zip successfully imported\n",
            "Files extracted: ['gpr_corpus', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/corpora/eacl_corpus.zip\", shell=True)\n",
        "print(\"eacl_corpus.zip successfully imported\")\n",
        "eacl_corpus_file_path_zip = 'eacl_corpus.zip'\n",
        "eacl_corpus_file_path = 'corpora/eacl-corpus'\n",
        "with zipfile.ZipFile(eacl_corpus_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(eacl_corpus_file_path)\n",
        "extracted_files = os.listdir(eacl_corpus_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEdfwyRaMHNN",
        "outputId": "48a56274-b8c5-4f2d-8f00-3381e1870a2a"
      },
      "id": "EEdfwyRaMHNN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eacl_corpus.zip successfully imported\n",
            "Files extracted: ['eacl_corpus', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77496b2-c993-4be3-b1bb-eca04e33cf3c",
      "metadata": {
        "id": "d77496b2-c993-4be3-b1bb-eca04e33cf3c"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7848602-f4e3-4d65-8833-d33c230a953f",
      "metadata": {
        "id": "b7848602-f4e3-4d65-8833-d33c230a953f"
      },
      "source": [
        "### GPR 55"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f69ad0b-d78e-4ddd-8117-ce316aed90a9",
      "metadata": {
        "id": "6f69ad0b-d78e-4ddd-8117-ce316aed90a9"
      },
      "outputs": [],
      "source": [
        "gpr_df = pd.read_csv(\"corpora/gpr-corpus/gpr_corpus/GPR-KB-55/GPR-KB-55.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DIM_EMBEDDING = 768\n",
        "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1\", trust_remote_code=True)\n",
        "\n",
        "def gpr_get_embeddings(gpr_df: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Add embeddings column to a df\"\"\"\n",
        "  arguments_list = list(gpr_df['argument'])\n",
        "\n",
        "  clustering_embeddings = model.encode(['clustering: ' + argument for argument in arguments_list])\n",
        "  clustering_df = pd.DataFrame(clustering_embeddings, columns=[f\"clustering_{str(i)}\" for i in range(DIM_EMBEDDING)])\n",
        "  embeddings_clu_df = pd.concat([gpr_df, clustering_df], axis=1)\n",
        "\n",
        "  return embeddings_clu_df"
      ],
      "metadata": {
        "id": "AV6yXQ3ed4lj"
      },
      "id": "AV6yXQ3ed4lj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199a733b-f251-496e-9b2b-73222c703857",
      "metadata": {
        "id": "199a733b-f251-496e-9b2b-73222c703857"
      },
      "outputs": [],
      "source": [
        "gpr_claims_df = gpr_get_embeddings_df(gpr_df['claim'])\n",
        "gpr_rebuttals_df = gpr_get_embeddings_df(gpr_df['rebuttal'])\n",
        "gpr_x_test = gpr_claims_df.select_dtypes(include=[np.number])\n",
        "gpr_y_test = gpr_rebuttals_df.select_dtypes(include=[np.number])\n",
        "gpr_combined = pd.concat([gpr_claims_df, gpr_rebuttals_df])\n",
        "gpr_combined = gpr_combined.reset_index(drop=True)\n",
        "gpr_combined_nums = gpr_combined.select_dtypes(include=[np.number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0682cdf-9b24-4f96-9bce-0dfb06cd0cec",
      "metadata": {
        "id": "d0682cdf-9b24-4f96-9bce-0dfb06cd0cec"
      },
      "outputs": [],
      "source": [
        "def metric_choose_argument_gpr(y_true, y_pred):\n",
        "  \"\"\"See if the output vector is closest to the rebuttal to the claim\"\"\"\n",
        "  gpr_training_df_32 = tf.cast(gpr_combined_nums, dtype=tf.float32)\n",
        "  gpr_norm = tf.norm(gpr_training_df_32, axis=1)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(gpr_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * gpr_norm, [-1, 1])\n",
        "  cos_sim_true = tf.matmul(gpr_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * gpr_norm, [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4fce8f5-b7ad-4898-88e2-205c885875d8",
      "metadata": {
        "id": "f4fce8f5-b7ad-4898-88e2-205c885875d8"
      },
      "source": [
        "### EACL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b0767d-3428-49db-bce1-5f26dccda2e6",
      "metadata": {
        "scrolled": true,
        "id": "43b0767d-3428-49db-bce1-5f26dccda2e6"
      },
      "outputs": [],
      "source": [
        "eacl_df = pd.read_csv(\"corpora/eacl-corpus/eacl_corpus/claim_stance_dataset.csv\")\n",
        "eacl_df = eacl_df[['topicId', 'topicText', 'claims.stance', 'claims.claimCorrectedText']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bd479fd-e5db-4348-b4ae-8cf77b7cc345",
      "metadata": {
        "id": "5bd479fd-e5db-4348-b4ae-8cf77b7cc345"
      },
      "outputs": [],
      "source": [
        "topic_lens = []\n",
        "pro_lens = []\n",
        "con_lens = []\n",
        "for topic in eacl_df['topicId'].unique():\n",
        "  topic_rows = eacl_df[eacl_df['topicId'] == topic]\n",
        "  topic_lens.append(len(topic_rows))\n",
        "  pro_lens.append(len(topic_rows[topic_rows['claims.stance'] == \"PRO\"]))\n",
        "  con_lens.append(len(topic_rows[topic_rows['claims.stance'] == \"CON\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c20b12-93b4-497a-89aa-375667ee8bdd",
      "metadata": {
        "id": "c8c20b12-93b4-497a-89aa-375667ee8bdd"
      },
      "outputs": [],
      "source": [
        "DIM_EMBEDDING = 768\n",
        "\n",
        "\"\"\"Add embeddings column to a df\"\"\"\n",
        "  arguments_list = list(gpr_df['argument'])\n",
        "\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=60, max=500), stop=stop_after_attempt(10))\n",
        "def eacl_get_embeddings(arguments: list) -> list:\n",
        "  \"\"\"Convert an argument into a (1 x 768) embedding df\"\"\"\n",
        "  clustering_embeddings = model.encode(['clustering: ' + argument for argument in arguments_list])\n",
        "  clustering_df = pd.DataFrame(clustering_embeddings, columns=[f\"clustering_{str(i)}\" for i in range(DIM_EMBEDDING)])\n",
        "  embeddings_clu_df = pd.concat([gpr_df, clustering_df], axis=1)\n",
        "\n",
        "  return embeddings_clu_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0a1583-f638-43f0-8f60-1c2f5d1879e9",
      "metadata": {
        "id": "4c0a1583-f638-43f0-8f60-1c2f5d1879e9"
      },
      "outputs": [],
      "source": [
        "API_LIMIT = 1000\n",
        "\n",
        "def eacl_get_embeddings_df(eacl_df: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Add embeddings column to a df\"\"\"\n",
        "  embeddings_df = pd.DataFrame()\n",
        "  arguments_list = list(eacl_df['claims.claimCorrectedText'])\n",
        "  total_len = len(arguments_list)\n",
        "  i = 0\n",
        "\n",
        "  # Grab embeddings from arguments column in chunks\n",
        "  while i < total_len:\n",
        "    embeddings = eacl_get_embeddings(arguments_list[i:min(total_len, i+API_LIMIT)])\n",
        "    embeddings_df = pd.concat([embeddings_df, embeddings], axis=0, ignore_index=True)\n",
        "    i = i + API_LIMIT\n",
        "  arguments_embeddings_df = pd.concat([eacl_df, embeddings_df], axis=1)\n",
        "  return arguments_embeddings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87e8091-e303-4388-a899-fe6a4cdaa3bc",
      "metadata": {
        "scrolled": true,
        "id": "b87e8091-e303-4388-a899-fe6a4cdaa3bc"
      },
      "outputs": [],
      "source": [
        "eacl_embeddings_df = eacl_get_embeddings_df(eacl_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbab4309-efd9-4f13-a756-154d2e229ed5",
      "metadata": {
        "scrolled": true,
        "id": "bbab4309-efd9-4f13-a756-154d2e229ed5"
      },
      "outputs": [],
      "source": [
        "eacl_nums_df = eacl_embeddings_df.select_dtypes(include=[np.number])\n",
        "eacl_vectors_df = eacl_nums_df.drop('topicId', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder Model"
      ],
      "metadata": {
        "id": "-M6M0xNuLPVJ"
      },
      "id": "-M6M0xNuLPVJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import model from OSF"
      ],
      "metadata": {
        "id": "FcHGTBqldSm9"
      },
      "id": "FcHGTBqldSm9"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/nomic-autoencoder/nomic_autoencoder.zip\", shell=True)\n",
        "print(\"nomic_autoencoder.zip successfully imported\")\n",
        "nomic_autoencoder_file_path_zip = 'nomic_autoencoder.zip'\n",
        "nomic_autoencoder_file_path = 'current-data-dump/nomic-autoencoder'\n",
        "with zipfile.ZipFile(nomic_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(nomic_autoencoder_file_path)\n",
        "extracted_files = os.listdir(nomic_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aetiEHo9K2So",
        "outputId": "cf897881-3555-48f7-bd4e-b2d244bcfa2c"
      },
      "id": "aetiEHo9K2So",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_training_log.csv', 'global_training_plot.png', 'global_shuffled_autoencoder_model.keras', 'global_shuffled_training_log.csv', 'global_shuffled_training_plot.png', '.ipynb_checkpoints', 'global_training_df.pkl', 'combined_global_training_plot.png', 'global_autoencoder_model.keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_training_df = pd.read_pickle('current-data-dump/nomic-autoencoder/global_training_df.pkl')"
      ],
      "metadata": {
        "id": "Heh0bcdiLiqS"
      },
      "id": "Heh0bcdiLiqS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric"
      ],
      "metadata": {
        "id": "hQ9_lP8vJVjM"
      },
      "id": "hQ9_lP8vJVjM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53be282-1ddf-4bbe-af7a-412b8c685066",
      "metadata": {
        "id": "e53be282-1ddf-4bbe-af7a-412b8c685066"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  global_training_df_32 = tf.cast(global_training_df, dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e3a4568-5a9c-4652-a321-d89618146273",
      "metadata": {
        "id": "2e3a4568-5a9c-4652-a321-d89618146273"
      },
      "source": [
        "## Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c40f5f9-aeea-4e29-89d5-5b3f9a949638",
      "metadata": {
        "id": "3c40f5f9-aeea-4e29-89d5-5b3f9a949638"
      },
      "outputs": [],
      "source": [
        "global_autoencoder_model = tf.keras.models.load_model('current-data-dump/nomic-autoencoder/global_autoencoder_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a844caf-39c0-46ab-8611-cf22c919a932",
      "metadata": {
        "id": "7a844caf-39c0-46ab-8611-cf22c919a932"
      },
      "source": [
        "## GPR predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6557b3bb-29ad-4e6d-8a09-629d65c6b9dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6557b3bb-29ad-4e6d-8a09-629d65c6b9dd",
        "outputId": "c1c7ffbc-a40a-4af7-a2e8-4a83e45c737c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "global_autoencoder_gpr_predictions = global_autoencoder_model.predict(gpr_x_test)\n",
        "global_autoencoder_gpr_predictions_df = pd.DataFrame(global_autoencoder_gpr_predictions)\n",
        "global_autoencoder_gpr_predictions_df.columns = [str(i) for i in global_autoencoder_gpr_predictions_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482d775e-4e43-4632-b665-d64e5c9baf7b",
      "metadata": {
        "id": "482d775e-4e43-4632-b665-d64e5c9baf7b"
      },
      "outputs": [],
      "source": [
        "successes = 0\n",
        "for i in range(len(gpr_y_test)):\n",
        "  gpr_y_test_tf = tf.convert_to_tensor(gpr_y_test.loc[i], dtype=tf.float32)\n",
        "  gpr_pred_tf = tf.convert_to_tensor(global_autoencoder_gpr_predictions_df.loc[i], dtype=tf.float32)\n",
        "  gpr_y_test_tf = tf.reshape(gpr_y_test_tf, (1, -1))\n",
        "  gpr_pred_tf = tf.reshape(gpr_pred_tf, (1, -1))\n",
        "  if metric_choose_argument_gpr(gpr_y_test_tf, gpr_pred_tf).numpy() == 1:\n",
        "    successes += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a14c5b4-3954-4536-a2ea-d6f538690a33",
      "metadata": {
        "id": "7a14c5b4-3954-4536-a2ea-d6f538690a33"
      },
      "outputs": [],
      "source": [
        "gpr_success_rate = successes / len(gpr_y_test) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964b043e-166b-4cdb-8c90-6a7c3e9de543",
      "metadata": {
        "id": "964b043e-166b-4cdb-8c90-6a7c3e9de543"
      },
      "source": [
        "## EACL Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde0c9db-8665-4745-b223-b1a128a13992",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cde0c9db-8665-4745-b223-b1a128a13992",
        "outputId": "87b504a7-dcc5-4299-c716-4028446b88a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 1s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "global_autoencoder_eacl_predictions = global_autoencoder_model.predict(eacl_vectors_df)\n",
        "global_autoencoder_eacl_predictions_df = pd.DataFrame(global_autoencoder_eacl_predictions)\n",
        "global_autoencoder_eacl_predictions_df.columns = [str(i) for i in global_autoencoder_eacl_predictions_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eacl_topk = 10"
      ],
      "metadata": {
        "id": "TkOtj_qHZCyo"
      },
      "id": "TkOtj_qHZCyo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eacl_embeddings_df_32 = tf.cast(eacl_vectors_df, dtype=tf.float32)\n",
        "global_autoencoder_eacl_predictions_tf = tf.constant(global_autoencoder_eacl_predictions_df.values, dtype=tf.float32)\n",
        "pred_topk = []\n",
        "eacl_embeddings_norm = tf.norm(eacl_embeddings_df_32, axis=1)\n",
        "eacl_topics = list(eacl_embeddings_df['topicId'])\n",
        "eacl_stances = list(eacl_embeddings_df['claims.stance'])"
      ],
      "metadata": {
        "id": "NeDejiHcORtp"
      },
      "id": "NeDejiHcORtp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in enumerate(global_autoencoder_eacl_predictions_tf):\n",
        "  successes = 0\n",
        "  y_pred = tf.reshape(row, [1, -1])\n",
        "  target_topic = eacl_topics[i]\n",
        "  target_type = 'PRO' if eacl_stances[i] == 'CON' else 'CON'\n",
        "\n",
        "  cos_sim_pred = tf.matmul(eacl_embeddings_df_32, y_pred, transpose_b=True) / tf.reshape((tf.norm(y_pred) * eacl_embeddings_norm), [-1, 1])\n",
        "  top_k_sim_pred = tf.math.top_k(tf.reshape(cos_sim_pred, [-1]), k=eacl_topk).indices.numpy()\n",
        "\n",
        "  for index in top_k_sim_pred:\n",
        "    if eacl_topics[index] == target_topic and eacl_stances[index] == target_type:\n",
        "      successes += 1\n",
        "  pred_topk.append(successes / eacl_topk * 100)"
      ],
      "metadata": {
        "id": "r3cVyLKuVaNr"
      },
      "id": "r3cVyLKuVaNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d27c121-eb83-4c4c-b60e-417b52da304f",
      "metadata": {
        "id": "3d27c121-eb83-4c4c-b60e-417b52da304f"
      },
      "outputs": [],
      "source": [
        "eacl_topk_success_rate = statistics.mean(pred_topk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Values"
      ],
      "metadata": {
        "id": "rE4qFUefYJuQ"
      },
      "id": "rE4qFUefYJuQ"
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame(columns=['gpr_success_rate', 'eacl_topk_success_rate', 'eacl_topk'])\n",
        "result_df = result_df.append({'gpr_success_rate': gpr_success_rate, 'eacl_topk_success_rate': eacl_topk_success_rate, 'eacl_topk': eacl_topk}, ignore_index=True)\n",
        "results_folder_path = 'current-data-dump/nomic-autoencoder/nomic-autoencoder-predictions/'\n",
        "os.makedirs(results_folder_path, exist_ok=True)\n",
        "results_file_path = f'{results_folder_path}novel_corpora_prediction.pkl'\n",
        "with open(results_file_path, 'wb') as file:\n",
        "  pickle.dump(result_df, file)\n",
        "  print(f\"File uploaded to {results_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo8TBPUfYMKp",
        "outputId": "414fba3d-c8b1-49b8-fa5d-dfcbee71c64d"
      },
      "id": "uo8TBPUfYMKp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded to current_data_dump/ada_autoencoder_predictions/novel_corpora_prediction.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-148-36c7a7ffab45>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  result_df = result_df.append({'gpr_success_rate': gpr_success_rate, 'eacl_topk_success_rate': eacl_topk_success_rate, 'eacl_topk': eacl_topk}, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nomic_autoencoder_file_path = 'current-data-dump/nomic-autoencoder/nomic-autoencoder-predictions'\n",
        "result = subprocess.run([f\"osf -p sakjg upload -r --force {nomic_autoencoder_file_path}/ data-dump/nomic-autoencoder/nomic-autoencoder-predictions\"], shell=True, capture_output=True, text=True)\n",
        "print(result.stderr)\n",
        "print(f\"File: {nomic_autoencoder_file_path} uploaded at osfstorage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIxNg610aGyR",
        "outputId": "01bd2df1-7707-4f7b-ae1e-ddfa77b7b204"
      },
      "id": "jIxNg610aGyR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File: /content/current_data_dump/ada_autoencoder_predictions uploaded at osfstorage\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}