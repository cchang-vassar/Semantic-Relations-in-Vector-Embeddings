{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchang-vassar/Semantic-Relations-in-Vector-Embeddings/blob/main/study3_2_%5Bada003%5Dautoencoder_choose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ec119b-3682-48e1-80a4-d50af48ee755",
      "metadata": {
        "id": "c8ec119b-3682-48e1-80a4-d50af48ee755"
      },
      "source": [
        "# [ada-003] Autoencoder: Choose Corresponding Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d6be4b-ee66-48b6-b449-cfe1abf83dff",
      "metadata": {
        "id": "c9d6be4b-ee66-48b6-b449-cfe1abf83dff"
      },
      "source": [
        "Given an embedding, can a model be trained to choose the correct embeddings corresponding to its counterargument from a list of them?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "rraCIAGnMU04"
      },
      "id": "rraCIAGnMU04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "x6lP1bVYImnN"
      },
      "id": "x6lP1bVYImnN"
    },
    {
      "cell_type": "code",
      "source": [
        "# General imports\n",
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from google.colab import userdata\n",
        "import pickle\n",
        "import statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from scipy import spatial\n",
        "from tenacity import (\n",
        "  retry,\n",
        "  stop_after_attempt,\n",
        "  wait_random_exponential\n",
        ")"
      ],
      "metadata": {
        "id": "uG3AaiqUInby"
      },
      "id": "uG3AaiqUInby",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyZ99B-Wu1jI"
      },
      "source": [
        "### OpenAI Setup"
      ],
      "id": "yyZ99B-Wu1jI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks8hjOxWu1jJ",
        "outputId": "4e589434-a1bd-475d-fca3-704ce5942fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/312.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/312.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ],
      "id": "Ks8hjOxWu1jJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmWe4o7-u1jN"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "id": "VmWe4o7-u1jN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1iJAH9tu1jO"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()"
      ],
      "id": "c1iJAH9tu1jO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZL8xzRMyOGE"
      },
      "source": [
        "### OSF Setup"
      ],
      "id": "1ZL8xzRMyOGE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS_fc5dDySK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f92b84d-6c12-4194-dab4-6100e2b65a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting osfclient\n",
            "  Downloading osfclient-0.0.5-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from osfclient) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from osfclient) (4.66.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from osfclient) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->osfclient) (2024.2.2)\n",
            "Installing collected packages: osfclient\n",
            "Successfully installed osfclient-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install osfclient"
      ],
      "id": "fS_fc5dDySK5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7LsfY62TqsU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_USERNAME\"] = userdata.get(\"OSF_USERNAME\")\n",
        "OSF_USERNAME = os.environ[\"OSF_USERNAME\"]"
      ],
      "id": "q7LsfY62TqsU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc540GW4OGT5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PASSWORD\"] = userdata.get(\"OSF_PASSWORD\")\n",
        "OSF_PASSWORD = os.environ[\"OSF_PASSWORD\"]"
      ],
      "id": "Dc540GW4OGT5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-OVlX8Z0pZy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_TOKEN\"] = userdata.get(\"OSF_TOKEN\")\n",
        "OSF_TOKEN = os.environ[\"OSF_TOKEN\"]"
      ],
      "id": "z-OVlX8Z0pZy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTXKZf9r4RY3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OSF_PROJECT_ID\"] = userdata.get(\"OSF_PROJECT_ID\")\n",
        "OSF_PROJECT_ID = os.environ[\"OSF_PROJECT_ID\"]"
      ],
      "id": "rTXKZf9r4RY3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Corpora Data"
      ],
      "metadata": {
        "id": "4TgJ2Ob4MFbl"
      },
      "id": "4TgJ2Ob4MFbl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPR"
      ],
      "metadata": {
        "id": "g6ZYGFHFsQfw"
      },
      "id": "g6ZYGFHFsQfw"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/corpora/gpr_corpus.zip\", shell=True)\n",
        "print(\"gpr_corpus.zip successfully imported\")\n",
        "gpr_corpus_file_path_zip = 'gpr_corpus.zip'\n",
        "gpr_corpus_file_path = 'corpora/gpr-corpus'\n",
        "with zipfile.ZipFile(gpr_corpus_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(gpr_corpus_file_path)\n",
        "extracted_files = os.listdir(gpr_corpus_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxFLKKkTNvR-",
        "outputId": "077f6229-3f0e-4c3f-e74f-080a300bdea9"
      },
      "id": "SxFLKKkTNvR-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpr_corpus.zip successfully imported\n",
            "Files extracted: ['gpr_corpus', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EACL"
      ],
      "metadata": {
        "id": "AEl2TxdLsRkD"
      },
      "id": "AEl2TxdLsRkD"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/corpora/eacl_corpus.zip\", shell=True)\n",
        "print(\"eacl_corpus.zip successfully imported\")\n",
        "eacl_corpus_file_path_zip = 'eacl_corpus.zip'\n",
        "eacl_corpus_file_path = 'corpora/eacl-corpus'\n",
        "with zipfile.ZipFile(eacl_corpus_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(eacl_corpus_file_path)\n",
        "extracted_files = os.listdir(eacl_corpus_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEdfwyRaMHNN",
        "outputId": "e6f5a49e-7475-4965-8157-0ce169d5a047"
      },
      "id": "EEdfwyRaMHNN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eacl_corpus.zip successfully imported\n",
            "Files extracted: ['__MACOSX', 'eacl_corpus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### persuade_corpus"
      ],
      "metadata": {
        "id": "Ym2DxgkGy5sW"
      },
      "id": "Ym2DxgkGy5sW"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/corpora/persuade_corpus.zip\", shell=True)\n",
        "print(\"persuade_corpus.zip successfully imported\")\n",
        "persuade_corpus_file_path_zip = 'persuade_corpus.zip'\n",
        "persuade_corpus_file_path = 'corpora/persuade-corpus'\n",
        "with zipfile.ZipFile(persuade_corpus_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(persuade_corpus_file_path)\n",
        "extracted_files = os.listdir(persuade_corpus_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRjC2thyy7Jw",
        "outputId": "36050329-6f7d-4938-c331-581763f811e7"
      },
      "id": "gRjC2thyy7Jw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "persuade_corpus.zip successfully imported\n",
            "Files extracted: ['persuade_corpus', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SciFact"
      ],
      "metadata": {
        "id": "09eGtSDXsTCa"
      },
      "id": "09eGtSDXsTCa"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/corpora/scifact_corpus.zip\", shell=True)\n",
        "print(\"scifact_corpus.zip successfully imported\")\n",
        "scifact_corpus_file_path_zip = 'scifact_corpus.zip'\n",
        "scifact_corpus_file_path = 'corpora/scifact-corpus'\n",
        "with zipfile.ZipFile(scifact_corpus_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(scifact_corpus_file_path)\n",
        "extracted_files = os.listdir(scifact_corpus_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trK8YnyXrlLw",
        "outputId": "227802c6-c1bd-457b-b11f-f5b0821f74ca"
      },
      "id": "trK8YnyXrlLw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scifact_corpus.zip successfully imported\n",
            "Files extracted: ['__MACOSX', 'scifact_corpus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77496b2-c993-4be3-b1bb-eca04e33cf3c",
      "metadata": {
        "id": "d77496b2-c993-4be3-b1bb-eca04e33cf3c"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7848602-f4e3-4d65-8833-d33c230a953f",
      "metadata": {
        "id": "b7848602-f4e3-4d65-8833-d33c230a953f"
      },
      "source": [
        "### GPR 55"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f69ad0b-d78e-4ddd-8117-ce316aed90a9",
      "metadata": {
        "id": "6f69ad0b-d78e-4ddd-8117-ce316aed90a9"
      },
      "outputs": [],
      "source": [
        "gpr_df = pd.read_csv(\"corpora/gpr-corpus/gpr_corpus/GPR-KB-55/GPR-KB-55.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2a4a33-9bcd-4900-8fb7-760c9bc50cfe",
      "metadata": {
        "id": "ab2a4a33-9bcd-4900-8fb7-760c9bc50cfe"
      },
      "outputs": [],
      "source": [
        "DIM_EMBEDDING = 1536\n",
        "\n",
        "def gpr_get_embeddings_df(gpr_df: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Add embeddings column to a df\"\"\"\n",
        "  gpr_embeddings_df = pd.DataFrame()\n",
        "  arguments_list = list(gpr_df)\n",
        "\n",
        "  claims_embeddings = client.embeddings.create(input=arguments_list, model=\"text-embedding-ada-002\")\n",
        "  claims_embeddings_data = [embedding_data.embedding for embedding_data in claims_embeddings.data]\n",
        "  claims_embeddings_df = pd.DataFrame(claims_embeddings_data, columns=[f\"{str(i)}\" for i in range(DIM_EMBEDDING)])\n",
        "  claims_embeddings_df = claims_embeddings_df.reset_index(drop=True)\n",
        "\n",
        "  claims_embeddings_df = pd.concat([gpr_df, claims_embeddings_df], axis=1)\n",
        "  return claims_embeddings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199a733b-f251-496e-9b2b-73222c703857",
      "metadata": {
        "id": "199a733b-f251-496e-9b2b-73222c703857"
      },
      "outputs": [],
      "source": [
        "gpr_claims_df = gpr_get_embeddings_df(gpr_df['claim'])\n",
        "gpr_rebuttals_df = gpr_get_embeddings_df(gpr_df['rebuttal'])\n",
        "gpr_x_test = gpr_claims_df.select_dtypes(include=[np.number])\n",
        "gpr_y_test = gpr_rebuttals_df.select_dtypes(include=[np.number])\n",
        "gpr_combined = pd.concat([gpr_claims_df, gpr_rebuttals_df])\n",
        "gpr_combined = gpr_combined.reset_index(drop=True)\n",
        "gpr_combined_nums = gpr_combined.select_dtypes(include=[np.number])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min([len(claim) for claim in gpr_rebuttals_df['rebuttal']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U44BB_lUULe",
        "outputId": "c2db126c-5ea5-49cd-8285-a67c8a39982e"
      },
      "id": "9U44BB_lUULe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0682cdf-9b24-4f96-9bce-0dfb06cd0cec",
      "metadata": {
        "id": "d0682cdf-9b24-4f96-9bce-0dfb06cd0cec"
      },
      "outputs": [],
      "source": [
        "def metric_choose_argument_gpr(y_true, y_pred):\n",
        "  \"\"\"See if the output vector is closest to the rebuttal to the claim\"\"\"\n",
        "  gpr_training_df_32 = tf.cast(gpr_combined_nums, dtype=tf.float32)\n",
        "  gpr_norm = tf.norm(gpr_training_df_32, axis=1)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(gpr_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * gpr_norm, [-1, 1])\n",
        "  cos_sim_true = tf.matmul(gpr_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * gpr_norm, [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4fce8f5-b7ad-4898-88e2-205c885875d8",
      "metadata": {
        "id": "f4fce8f5-b7ad-4898-88e2-205c885875d8"
      },
      "source": [
        "### EACL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b0767d-3428-49db-bce1-5f26dccda2e6",
      "metadata": {
        "scrolled": true,
        "id": "43b0767d-3428-49db-bce1-5f26dccda2e6"
      },
      "outputs": [],
      "source": [
        "eacl_df = pd.read_csv(\"corpora/eacl-corpus/eacl_corpus/claim_stance_dataset.csv\")\n",
        "eacl_df = eacl_df[['topicId', 'topicText', 'claims.stance', 'claims.claimCorrectedText']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bd479fd-e5db-4348-b4ae-8cf77b7cc345",
      "metadata": {
        "id": "5bd479fd-e5db-4348-b4ae-8cf77b7cc345"
      },
      "outputs": [],
      "source": [
        "topic_lens = []\n",
        "pro_lens = []\n",
        "con_lens = []\n",
        "for topic in eacl_df['topicId'].unique():\n",
        "  topic_rows = eacl_df[eacl_df['topicId'] == topic]\n",
        "  topic_lens.append(len(topic_rows))\n",
        "  pro_lens.append(len(topic_rows[topic_rows['claims.stance'] == \"PRO\"]))\n",
        "  con_lens.append(len(topic_rows[topic_rows['claims.stance'] == \"CON\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c20b12-93b4-497a-89aa-375667ee8bdd",
      "metadata": {
        "id": "c8c20b12-93b4-497a-89aa-375667ee8bdd"
      },
      "outputs": [],
      "source": [
        "DIM_EMBEDDING = 1536\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=60, max=500), stop=stop_after_attempt(10))\n",
        "def eacl_get_embeddings(arguments: list) -> list:\n",
        "  \"\"\"Convert an argument into a (1 x 1536) embedding df\"\"\"\n",
        "  embeddings = client.embeddings.create(input=arguments, model=\"text-embedding-ada-002\")\n",
        "  embeddings_data = [embedding_data.embedding for embedding_data in embeddings.data]\n",
        "  embeddings_df = pd.DataFrame(embeddings_data, columns=[f\"{str(i)}\" for i in range(DIM_EMBEDDING)])\n",
        "  return embeddings_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0a1583-f638-43f0-8f60-1c2f5d1879e9",
      "metadata": {
        "id": "4c0a1583-f638-43f0-8f60-1c2f5d1879e9"
      },
      "outputs": [],
      "source": [
        "API_LIMIT = 1000\n",
        "\n",
        "def eacl_get_embeddings_df(eacl_df: pd.DataFrame) -> pd.DataFrame:\n",
        "  \"\"\"Add embeddings column to a df\"\"\"\n",
        "  embeddings_df = pd.DataFrame()\n",
        "  arguments_list = list(eacl_df['claims.claimCorrectedText'])\n",
        "  total_len = len(arguments_list)\n",
        "  i = 0\n",
        "\n",
        "  # Grab embeddings from arguments column in chunks\n",
        "  while i < total_len:\n",
        "    embeddings = eacl_get_embeddings(arguments_list[i:min(total_len, i+API_LIMIT)])\n",
        "    embeddings_df = pd.concat([embeddings_df, embeddings], axis=0, ignore_index=True)\n",
        "    i = i + API_LIMIT\n",
        "  arguments_embeddings_df = pd.concat([eacl_df, embeddings_df], axis=1)\n",
        "  return arguments_embeddings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87e8091-e303-4388-a899-fe6a4cdaa3bc",
      "metadata": {
        "scrolled": true,
        "id": "b87e8091-e303-4388-a899-fe6a4cdaa3bc"
      },
      "outputs": [],
      "source": [
        "eacl_embeddings_df = eacl_get_embeddings_df(eacl_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbab4309-efd9-4f13-a756-154d2e229ed5",
      "metadata": {
        "scrolled": true,
        "id": "bbab4309-efd9-4f13-a756-154d2e229ed5"
      },
      "outputs": [],
      "source": [
        "eacl_nums_df = eacl_embeddings_df.select_dtypes(include=[np.number])\n",
        "eacl_vectors_df = eacl_nums_df.drop('topicId', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persuade Corpus"
      ],
      "metadata": {
        "id": "KBoDgWRKzHJn"
      },
      "id": "KBoDgWRKzHJn"
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus = pd.read_csv('/content/corpora/persuade-corpus/persuade_corpus/persuade_corpus_1.0.csv')\n",
        "persuade_source = pd.read_csv('/content/corpora/persuade-corpus/persuade_corpus/persuade_2.0_human_scores_demo_id_github.csv')"
      ],
      "metadata": {
        "id": "Y-ssdwxAzLdO"
      },
      "id": "Y-ssdwxAzLdO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus = persuade_corpus[persuade_corpus['discourse_type'] == \"Evidence\"]\n",
        "persuade_corpus = persuade_corpus.drop(columns=['competition_set', 'full_text', 'discourse_id', 'discourse_start', 'discourse_end', 'discourse_type_num'])"
      ],
      "metadata": {
        "id": "LfSplQBrzTMg"
      },
      "id": "LfSplQBrzTMg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_source = persuade_source.drop(columns=['full_text', 'holistic_essay_score', 'word_count', 'task', 'assignment', 'source_text', 'gender', 'grade_level', 'ell_status', 'race_ethnicity', 'economically_disadvantaged', 'student_disability_status'])"
      ],
      "metadata": {
        "id": "cPhg-urjzkhQ"
      },
      "id": "cPhg-urjzkhQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_source_dict = zip(persuade_source['essay_id_comp'], persuade_source['prompt_name'])"
      ],
      "metadata": {
        "id": "OzUpCb3V04AN"
      },
      "id": "OzUpCb3V04AN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_source_dict = dict(persuade_source_dict)"
      ],
      "metadata": {
        "id": "Z1ubfKpK1Pfd"
      },
      "id": "Z1ubfKpK1Pfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus['argument'] = [persuade_source_dict[essay_id] if essay_id in persuade_source_dict.keys() else \"\" for essay_id in persuade_corpus['essay_id_comp']]"
      ],
      "metadata": {
        "id": "G23vkial1n18"
      },
      "id": "G23vkial1n18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus = persuade_corpus[persuade_corpus['argument'] != \"\"]"
      ],
      "metadata": {
        "id": "1nDTVqrk18Tv"
      },
      "id": "1nDTVqrk18Tv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus = persuade_corpus.drop(columns=['discourse_type', 'essay_id_comp'])\n",
        "persuade_corpus = persuade_corpus.rename(columns={'discourse_text': 'evidence'})"
      ],
      "metadata": {
        "id": "YcRZE6r12BK_"
      },
      "id": "YcRZE6r12BK_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus = persuade_corpus.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nzx2E_hr2VJE"
      },
      "id": "nzx2E_hr2VJE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_argument_dict = {\n",
        "    'Phones and driving': 'Drivers should not be allowed to use phones while driving',\n",
        "    'Car-free cities': 'We should develop cities to be car-free from now on',\n",
        "    'Summer projects': 'Summer projects are valuable learning opportunities for students',\n",
        "    '\"A Cowboy Who Rode the Waves\"': \"The Seagoing Cowboys' work is adventurous, meaningful and transformative\",\n",
        "    'Mandatory extracurricular activities': \"Extracurricular activities play an irreplacable role in students' education\",\n",
        "    'Exploring Venus': 'Venus is a challenging but rewarding planet to explore',\n",
        "    'Facial action coding system': 'Having a large-scale software that analyzes and codifies human facial expressions is pointless',\n",
        "    'The Face on Mars': 'The face on Mars suggests alien activity in the universe',\n",
        "    'Community service': 'Doing community service is important to both societal and personal benefit',\n",
        "    'Grades for extracurricular activities': 'Extracurricular activities should not be graded',\n",
        "    'Driverless cars': 'Driverless cars are the future and should be fully embraced',\n",
        "    'Does the electoral college work?': 'The electoral college does not work',\n",
        "    'Cell phones at school': 'Students should be allowed to bring cell phones to school',\n",
        "    'Distance learning': 'Online classes are the bane of real education',\n",
        "    'Seeking multiple opinions': 'It is always a good idea to seek the opinions of multiple people'\n",
        "}"
      ],
      "metadata": {
        "id": "ismVzpD02hM8"
      },
      "id": "ismVzpD02hM8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_corpus['argument'] = [persuade_argument_dict[topic] for topic in persuade_corpus['argument']]"
      ],
      "metadata": {
        "id": "sMYLXzcq2ZTD"
      },
      "id": "sMYLXzcq2ZTD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_arguments_df = pd.DataFrame(persuade_argument_dict.values(), columns=['argument'])"
      ],
      "metadata": {
        "id": "ji2bl7UD7Hi-"
      },
      "id": "ji2bl7UD7Hi-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL3fOrfM6hPY"
      },
      "outputs": [],
      "source": [
        "DIM_EMBEDDING = 1536\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=60, max=500), stop=stop_after_attempt(10))\n",
        "def persuade_get_embeddings(arguments: list) -> list:\n",
        "  \"\"\"Convert an argument into a (1 x 1536) embedding df\"\"\"\n",
        "  embeddings = client.embeddings.create(input=arguments, model=\"text-embedding-ada-002\")\n",
        "  embeddings_data = [embedding_data.embedding for embedding_data in embeddings.data]\n",
        "  embeddings_df = pd.DataFrame(embeddings_data, columns=[f\"{str(i)}\" for i in range(DIM_EMBEDDING)])\n",
        "  return embeddings_df.reset_index(drop=True)"
      ],
      "id": "EL3fOrfM6hPY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iAMbl5F6hPY"
      },
      "outputs": [],
      "source": [
        "API_LIMIT = 1000\n",
        "\n",
        "def persuade_get_embeddings_df(persuade_df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
        "  \"\"\"Add embeddings column to a df\"\"\"\n",
        "  embeddings_df = pd.DataFrame()\n",
        "  arguments_list = list(persuade_df[column_name])\n",
        "  total_len = len(arguments_list)\n",
        "  i = 0\n",
        "\n",
        "  # Grab embeddings from arguments column in chunks\n",
        "  while i < total_len:\n",
        "    embeddings = persuade_get_embeddings(arguments_list[i:min(total_len, i+API_LIMIT)])\n",
        "    embeddings_df = pd.concat([embeddings_df, embeddings], axis=0, ignore_index=True)\n",
        "    i = i + API_LIMIT\n",
        "  arguments_embeddings_df = pd.concat([persuade_df, embeddings_df], axis=1)\n",
        "  return arguments_embeddings_df"
      ],
      "id": "4iAMbl5F6hPY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wqHn1Ktc6hPY"
      },
      "outputs": [],
      "source": [
        "persuade_arguments_embeddings_df = persuade_get_embeddings_df(persuade_arguments_df, 'argument')"
      ],
      "id": "wqHn1Ktc6hPY"
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_arguments_vector_df = persuade_arguments_embeddings_df.select_dtypes(include=[np.number])"
      ],
      "metadata": {
        "id": "ZaQxWITn_tP8"
      },
      "id": "ZaQxWITn_tP8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_evidence_embeddings_df = persuade_get_embeddings_df(persuade_corpus, 'evidence')"
      ],
      "metadata": {
        "id": "hA6MfzLN-SWX"
      },
      "id": "hA6MfzLN-SWX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_evidence_vector_df = persuade_evidence_embeddings_df.select_dtypes(include=[np.number])"
      ],
      "metadata": {
        "id": "LSZ7Oi-u_Mvn"
      },
      "id": "LSZ7Oi-u_Mvn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "argument_evidence_counts = Counter(persuade_evidence_embeddings_df['argument'])"
      ],
      "metadata": {
        "id": "VS_TdG5jBsCS"
      },
      "id": "VS_TdG5jBsCS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(argument_evidence_counts.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1ypf96tBxw8",
        "outputId": "6d685bb0-5e23-4601-a6bd-eacf8d6f27dc"
      },
      "id": "q1ypf96tBxw8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7518"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SciFact Corpus"
      ],
      "metadata": {
        "id": "KEUfpZVasFVj"
      },
      "id": "KEUfpZVasFVj"
    },
    {
      "cell_type": "code",
      "source": [
        "DIM_EMBEDDING = 1536\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=60, max=500), stop=stop_after_attempt(10))\n",
        "def scifact_get_embeddings(arguments: list) -> list:\n",
        "  \"\"\"Convert an argument into a (1 x 1536) embedding df\"\"\"\n",
        "  embeddings = client.embeddings.create(input=arguments, model=\"text-embedding-ada-002\")\n",
        "  embeddings_data = [embedding_data.embedding for embedding_data in embeddings.data]\n",
        "  embeddings_df = pd.DataFrame(embeddings_data, columns=[f\"{str(i)}\" for i in range(DIM_EMBEDDING)])\n",
        "  return embeddings_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ABburqcPG0tL"
      },
      "id": "ABburqcPG0tL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_LIMIT = 1000\n",
        "\n",
        "def scifact_get_embeddings_df(scifact_df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
        "  \"\"\"Add embeddings column to a df\"\"\"\n",
        "  embeddings_df = pd.DataFrame()\n",
        "  arguments_list = list(scifact_df[column_name])\n",
        "  total_len = len(arguments_list)\n",
        "  i = 0\n",
        "\n",
        "  # Grab embeddings from arguments column in chunks\n",
        "  while i < total_len:\n",
        "    embeddings = scifact_get_embeddings(arguments_list[i:min(total_len, i+API_LIMIT)])\n",
        "    embeddings_df = pd.concat([embeddings_df, embeddings], axis=0, ignore_index=True)\n",
        "    i = i + API_LIMIT\n",
        "  arguments_embeddings_df = pd.concat([scifact_df, embeddings_df], axis=1)\n",
        "  return arguments_embeddings_df"
      ],
      "metadata": {
        "id": "wbSA3U7YG10I"
      },
      "id": "wbSA3U7YG10I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_corpus = pd.read_json('/content/corpora/scifact-corpus/scifact_corpus/corpus.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "pfOD_Nx6sCtc"
      },
      "id": "pfOD_Nx6sCtc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_evidence_corpus = []\n",
        "\n",
        "for abstract in scifact_corpus['abstract']:\n",
        "  for sentence in abstract:\n",
        "    scifact_evidence_corpus.append(sentence)"
      ],
      "metadata": {
        "id": "iSFcAQLjs_x_"
      },
      "id": "iSFcAQLjs_x_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_evidence_embeddings_corpus = scifact_get_embeddings_df(pd.DataFrame(scifact_evidence_corpus, columns=['evidence']), 'evidence')"
      ],
      "metadata": {
        "id": "qKo3XacDHP-A"
      },
      "id": "qKo3XacDHP-A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_evidence_embeddings = scifact_evidence_embeddings_corpus.select_dtypes(include=[np.number])"
      ],
      "metadata": {
        "id": "_LtQ-xtEHnA4"
      },
      "id": "_LtQ-xtEHnA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_test = pd.read_json('/content/corpora/scifact-corpus/scifact_corpus/claims_test.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "j_IVlWPNtDy9"
      },
      "id": "j_IVlWPNtDy9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_test = scifact_test.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "P8_H6TCctIa3"
      },
      "id": "P8_H6TCctIa3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_test_embeddings_corpus = scifact_get_embeddings_df(scifact_test, 'claim')"
      ],
      "metadata": {
        "id": "CsdSs4B8HpO7"
      },
      "id": "CsdSs4B8HpO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_test_embeddings = scifact_test_embeddings_corpus.select_dtypes(include=[np.number])"
      ],
      "metadata": {
        "id": "TqpIktG1JKqO"
      },
      "id": "TqpIktG1JKqO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder Model"
      ],
      "metadata": {
        "id": "-M6M0xNuLPVJ"
      },
      "id": "-M6M0xNuLPVJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Counterargument model"
      ],
      "metadata": {
        "id": "B65r-dHQDUEY"
      },
      "id": "B65r-dHQDUEY"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-autoencoder/ada_autoencoder.zip\", shell=True)\n",
        "print(\"ada_autoencoder.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'ada_autoencoder.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/ada-autoencoder'\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aetiEHo9K2So",
        "outputId": "59f034e2-37ff-41f2-c9ae-55b5e0f89495"
      },
      "id": "aetiEHo9K2So",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_training_plot.png', 'x_test.pkl', 'y_test.pkl', 'y_teset.pkl', 'global_shuffled_training_plot.png', 'global_shuffled_training_log.csv', 'training_df.pkl', 'combined_global_training_plot.png', 'global_training_df.pkl', 'global_shuffled_autoencoder_model.keras', 'x_train.pkl', 'y_train.pkl', 'global_autoencoder_model.keras', 'global_training_log.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pd.read_pickle('current-data-dump/ada-autoencoder/x_train.pkl')\n",
        "y_train = pd.read_pickle('current-data-dump/ada-autoencoder/y_train.pkl')\n",
        "x_test = pd.read_pickle('current-data-dump/ada-autoencoder/x_test.pkl')\n",
        "y_test = pd.read_pickle('current-data-dump/ada-autoencoder/y_test.pkl')"
      ],
      "metadata": {
        "id": "afiKxdeRu-HK"
      },
      "id": "afiKxdeRu-HK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evidence model"
      ],
      "metadata": {
        "id": "7IYsp-J2DVxq"
      },
      "id": "7IYsp-J2DVxq"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-evidence-autoencoder/ada003_evidence_autoencoder.zip\", shell=True)\n",
        "print(\"ada003_evidence_autoencoder.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'ada003_evidence_autoencoder.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/ada-evidence-autoencoder'\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt_T-7PoDTgk",
        "outputId": "2471363e-f056-4442-a73f-6c82bbd8dac6"
      },
      "id": "Nt_T-7PoDTgk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada003_evidence_autoencoder.zip successfully imported\n",
            "Files extracted: ['global_x_test.pkl', 'global_shuffled_training_log.csv', 'global_shuffled_autoencoder_model.keras', 'global_y_test.pkl', 'global_y_train.pkl', 'global_autoencoder_model.keras', 'global_x_train.pkl', 'global_training_log.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_evidence_train = pd.read_pickle('current-data-dump/ada-evidence-autoencoder/global_x_train.pkl')\n",
        "y_evidence_train = pd.read_pickle('current-data-dump/ada-evidence-autoencoder/global_y_train.pkl')\n",
        "x_evidence_test = pd.read_pickle('current-data-dump/ada-evidence-autoencoder/global_x_test.pkl')\n",
        "y_evidence_test = pd.read_pickle('current-data-dump/ada-evidence-autoencoder/global_y_test.pkl')"
      ],
      "metadata": {
        "id": "leXMXiIbDjwu"
      },
      "id": "leXMXiIbDjwu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SciFact models"
      ],
      "metadata": {
        "id": "lLJ9m6ToGLB4"
      },
      "id": "lLJ9m6ToGLB4"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-scifact-autoencoder/ada003_scifact_autoencoder.zip\", shell=True)\n",
        "print(\"ada003_scifact_autoencoder.zip successfully imported\")\n",
        "ada_autoencoder_file_path_zip = 'ada003_scifact_autoencoder.zip'\n",
        "ada_autoencoder_file_path = 'current-data-dump/ada-scifact-autoencoder'\n",
        "with zipfile.ZipFile(ada_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb5dda7-d172-45ee-edcc-e575a1df1a66",
        "id": "N48y6VY7GLCC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ada003_scifact_autoencoder.zip successfully imported\n",
            "Files extracted: ['y_train_combined.pkl', 'combined_training_log.csv', 'combined_shuffled_training_log.csv', 'counter_shuffled_autoencoder_model.keras', 'pro_autoencoder_model.keras', 'all_shuffled_training_plot.png', 'counter_shuffled_training_plot.png', 'y_test_counter.pkl', 'pro_shuffled_training_log.csv', 'pro_shuffled_autoencoder_model.keras', 'x_train_pro.pkl', 'pro_training_log.csv', 'x_test_combined.pkl', 'counter_training_plot.png', 'x_test_pro.pkl', 'pro_shuffled_training_plot.png', 'x_train_combined.pkl', 'y_test_combined.pkl', 'all_training_plot.png', 'x_test_counter.pkl', 'y_test_pro.pkl', 'combined_counter_training_plot.png', 'counter_training_log.csv', 'counter_shuffled_training_log.csv', 'combined_pro_training_plot.png', 'combined_autoencoder_model.keras', 'combined_shuffled_autoencoder_model.keras', 'y_train_counter.pkl', 'y_train_pro.pkl', 'combined_training_plot.png', 'counter_autoencoder_model.keras', 'pro_training_plot.png', 'x_train_counter.pkl']\n"
          ]
        }
      ],
      "id": "N48y6VY7GLCC"
    },
    {
      "cell_type": "code",
      "source": [
        "x_scifact_train = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/x_train_combined.pkl')\n",
        "y_scifact_train = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/y_train_combined.pkl')\n",
        "x_scifact_test = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/x_test_combined.pkl')\n",
        "y_scifact_test = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/y_test_combined.pkl')"
      ],
      "metadata": {
        "id": "5fBH-eLbGLCC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5fBH-eLbGLCC"
    },
    {
      "cell_type": "code",
      "source": [
        "x_scifact_pro_train = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/x_train_pro.pkl')\n",
        "y_scifact_pro_train = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/y_train_pro.pkl')\n",
        "x_scifact_pro_test = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/x_test_pro.pkl')\n",
        "y_scifact_pro_test = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/y_test_pro.pkl')"
      ],
      "metadata": {
        "id": "sW6bSAzpPDdF"
      },
      "id": "sW6bSAzpPDdF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_scifact_counter_train = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/x_train_counter.pkl')\n",
        "y_scifact_counter_train = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/y_train_counter.pkl')\n",
        "x_scifact_counter_test = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/x_test_counter.pkl')\n",
        "y_scifact_counter_test = pd.read_pickle('current-data-dump/ada-scifact-autoencoder/y_test_counter.pkl')"
      ],
      "metadata": {
        "id": "e5AdE4QmPIuC"
      },
      "id": "e5AdE4QmPIuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric"
      ],
      "metadata": {
        "id": "hQ9_lP8vJVjM"
      },
      "id": "hQ9_lP8vJVjM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53be282-1ddf-4bbe-af7a-412b8c685066",
      "metadata": {
        "id": "e53be282-1ddf-4bbe-af7a-412b8c685066"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_global_y_train(y_true, y_pred):\n",
        "  global_training_df_32 = tf.cast(pd.concat([x_train, y_train, x_test, y_test]), dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_combined_y_train(y_true, y_pred):\n",
        "  global_training_df_32 = tf.cast(pd.concat([x_scifact_train, y_scifact_train, x_scifact_test, y_scifact_test]), dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "metadata": {
        "id": "Osz3_gw9GfGv"
      },
      "id": "Osz3_gw9GfGv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_pro_y_train(y_true, y_pred):\n",
        "  global_training_df_32 = tf.cast(pd.concat([x_scifact_pro_train, y_scifact_pro_train, x_scifact_pro_test, y_scifact_pro_test]), dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "metadata": {
        "id": "Ufbdw0ZAPMX0"
      },
      "id": "Ufbdw0ZAPMX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def metric_choose_argument_counter_y_train(y_true, y_pred):\n",
        "  global_training_df_32 = tf.cast(pd.concat([x_scifact_counter_train, y_scifact_counter_train, x_scifact_counter_test, y_scifact_counter_test]), dtype=tf.float32)\n",
        "\n",
        "  cos_sim_pred = tf.matmul(global_training_df_32, y_pred, transpose_b=True) / tf.reshape(tf.norm(y_pred) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "  cos_sim_true = tf.matmul(global_training_df_32, y_true, transpose_b=True) / tf.reshape(tf.norm(y_true) * tf.norm(global_training_df_32, axis=1), [-1, 1])\n",
        "\n",
        "  max_cos_sim_pred = tf.math.argmax(cos_sim_pred)\n",
        "  max_cos_sim_true = tf.math.argmax(cos_sim_true)\n",
        "\n",
        "  return tf.math.count_nonzero(tf.equal(max_cos_sim_pred, max_cos_sim_true))"
      ],
      "metadata": {
        "id": "i1uH8IP1PPns"
      },
      "id": "i1uH8IP1PPns",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2e3a4568-5a9c-4652-a321-d89618146273",
      "metadata": {
        "id": "2e3a4568-5a9c-4652-a321-d89618146273"
      },
      "source": [
        "## Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c40f5f9-aeea-4e29-89d5-5b3f9a949638",
      "metadata": {
        "id": "3c40f5f9-aeea-4e29-89d5-5b3f9a949638"
      },
      "outputs": [],
      "source": [
        "global_autoencoder_model = tf.keras.models.load_model('current-data-dump/ada-autoencoder/global_autoencoder_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_evidence_autoencoder_model = tf.keras.models.load_model('current-data-dump/ada-evidence-autoencoder/global_autoencoder_model.keras')"
      ],
      "metadata": {
        "id": "_DUXTg6lD535"
      },
      "id": "_DUXTg6lD535",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_scifact_autoencoder_model = tf.keras.models.load_model('/content/current-data-dump/ada-scifact-autoencoder/combined_autoencoder_model.keras')"
      ],
      "metadata": {
        "id": "0x4rOj7VGFPk"
      },
      "id": "0x4rOj7VGFPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_scifact_pro_autoencoder_model = tf.keras.models.load_model('/content/current-data-dump/ada-scifact-autoencoder/pro_autoencoder_model.keras')"
      ],
      "metadata": {
        "id": "9-UIYVx9PTul"
      },
      "id": "9-UIYVx9PTul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_scifact_counter_autoencoder_model = tf.keras.models.load_model('/content/current-data-dump/ada-scifact-autoencoder/counter_autoencoder_model.keras')"
      ],
      "metadata": {
        "id": "EWai9Rq_PWv2"
      },
      "id": "EWai9Rq_PWv2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7a844caf-39c0-46ab-8611-cf22c919a932",
      "metadata": {
        "id": "7a844caf-39c0-46ab-8611-cf22c919a932"
      },
      "source": [
        "## GPR predict (Counterargument)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6557b3bb-29ad-4e6d-8a09-629d65c6b9dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6557b3bb-29ad-4e6d-8a09-629d65c6b9dd",
        "outputId": "d201fd35-9db4-4fcf-f625-7cfa1b74ef86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "global_autoencoder_gpr_predictions = global_autoencoder_model.predict(gpr_x_test)\n",
        "global_autoencoder_gpr_predictions_df = pd.DataFrame(global_autoencoder_gpr_predictions)\n",
        "global_autoencoder_gpr_predictions_df.columns = [str(i) for i in global_autoencoder_gpr_predictions_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482d775e-4e43-4632-b665-d64e5c9baf7b",
      "metadata": {
        "id": "482d775e-4e43-4632-b665-d64e5c9baf7b"
      },
      "outputs": [],
      "source": [
        "successes = 0\n",
        "for i in range(len(gpr_y_test)):\n",
        "  gpr_y_test_tf = tf.convert_to_tensor(gpr_y_test.loc[i], dtype=tf.float32)\n",
        "  gpr_pred_tf = tf.convert_to_tensor(global_autoencoder_gpr_predictions_df.loc[i], dtype=tf.float32)\n",
        "  gpr_y_test_tf = tf.reshape(gpr_y_test_tf, (1, -1))\n",
        "  gpr_pred_tf = tf.reshape(gpr_pred_tf, (1, -1))\n",
        "  if metric_choose_argument_gpr(gpr_y_test_tf, gpr_pred_tf).numpy() == 1:\n",
        "    successes += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a14c5b4-3954-4536-a2ea-d6f538690a33",
      "metadata": {
        "id": "7a14c5b4-3954-4536-a2ea-d6f538690a33"
      },
      "outputs": [],
      "source": [
        "gpr_success_rate = successes / len(gpr_y_test) * 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpr_success_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBBrJs1ty_rs",
        "outputId": "0efb0e36-3edb-47ec-da49-970503236352"
      },
      "id": "EBBrJs1ty_rs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8181818181818181"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964b043e-166b-4cdb-8c90-6a7c3e9de543",
      "metadata": {
        "id": "964b043e-166b-4cdb-8c90-6a7c3e9de543"
      },
      "source": [
        "## EACL Predict (Counterargument)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde0c9db-8665-4745-b223-b1a128a13992",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cde0c9db-8665-4745-b223-b1a128a13992",
        "outputId": "63004a1d-5d3d-4c25-893c-34a17419103e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "global_autoencoder_eacl_predictions = global_autoencoder_model.predict(eacl_vectors_df)\n",
        "global_autoencoder_eacl_predictions_df = pd.DataFrame(global_autoencoder_eacl_predictions)\n",
        "global_autoencoder_eacl_predictions_df.columns = [str(i) for i in global_autoencoder_eacl_predictions_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eacl_topk = 1\n",
        "pred_topk = []"
      ],
      "metadata": {
        "id": "TkOtj_qHZCyo"
      },
      "id": "TkOtj_qHZCyo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eacl_embeddings_df_32 = tf.cast(eacl_vectors_df, dtype=tf.float32)\n",
        "global_autoencoder_eacl_predictions_tf = tf.constant(global_autoencoder_eacl_predictions_df.values, dtype=tf.float32)\n",
        "eacl_embeddings_norm = tf.norm(eacl_embeddings_df_32, axis=1)\n",
        "eacl_topics = list(eacl_embeddings_df['topicId'])\n",
        "eacl_stances = list(eacl_embeddings_df['claims.stance'])"
      ],
      "metadata": {
        "id": "NeDejiHcORtp"
      },
      "id": "NeDejiHcORtp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in enumerate(global_autoencoder_eacl_predictions_tf):\n",
        "  successes = 0\n",
        "  y_pred = tf.reshape(row, [1, -1])\n",
        "  target_topic = eacl_topics[i]\n",
        "  target_type = 'PRO' if eacl_stances[i] == 'CON' else 'CON'\n",
        "\n",
        "  cos_sim_pred = tf.matmul(eacl_embeddings_df_32, y_pred, transpose_b=True) / tf.reshape((tf.norm(y_pred) * eacl_embeddings_norm), [-1, 1])\n",
        "  top_k_sim_pred = tf.math.top_k(tf.reshape(cos_sim_pred, [-1]), k=eacl_topk).indices.numpy()\n",
        "\n",
        "  for index in top_k_sim_pred:\n",
        "    if eacl_topics[index] == target_topic and eacl_stances[index] == target_type:\n",
        "      successes += 1\n",
        "  pred_topk.append(successes / eacl_topk * 100)"
      ],
      "metadata": {
        "id": "r3cVyLKuVaNr"
      },
      "id": "r3cVyLKuVaNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d27c121-eb83-4c4c-b60e-417b52da304f",
      "metadata": {
        "id": "3d27c121-eb83-4c4c-b60e-417b52da304f"
      },
      "outputs": [],
      "source": [
        "eacl_topk_success_rate = statistics.mean(pred_topk)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eacl_topk_success_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlbXZEIKvs-9",
        "outputId": "35ceb4d2-7c0a-4229-989b-c1fe7a170832"
      },
      "id": "PlbXZEIKvs-9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.4586466165413534"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFd-ei2Q6J4q"
      },
      "source": [
        "## persuade Predict (Evidence)"
      ],
      "id": "fFd-ei2Q6J4q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbb14b7-d091-464d-8e6c-2b5d486d8000",
        "id": "UcY3IRhl6J4r"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "global_evidence_autoencoder_persuade_predictions = global_evidence_autoencoder_model.predict(persuade_arguments_vector_df)\n",
        "global_evidence_autoencoder_persuade_predictions_df = pd.DataFrame(global_evidence_autoencoder_persuade_predictions)\n",
        "global_evidence_autoencoder_persuade_predictions_df.columns = [str(i) for i in global_evidence_autoencoder_persuade_predictions_df.columns]"
      ],
      "id": "UcY3IRhl6J4r"
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_topk = 50000\n",
        "pred_topk=[]"
      ],
      "metadata": {
        "id": "4U-vuhqr6J4r"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4U-vuhqr6J4r"
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_embeddings_df_32 = tf.cast(persuade_evidence_vector_df, dtype=tf.float32)\n",
        "global_autoencoder_persuade_predictions_tf = tf.constant(global_evidence_autoencoder_persuade_predictions_df.values, dtype=tf.float32)\n",
        "persuade_embeddings_norm = tf.norm(persuade_embeddings_df_32, axis=1)\n",
        "persuade_topics = list(persuade_evidence_embeddings_df['argument'])"
      ],
      "metadata": {
        "id": "08RkjrM-6J4r"
      },
      "execution_count": null,
      "outputs": [],
      "id": "08RkjrM-6J4r"
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in enumerate(global_autoencoder_persuade_predictions_tf):\n",
        "  successes = 0\n",
        "  y_pred = tf.reshape(row, [1, -1])\n",
        "  target_topic = persuade_topics[i]\n",
        "\n",
        "  cos_sim_pred = tf.matmul(persuade_embeddings_df_32, y_pred, transpose_b=True) / tf.reshape((tf.norm(y_pred) * persuade_embeddings_norm), [-1, 1])\n",
        "  top_k_sim_pred = tf.math.top_k(tf.reshape(cos_sim_pred, [-1]), k=persuade_topk).indices.numpy()\n",
        "\n",
        "  for index in top_k_sim_pred:\n",
        "    if persuade_topics[index] == target_topic:\n",
        "      successes += 1\n",
        "  pred_topk.append(successes / persuade_topk * 100)"
      ],
      "metadata": {
        "id": "_sABJgbt6J4r"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_sABJgbt6J4r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giYL-zr-6J4r"
      },
      "outputs": [],
      "source": [
        "persuade_topk_success_rate = statistics.mean(pred_topk)"
      ],
      "id": "giYL-zr-6J4r"
    },
    {
      "cell_type": "code",
      "source": [
        "persuade_topk_success_rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2016d9-8d51-4254-c23a-b942a6f8384b",
        "id": "gTsQI40n6J4r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2654666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ],
      "id": "gTsQI40n6J4r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKl5lcUtwvGZ"
      },
      "source": [
        "## Scifact Predict (Evidence + Combined + Qualitative)"
      ],
      "id": "kKl5lcUtwvGZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac66e6d9-055a-4b9c-dfdc-e67680f4abff",
        "id": "88iTjklkwvGa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "global_autoencoder_scifact_predictions = global_scifact_autoencoder_model.predict(scifact_test_embeddings)\n",
        "global_autoencoder_scifact_predictions_df = pd.DataFrame(global_autoencoder_scifact_predictions)\n",
        "global_autoencoder_scifact_predictions_df.columns = [str(i) for i in global_autoencoder_scifact_predictions_df.columns]"
      ],
      "id": "88iTjklkwvGa"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_topk = 10\n",
        "pred_topk=[]"
      ],
      "metadata": {
        "id": "FdbEVqvqwvGa"
      },
      "execution_count": null,
      "outputs": [],
      "id": "FdbEVqvqwvGa"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_embeddings_df_32 = tf.cast(scifact_evidence_embeddings, dtype=tf.float32)\n",
        "global_autoencoder_scifact_predictions_tf = tf.constant(global_autoencoder_scifact_predictions_df.values, dtype=tf.float32)\n",
        "scifact_embeddings_norm = tf.norm(scifact_embeddings_df_32, axis=1)"
      ],
      "metadata": {
        "id": "Zqjip_4IwvGa"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Zqjip_4IwvGa"
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_column = []\n",
        "for i, row in enumerate(global_autoencoder_scifact_predictions_tf):\n",
        "  pred_topk = []\n",
        "  successes = 0\n",
        "  y_pred = tf.reshape(row, [1, -1])\n",
        "\n",
        "  cos_sim_pred = tf.matmul(scifact_embeddings_df_32, y_pred, transpose_b=True) / tf.reshape((tf.norm(y_pred) * scifact_embeddings_norm), [-1, 1])\n",
        "  top_k_sim_pred = tf.math.top_k(tf.reshape(cos_sim_pred, [-1]), k=scifact_topk).indices.numpy()\n",
        "\n",
        "  for index in top_k_sim_pred:\n",
        "    pred_topk.append(scifact_evidence_embeddings_corpus.iloc[index]['evidence'])\n",
        "  evidence_column.append(pred_topk)"
      ],
      "metadata": {
        "id": "-v_Jepg8wvGb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "-v_Jepg8wvGb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQCHlmDfwvGb"
      },
      "outputs": [],
      "source": [
        "scifact_topk_results = scifact_test.copy()\n",
        "scifact_topk_results['topk'] = evidence_column"
      ],
      "id": "XQCHlmDfwvGb"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_topk_results.to_csv('current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions/scifact_combined_topk_results.csv')"
      ],
      "metadata": {
        "id": "XOoCRnaRwvGb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "625446da-e187-4e98-ed09-7d943bf885ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: 'current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-b274d136918b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscifact_topk_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions/scifact_combined_topk_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3770\u001b[0m         )\n\u001b[1;32m   3771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3772\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3773\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3774\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         )\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions'"
          ]
        }
      ],
      "id": "XOoCRnaRwvGb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_NAcKqKO0C6"
      },
      "source": [
        "## Scifact Predict (Evidence + Pro + Qualitative)"
      ],
      "id": "q_NAcKqKO0C6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "COGBL2brO0C6"
      },
      "outputs": [],
      "source": [
        "global_autoencoder_scifact_pro_predictions = global_scifact_pro_autoencoder_model.predict(scifact_test_embeddings)\n",
        "global_autoencoder_scifact_pro_predictions_df = pd.DataFrame(global_autoencoder_scifact_pro_predictions)\n",
        "global_autoencoder_scifact_pro_predictions_df.columns = [str(i) for i in global_autoencoder_scifact_pro_predictions_df.columns]"
      ],
      "id": "COGBL2brO0C6"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_pro_topk = 10\n",
        "pred_pro_topk=[]"
      ],
      "metadata": {
        "id": "p_hRWWxxO0C7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "p_hRWWxxO0C7"
    },
    {
      "cell_type": "code",
      "source": [
        "# scifact_embeddings_df_32 = tf.cast(scifact_evidence_embeddings, dtype=tf.float32)\n",
        "global_autoencoder_scifact_pro_predictions_tf = tf.constant(global_autoencoder_scifact_pro_predictions_df.values, dtype=tf.float32)\n",
        "# scifact_embeddings_norm = tf.norm(scifact_embeddings_df_32, axis=1)"
      ],
      "metadata": {
        "id": "ADDw32OOO0C7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ADDw32OOO0C7"
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_pro_column = []\n",
        "for i, row in enumerate(global_autoencoder_scifact_pro_predictions_tf):\n",
        "  pred_pro_topk = []\n",
        "  successes = 0\n",
        "  y_pred = tf.reshape(row, [1, -1])\n",
        "\n",
        "  cos_sim_pred = tf.matmul(scifact_embeddings_df_32, y_pred, transpose_b=True) / tf.reshape((tf.norm(y_pred) * scifact_embeddings_norm), [-1, 1])\n",
        "  top_k_sim_pred = tf.math.top_k(tf.reshape(cos_sim_pred, [-1]), k=scifact_topk).indices.numpy()\n",
        "\n",
        "  for index in top_k_sim_pred:\n",
        "    pred_pro_topk.append(scifact_evidence_embeddings_corpus.iloc[index]['evidence'])\n",
        "  evidence_pro_column.append(pred_pro_topk)"
      ],
      "metadata": {
        "id": "u5LkXNvzO0C7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "u5LkXNvzO0C7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4URWvqg3O0C7"
      },
      "outputs": [],
      "source": [
        "scifact_pro_topk_results = scifact_test.copy()\n",
        "scifact_pro_topk_results['topk'] = evidence_pro_column"
      ],
      "id": "4URWvqg3O0C7"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_pro_topk_results.to_csv('current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions/scifact_pro_topk_results.csv')"
      ],
      "metadata": {
        "id": "Y1ezKdMVO0C7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y1ezKdMVO0C7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqOE8WiLQLGi"
      },
      "source": [
        "## Scifact Predict (Evidence + Counter + Qualitative)"
      ],
      "id": "eqOE8WiLQLGi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Qpe7iFFbQLGi"
      },
      "outputs": [],
      "source": [
        "global_autoencoder_scifact_counter_predictions = global_scifact_counter_autoencoder_model.predict(scifact_test_embeddings)\n",
        "global_autoencoder_scifact_counter_predictions_df = pd.DataFrame(global_autoencoder_scifact_counter_predictions)\n",
        "global_autoencoder_scifact_counter_predictions_df.columns = [str(i) for i in global_autoencoder_scifact_counter_predictions_df.columns]"
      ],
      "id": "Qpe7iFFbQLGi"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_counter_topk = 10\n",
        "pred_counter_topk=[]"
      ],
      "metadata": {
        "id": "LKkwYUQCQLGi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LKkwYUQCQLGi"
    },
    {
      "cell_type": "code",
      "source": [
        "# scifact_embeddings_df_32 = tf.cast(scifact_evidence_embeddings, dtype=tf.float32)\n",
        "global_autoencoder_scifact_counter_predictions_tf = tf.constant(global_autoencoder_scifact_counter_predictions_df.values, dtype=tf.float32)\n",
        "# scifact_embeddings_norm = tf.norm(scifact_embeddings_df_32, axis=1)"
      ],
      "metadata": {
        "id": "HSJ9mTvYQLGj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "HSJ9mTvYQLGj"
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_counter_column = []\n",
        "for i, row in enumerate(global_autoencoder_scifact_counter_predictions_tf):\n",
        "  pred_counter_topk = []\n",
        "  successes = 0\n",
        "  y_pred = tf.reshape(row, [1, -1])\n",
        "\n",
        "  cos_sim_pred = tf.matmul(scifact_embeddings_df_32, y_pred, transpose_b=True) / tf.reshape((tf.norm(y_pred) * scifact_embeddings_norm), [-1, 1])\n",
        "  top_k_sim_pred = tf.math.top_k(tf.reshape(cos_sim_pred, [-1]), k=scifact_topk).indices.numpy()\n",
        "\n",
        "  for index in top_k_sim_pred:\n",
        "    pred_counter_topk.append(scifact_evidence_embeddings_corpus.iloc[index]['evidence'])\n",
        "  evidence_counter_column.append(pred_counter_topk)"
      ],
      "metadata": {
        "id": "dPfqxa34QLGj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "dPfqxa34QLGj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXrvWDTPQLGj"
      },
      "outputs": [],
      "source": [
        "scifact_counter_topk_results = scifact_test.copy()\n",
        "scifact_counter_topk_results['topk'] = evidence_counter_column"
      ],
      "id": "wXrvWDTPQLGj"
    },
    {
      "cell_type": "code",
      "source": [
        "scifact_counter_topk_results.to_csv('current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions/scifact_counter_topk_results.csv')"
      ],
      "metadata": {
        "id": "MgVNrRHrQLGj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "MgVNrRHrQLGj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Values"
      ],
      "metadata": {
        "id": "rE4qFUefYJuQ"
      },
      "id": "rE4qFUefYJuQ"
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = {'gpr_success_rate': gpr_success_rate, 'eacl_topk_success_rate': eacl_topk_success_rate, 'eacl_topk': eacl_topk}\n",
        "result_df = pd.DataFrame([result_df])\n",
        "results_folder_path = 'current-data-dump/ada-autoencoder/ada_autoencoder_predictions/'\n",
        "os.makedirs(results_folder_path, exist_ok=True)\n",
        "results_file_path = f'{results_folder_path}novel_corpora_prediction.pkl'\n",
        "with open(results_file_path, 'wb') as file:\n",
        "  pickle.dump(result_df, file)\n",
        "  print(f\"File uploaded to {results_file_path}\")"
      ],
      "metadata": {
        "id": "uo8TBPUfYMKp"
      },
      "id": "uo8TBPUfYMKp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_result_df = {'persuade_topk_success_rate': persuade_topk_success_rate}\n",
        "evidence_result_df = pd.DataFrame([evidence_result_df])\n",
        "evidence_results_folder_path = 'current-data-dump/ada-evidence-autoencoder/ada_autoencoder_predictions/'\n",
        "os.makedirs(evidence_results_folder_path, exist_ok=True)\n",
        "evidence_results_file_path = f'{evidence_results_folder_path}persuade_corpus_prediction.pkl'\n",
        "with open(evidence_results_file_path, 'wb') as file:\n",
        "  pickle.dump(evidence_result_df, file)\n",
        "  print(f\"File uploaded to {evidence_results_file_path}\")"
      ],
      "metadata": {
        "id": "yCGRjH3aTX7G"
      },
      "id": "yCGRjH3aTX7G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada_autoencoder_file_path = 'current-data-dump/ada-autoencoder/ada_autoencoder_predictions'\n",
        "result = subprocess.run([f\"osf -p sakjg upload -r --force {ada_autoencoder_file_path}/ data-dump/ada003-autoencoder/ada-autoencoder-predictions\"], shell=True, capture_output=True, text=True)\n",
        "print(result.stderr)\n",
        "print(f\"File: {ada_autoencoder_file_path} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "jIxNg610aGyR"
      },
      "id": "jIxNg610aGyR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada_evidence_autoencoder_file_path = 'current-data-dump/ada-evidence-autoencoder/ada_autoencoder_predictions'\n",
        "result = subprocess.run([f\"osf -p sakjg upload -r --force {ada_evidence_autoencoder_file_path}/ data-dump/ada003-evidence-autoencoder/ada-autoencoder-predictions\"], shell=True, capture_output=True, text=True)\n",
        "print(result.stderr)\n",
        "print(f\"File: {ada_evidence_autoencoder_file_path} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "rlFUuD-MT0fN"
      },
      "id": "rlFUuD-MT0fN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada_scifact_autoencoder_file_path = 'current-data-dump/ada-scifact-autoencoder/ada_autoencoder_predictions'\n",
        "result = subprocess.run([f\"osf -p sakjg upload -r --force {ada_scifact_autoencoder_file_path}/ data-dump/ada003-scifact-autoencoder/ada-autoencoder-predictions\"], shell=True, capture_output=True, text=True)\n",
        "print(result.stderr)\n",
        "print(f\"File: {ada_scifact_autoencoder_file_path} uploaded at osfstorage\")"
      ],
      "metadata": {
        "id": "WHZGxcwdT9jE"
      },
      "id": "WHZGxcwdT9jE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "Sgyl5tXbLI67"
      },
      "id": "Sgyl5tXbLI67"
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-autoencoder/ada_autoencoder.zip\", shell=True)\n",
        "print(\"ada003_autoencoder.zip successfully imported\")\n",
        "ada003_autoencoder_file_path_zip = 'ada003_autoencoder.zip'\n",
        "ada003_autoencoder_file_path = 'current-data-dump/ada003-autoencoder'\n",
        "with zipfile.ZipFile(ada003_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada003_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada003_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "EU5Agy1vLJoR"
      },
      "id": "EU5Agy1vLJoR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-evidence-autoencoder/ada003_evidence_autoencoder.zip\", shell=True)\n",
        "print(\"ada003_evidence_autoencoder.zip successfully imported\")\n",
        "ada003_autoencoder_file_path_zip = 'ada003_evidence_autoencoder.zip'\n",
        "ada003_autoencoder_file_path = 'current-data-dump/ada003-evidence-autoencoder'\n",
        "with zipfile.ZipFile(ada003_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada003_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada003_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "MHcwjOkeLsjV"
      },
      "id": "MHcwjOkeLsjV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.run(\"osf -p sakjg fetch --force osfstorage/data-dump/ada003-scifact-autoencoder/ada003_scifact_autoencoder.zip\", shell=True)\n",
        "print(\"ada003_scifact_autoencoder.zip successfully imported\")\n",
        "ada003_autoencoder_file_path_zip = 'ada003_scifact_autoencoder.zip'\n",
        "ada003_autoencoder_file_path = 'current-data-dump/ada003-scifact-autoencoder'\n",
        "with zipfile.ZipFile(ada003_autoencoder_file_path_zip, 'r') as zip_ref:\n",
        "  zip_ref.extractall(ada003_autoencoder_file_path)\n",
        "extracted_files = os.listdir(ada003_autoencoder_file_path)\n",
        "print(\"Files extracted:\", extracted_files)"
      ],
      "metadata": {
        "id": "aJY-c3keLx-Z"
      },
      "id": "aJY-c3keLx-Z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rraCIAGnMU04",
        "4TgJ2Ob4MFbl",
        "b7848602-f4e3-4d65-8833-d33c230a953f"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}